{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/dhruv/Projects/VidSitu/vidsitu_data/vidsitu_annotations/vseg_ann_files/vsann_train_lb.json', 'r') as f:\n",
    "    train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/dhruv/Projects/VidSitu/vidsitu_data/vidsitu_annotations/vseg_ann_files/vsann_valid_lb.json', 'r') as f:\n",
    "    valid = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ev1': {'vid_uid': 'M3u94uEBq9o5',\n",
       "  'vid_seg_int': 'v_M3u94uEBq9o_seg_80_90',\n",
       "  'EvRel': 'Causes',\n",
       "  'Args': {'Arg1 (thing falling)': 'man in wetsuit',\n",
       "   'ArgM (direction)': 'downward',\n",
       "   'Scene of the Event': 'lake'},\n",
       "  'Arg_List': {'Arg1 (thing falling)': '0',\n",
       "   'ArgM (direction)': '1',\n",
       "   'Scene of the Event': '2'},\n",
       "  'Verb': 'dive (to drop)',\n",
       "  'VerbID': 'dive.02'},\n",
       " 'Ev2': {'vid_uid': 'M3u94uEBq9o5',\n",
       "  'vid_seg_int': 'v_M3u94uEBq9o_seg_80_90',\n",
       "  'EvRel': 'Causes',\n",
       "  'Args': {'Arg0 (breather)': 'man in wetsuit',\n",
       "   'Arg1 (air, we hope)': 'man in wetsuit',\n",
       "   'ArgM (manner)': 'aggressively',\n",
       "   'Scene of the Event': 'lake'},\n",
       "  'Arg_List': {'Arg0 (breather)': '0',\n",
       "   'Arg1 (air, we hope)': '1',\n",
       "   'ArgM (manner)': '2',\n",
       "   'Scene of the Event': '3'},\n",
       "  'Verb': 'breathe (suck air)',\n",
       "  'VerbID': 'breathe.01'},\n",
       " 'Ev3': {'vid_uid': 'M3u94uEBq9o5',\n",
       "  'vid_seg_int': 'v_M3u94uEBq9o_seg_80_90',\n",
       "  'Args': {'Arg0 (talker)': 'brunette girl',\n",
       "   'Arg2 (hearer)': 'brunette boy',\n",
       "   'ArgM (location)': 'lake',\n",
       "   'ArgM (manner)': 'casually'},\n",
       "  'Arg_List': {'Arg0 (talker)': '0',\n",
       "   'Arg2 (hearer)': '1',\n",
       "   'ArgM (location)': '2',\n",
       "   'ArgM (manner)': '3'},\n",
       "  'Verb': 'talk (speak)',\n",
       "  'VerbID': 'talk.01'},\n",
       " 'Ev4': {'vid_uid': 'M3u94uEBq9o5',\n",
       "  'vid_seg_int': 'v_M3u94uEBq9o_seg_80_90',\n",
       "  'EvRel': 'Causes',\n",
       "  'Args': {'Arg0 (talker)': 'brunette girl',\n",
       "   'Arg2 (hearer)': 'brunette boy',\n",
       "   'ArgM (location)': 'lake',\n",
       "   'ArgM (manner)': 'casually'},\n",
       "  'Arg_List': {'Arg0 (talker)': '0',\n",
       "   'Arg2 (hearer)': '1',\n",
       "   'ArgM (location)': '2',\n",
       "   'ArgM (manner)': '3'},\n",
       "  'Verb': 'talk (speak)',\n",
       "  'VerbID': 'talk.01'},\n",
       " 'Ev5': {'vid_uid': 'M3u94uEBq9o5',\n",
       "  'vid_seg_int': 'v_M3u94uEBq9o_seg_80_90',\n",
       "  'EvRel': 'Causes',\n",
       "  'Args': {'Arg0 (flipper, agent)': 'man in wetsuit',\n",
       "   'Arg1 (thing flipped)': 'body',\n",
       "   'ArgM (direction)': 'sideways',\n",
       "   'Scene of the Event': 'lake'},\n",
       "  'Arg_List': {'Arg0 (flipper, agent)': '0',\n",
       "   'Arg1 (thing flipped)': '1',\n",
       "   'ArgM (direction)': '2',\n",
       "   'Scene of the Event': '3'},\n",
       "  'Verb': 'flip (throw, turn over)',\n",
       "  'VerbID': 'flip.01'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_fine_tuning_format(dataset):\n",
    "    result = []\n",
    "\n",
    "    for item in dataset:\n",
    "        for event_key, event_data in item.items():\n",
    "            #vid_uid = event_data['vid_uid']\n",
    "            vid_seg_int = event_data['vid_seg_int']\n",
    "            verb = event_data['Verb']\n",
    "            roles = {i+1: role for i, role in enumerate(event_data['Args'].keys())}\n",
    "            nouns = {role: noun for role, noun in event_data['Args'].items()}\n",
    "            id_ = f\"{vid_seg_int}_{event_key}\"\n",
    "\n",
    "            # Calculate start and end times for the event\n",
    "            event_index = int(event_key[2:]) - 1  # Extract event index from key (Ev1 -> 0, Ev2 -> 1, etc.)\n",
    "            start_time = event_index * 2\n",
    "            end_time = start_time + 2\n",
    "\n",
    "            result.append({\n",
    "                'id': id_,\n",
    "                'video': f\"{vid_seg_int}.mp4\",  # Update the path according to your image storage structure\n",
    "                'event': event_key,\n",
    "                'start_secs': start_time,\n",
    "                'end_secs': end_time,\n",
    "                'conversations': [\n",
    "                    {\n",
    "                        'from': 'human',\n",
    "                        'value': \"<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles\"\n",
    "                    },\n",
    "                    {\n",
    "                        'from': 'gpt',\n",
    "                        'value': json.dumps({\"verb\": verb, \"roles\": roles, \"nouns\": nouns}, ensure_ascii=False)\n",
    "                    }\n",
    "                ]\n",
    "            })\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning_dataset = convert_to_fine_tuning_format(train)\n",
    "#print(json.dumps(fine_tuning_dataset, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'v_M3u94uEBq9o_seg_80_90_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_M3u94uEBq9o_seg_80_90.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"dive (to drop)\", \"roles\": {\"1\": \"Arg1 (thing falling)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (thing falling)\": \"man in wetsuit\", \"ArgM (direction)\": \"downward\", \"Scene of the Event\": \"lake\"}}'}]},\n",
       " {'id': 'v_M3u94uEBq9o_seg_80_90_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_M3u94uEBq9o_seg_80_90.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"breathe (suck air)\", \"roles\": {\"1\": \"Arg0 (breather)\", \"2\": \"Arg1 (air, we hope)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (breather)\": \"man in wetsuit\", \"Arg1 (air, we hope)\": \"man in wetsuit\", \"ArgM (manner)\": \"aggressively\", \"Scene of the Event\": \"lake\"}}'}]},\n",
       " {'id': 'v_M3u94uEBq9o_seg_80_90_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_M3u94uEBq9o_seg_80_90.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"brunette girl\", \"Arg2 (hearer)\": \"brunette boy\", \"ArgM (location)\": \"lake\", \"ArgM (manner)\": \"casually\"}}'}]},\n",
       " {'id': 'v_M3u94uEBq9o_seg_80_90_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_M3u94uEBq9o_seg_80_90.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"brunette girl\", \"Arg2 (hearer)\": \"brunette boy\", \"ArgM (location)\": \"lake\", \"ArgM (manner)\": \"casually\"}}'}]},\n",
       " {'id': 'v_M3u94uEBq9o_seg_80_90_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_M3u94uEBq9o_seg_80_90.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"flip (throw, turn over)\", \"roles\": {\"1\": \"Arg0 (flipper, agent)\", \"2\": \"Arg1 (thing flipped)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (flipper, agent)\": \"man in wetsuit\", \"Arg1 (thing flipped)\": \"body\", \"ArgM (direction)\": \"sideways\", \"Scene of the Event\": \"lake\"}}'}]},\n",
       " {'id': 'v_tSZtoveaa0A_seg_40_50_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_tSZtoveaa0A_seg_40_50.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"choke (to have or cause to have  difficulty in breathing)\", \"roles\": {\"1\": \"Arg0 (causer of choking, agent)\", \"2\": \"Arg1 (entity choked)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of choking, agent)\": \"the man with the blonde hair\", \"Arg1 (entity choked)\": \"the man with the brown hair\", \"Scene of the Event\": \"on a bridge\"}}'}]},\n",
       " {'id': 'v_tSZtoveaa0A_seg_40_50_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_tSZtoveaa0A_seg_40_50.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"strike (hit)\", \"roles\": {\"1\": \"Arg0 (agent, hitter - animate only!)\", \"2\": \"Arg1 (thing hit)\", \"3\": \"Arg2 (instrument, thing hit by or with)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, hitter - animate only!)\": \"the man with the brown hair\", \"Arg1 (thing hit)\": \"the man with the blonde hair\", \"Arg2 (instrument, thing hit by or with)\": \"his fist\", \"Scene of the Event\": \"on a bridge\"}}'}]},\n",
       " {'id': 'v_tSZtoveaa0A_seg_40_50_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_tSZtoveaa0A_seg_40_50.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"clamber (to climb awkwardly)\", \"roles\": {\"1\": \"Arg0 (awkward climber, agent)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (awkward climber, agent)\": \"the man with the brown hair\", \"ArgM (direction)\": \"up\", \"Scene of the Event\": \"on a bridge\"}}'}]},\n",
       " {'id': 'v_tSZtoveaa0A_seg_40_50_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_tSZtoveaa0A_seg_40_50.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pull ((try to) cause motion)\", \"roles\": {\"1\": \"Arg0 (puller)\", \"2\": \"Arg1 (thing pulled)\", \"3\": \"Arg2 (DIR or attribute of arg1)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (puller)\": \"the woman with blonde hair\", \"Arg1 (thing pulled)\": \"the man with brown hair\\'s leg\", \"Arg2 (DIR or attribute of arg1)\": \"down\", \"ArgM (location)\": \"on a bridge\"}}'}]},\n",
       " {'id': 'v_tSZtoveaa0A_seg_40_50_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_tSZtoveaa0A_seg_40_50.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"strike (hit)\", \"roles\": {\"1\": \"Arg0 (agent, hitter - animate only!)\", \"2\": \"Arg1 (thing hit)\", \"3\": \"Arg2 (instrument, thing hit by or with)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, hitter - animate only!)\": \"the man with the blonde hair\", \"Arg1 (thing hit)\": \"the woman with blonde hair\", \"Arg2 (instrument, thing hit by or with)\": \"his foot\", \"Scene of the Event\": \"on a bridge\"}}'}]},\n",
       " {'id': 'v_tSZtoveaa0A_seg_70_80_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_tSZtoveaa0A_seg_70_80.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"grab (to capture, obtain)\", \"roles\": {\"1\": \"Arg0 (grabber)\", \"2\": \"Arg1 (entity grabbed)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (grabber)\": \"man in gray jacket\", \"Arg1 (entity grabbed)\": \"the axe\", \"ArgM (location)\": \"on the handly\", \"ArgM (manner)\": \"while pulling at it\"}}'}]},\n",
       " {'id': 'v_tSZtoveaa0A_seg_70_80_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_tSZtoveaa0A_seg_70_80.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pull ((try to) cause motion)\", \"roles\": {\"1\": \"Arg0 (puller)\", \"2\": \"Arg1 (thing pulled)\", \"3\": \"Arg2 (DIR or attribute of arg1)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (puller)\": \"man in gray jacket\", \"Arg1 (thing pulled)\": \"the axe\", \"Arg2 (DIR or attribute of arg1)\": \"towards him\", \"ArgM (location)\": \"on a metal suspension beam of a bridge\"}}'}]},\n",
       " {'id': 'v_tSZtoveaa0A_seg_70_80_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_tSZtoveaa0A_seg_70_80.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hang (suspend)\", \"roles\": {\"1\": \"Arg0 (agent, entity causing something to be suspended)\", \"2\": \"Arg1 (thing suspended)\", \"3\": \"Arg2 (suspended from)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (agent, entity causing something to be suspended)\": \"man in a black suit\", \"Arg1 (thing suspended)\": \"-\", \"Arg2 (suspended from)\": \"from the beam\", \"ArgM (location)\": \"on a metal suspension beam of a bridge\", \"ArgM (manner)\": \"while trying to hold on\"}}'}]},\n",
       " {'id': 'v_tSZtoveaa0A_seg_70_80_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_tSZtoveaa0A_seg_70_80.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man in a brown suit\", \"Arg1 (looked at)\": \"man in a black suit\", \"ArgM (direction)\": \"below\", \"ArgM (manner)\": \"with concern\", \"Scene of the Event\": \"on a metal suspension beam of a bridge\"}}'}]},\n",
       " {'id': 'v_tSZtoveaa0A_seg_70_80_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_tSZtoveaa0A_seg_70_80.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"reach (stretch, grasp)\", \"roles\": {\"1\": \"Arg0 (reacher)\", \"2\": \"Arg1 (body part)\", \"3\": \"Arg2 (goal)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (purpose)\", \"6\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (reacher)\": \"man in a black suit\", \"Arg1 (body part)\": \"his hand\", \"Arg2 (goal)\": \"towards the other man\", \"ArgM (direction)\": \"above him\", \"ArgM (purpose)\": \"so he doesn\\'t fall\", \"Scene of the Event\": \"on a metal suspension beam of a bridge\"}}'}]},\n",
       " {'id': 'v_JKbrP4cjzo8_seg_100_110_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_JKbrP4cjzo8_seg_100_110.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man with vest\", \"Arg2 (hearer)\": \"woman and man with gray hair\", \"ArgM (manner)\": \"telling them what to do\", \"Scene of the Event\": \"boat\"}}'}]},\n",
       " {'id': 'v_JKbrP4cjzo8_seg_100_110_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_JKbrP4cjzo8_seg_100_110.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"release (let go)\", \"roles\": {\"1\": \"Arg0 (releaser)\", \"2\": \"Arg1 (thing released)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (releaser)\": \"woman\", \"Arg1 (thing released)\": \"box\", \"Scene of the Event\": \"boat\"}}'}]},\n",
       " {'id': 'v_JKbrP4cjzo8_seg_100_110_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_JKbrP4cjzo8_seg_100_110.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"motion (to direct with a gesture)\", \"roles\": {\"1\": \"Arg0 (gesturer)\", \"2\": \"Arg1 (gestured at)\", \"3\": \"Arg2 (for what)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (gesturer)\": \"man with vest\", \"Arg1 (gestured at)\": \"woman\", \"Arg2 (for what)\": \"telling her what to do\", \"Scene of the Event\": \"boat\"}}'}]},\n",
       " {'id': 'v_JKbrP4cjzo8_seg_100_110_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_JKbrP4cjzo8_seg_100_110.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"squirm (mode of motion)\", \"roles\": {\"1\": \"Arg0 (squirmer)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (squirmer)\": \"man with gray hair\", \"Scene of the Event\": \"boat\"}}'}]},\n",
       " {'id': 'v_JKbrP4cjzo8_seg_100_110_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_JKbrP4cjzo8_seg_100_110.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man with vest\", \"Arg1 (thing looked at or for or on)\": \"woman and man with gray hair\", \"ArgM (direction)\": \"in front of him\", \"ArgM (manner)\": \"annoyed\", \"Scene of the Event\": \"boat\"}}'}]},\n",
       " {'id': 'v_0mGmEE20CR0_seg_25_35_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0mGmEE20CR0_seg_25_35.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"climb (intentional climber)\", \"roles\": {\"1\": \"Arg0 (climber)\", \"2\": \"Arg1 (thing climbed (clomb?))\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (climber)\": \"Girl in pink sweater and funny hair with another girl in red cloth\", \"Arg1 (thing climbed (clomb?))\": \"snow riddled rocks\", \"ArgM (direction)\": \"up\", \"Scene of the Event\": \"snowy rocks\"}}'}]},\n",
       " {'id': 'v_0mGmEE20CR0_seg_25_35_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0mGmEE20CR0_seg_25_35.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shiver (shake from cold or fear)\", \"roles\": {\"1\": \"Arg1 (shiverer)\", \"2\": \"ArgM (location)\"}, \"nouns\": {\"Arg1 (shiverer)\": \"2 young looking males in red and yellow coats\", \"ArgM (location)\": \"snowy rocks\"}}'}]},\n",
       " {'id': 'v_0mGmEE20CR0_seg_25_35_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0mGmEE20CR0_seg_25_35.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"2 young looking males in red and yellow coats\", \"Arg1 (looked at)\": \"green door to a home\", \"ArgM (direction)\": \"forward\", \"ArgM (manner)\": \"looking for shelter\", \"Scene of the Event\": \"snowy rocks\"}}'}]},\n",
       " {'id': 'v_0mGmEE20CR0_seg_25_35_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0mGmEE20CR0_seg_25_35.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"wait (wait)\", \"roles\": {\"1\": \"Arg1 (wait-er (not waiter, that\\'s the other sense))\", \"2\": \"Arg2 (thing waited for)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (wait-er (not waiter, that\\'s the other sense))\": \"Girl in pink sweater and funny hair with another girl in red cloth along with 2 younger boys in red and yellow coats\", \"Arg2 (thing waited for)\": \"someone behind the door\", \"ArgM (location)\": \"snowy rocks\", \"ArgM (manner)\": \"cold\"}}'}]},\n",
       " {'id': 'v_0mGmEE20CR0_seg_25_35_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0mGmEE20CR0_seg_25_35.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pan (sweep slowly across)\", \"roles\": {\"1\": \"Arg0 (cause, agent)\", \"2\": \"Arg1 (camera, view)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cause, agent)\": \"camera\", \"Arg1 (camera, view)\": \"behind and above\", \"ArgM (direction)\": \"upward\", \"Scene of the Event\": \"snow riddled rocks\"}}'}]},\n",
       " {'id': 'v_QteR6PIwTNk_seg_75_85_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QteR6PIwTNk_seg_75_85.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"run (walk quickly, a course or contest)\", \"roles\": {\"1\": \"Arg0 (runner)\", \"2\": \"Arg1 (course, race, distance)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (goal)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (runner)\": \"boy in white shirt\", \"Arg1 (course, race, distance)\": \"hallway\", \"ArgM (direction)\": \"into a room\", \"ArgM (goal)\": \"to see what the other kids are doing\", \"Scene of the Event\": \"school\"}}'}]},\n",
       " {'id': 'v_QteR6PIwTNk_seg_75_85_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QteR6PIwTNk_seg_75_85.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"boy with gray shirt\", \"Arg2 (hearer)\": \"kids in the room\", \"ArgM (location)\": \"school room\", \"ArgM (manner)\": \"laughingingly\"}}'}]},\n",
       " {'id': 'v_QteR6PIwTNk_seg_75_85_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QteR6PIwTNk_seg_75_85.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"laugh (laugh)\", \"roles\": {\"1\": \"Arg0 (laugher)\", \"2\": \"Arg2 (source of joy)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (laugher)\": \"boy with gray shirt\", \"Arg2 (source of joy)\": \"happiness at the kids\\' attention\", \"ArgM (manner)\": \"happily\", \"Scene of the Event\": \"school room\"}}'}]},\n",
       " {'id': 'v_QteR6PIwTNk_seg_75_85_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QteR6PIwTNk_seg_75_85.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"wash ((make) become clean)\", \"roles\": {\"1\": \"Arg0 (agent of washing)\", \"2\": \"Arg1 (thing being washed, dirt)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent of washing)\": \"boy in plaid shirt\", \"Arg1 (thing being washed, dirt)\": \"his face\", \"Scene of the Event\": \"bathroom\"}}'}]},\n",
       " {'id': 'v_QteR6PIwTNk_seg_75_85_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QteR6PIwTNk_seg_75_85.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"boy with tie\", \"Arg2 (hearer)\": \"audience\", \"ArgM (manner)\": \"seriously\", \"Scene of the Event\": \"behind a table with other kids\"}}'}]},\n",
       " {'id': 'v_FdxUNsKZ4T8_seg_50_60_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_FdxUNsKZ4T8_seg_50_60.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"woman in a gray dress\", \"Arg2 (hearer)\": \"man in a white suit\", \"ArgM (manner)\": \"while sitting in a chair\", \"Scene of the Event\": \"in the den of a home\"}}'}]},\n",
       " {'id': 'v_FdxUNsKZ4T8_seg_50_60_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_FdxUNsKZ4T8_seg_50_60.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"woman in a gray dress\", \"Arg2 (hearer)\": \"man in a white suit\", \"ArgM (manner)\": \"while sitting in a chair\", \"Scene of the Event\": \"in the den of a home\"}}'}]},\n",
       " {'id': 'v_FdxUNsKZ4T8_seg_50_60_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_FdxUNsKZ4T8_seg_50_60.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"watch (look at)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"man in a white suit\", \"Arg1 (thing looked at)\": \"woman in a gray dress\", \"ArgM (manner)\": \"interested\", \"Scene of the Event\": \"in the den of a home\"}}'}]},\n",
       " {'id': 'v_FdxUNsKZ4T8_seg_50_60_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_FdxUNsKZ4T8_seg_50_60.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"respond (give an answer, reply)\", \"roles\": {\"1\": \"Arg0 (replier)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (replier)\": \"man in a white suit\", \"Scene of the Event\": \"in the den of a home\"}}'}]},\n",
       " {'id': 'v_FdxUNsKZ4T8_seg_50_60_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_FdxUNsKZ4T8_seg_50_60.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a white suit\", \"Arg2 (hearer)\": \"woman in a gray dress\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"in the den of a home\"}}'}]},\n",
       " {'id': 'v_891-YR-fgsk_seg_90_100_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_891-YR-fgsk_seg_90_100.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man on bed\", \"Arg1 (thing looked at or for or on)\": \"woman on black\", \"ArgM (direction)\": \"in front of him\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"a bedroom\"}}'}]},\n",
       " {'id': 'v_891-YR-fgsk_seg_90_100_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_891-YR-fgsk_seg_90_100.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"woman on black\", \"Arg2 (hearer)\": \"man on bed\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"a bedroom\"}}'}]},\n",
       " {'id': 'v_891-YR-fgsk_seg_90_100_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_891-YR-fgsk_seg_90_100.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"woman on black\", \"Arg1 (thing looked at or for or on)\": \"man on bed\", \"ArgM (direction)\": \"in front of her\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"a bedroom\"}}'}]},\n",
       " {'id': 'v_891-YR-fgsk_seg_90_100_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_891-YR-fgsk_seg_90_100.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lie (more explicit horizontal position)\", \"roles\": {\"1\": \"Arg1 (entity lying down)\", \"2\": \"Arg2 (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (entity lying down)\": \"man on bed\", \"Arg2 (location)\": \"bed\", \"ArgM (manner)\": \"disappointed\"}}'}]},\n",
       " {'id': 'v_891-YR-fgsk_seg_90_100_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_891-YR-fgsk_seg_90_100.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lie (more explicit horizontal position)\", \"roles\": {\"1\": \"Arg1 (entity lying down)\", \"2\": \"Arg2 (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (entity lying down)\": \"man on bed\", \"Arg2 (location)\": \"bed\", \"ArgM (manner)\": \"disappointed\"}}'}]},\n",
       " {'id': 'v_kHFzcXAU8hg_seg_35_45_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_kHFzcXAU8hg_seg_35_45.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"crouch (to bend forward)\", \"roles\": {\"1\": \"Arg0 (entity crouching)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (entity crouching)\": \"man in a white hat\", \"ArgM (direction)\": \"down\", \"ArgM (location)\": \"next to the person lying on the floor\"}}'}]},\n",
       " {'id': 'v_kHFzcXAU8hg_seg_35_45_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_kHFzcXAU8hg_seg_35_45.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"listen (attend to a sound)\", \"roles\": {\"1\": \"Arg0 (listener)\", \"2\": \"Arg1 (sound or speaker)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (listener)\": \"man in a white hat\", \"Arg1 (sound or speaker)\": \"to the person on the floor\", \"ArgM (manner)\": \"while cradling their head in his hand\", \"Scene of the Event\": \"inside a building\"}}'}]},\n",
       " {'id': 'v_kHFzcXAU8hg_seg_35_45_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_kHFzcXAU8hg_seg_35_45.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"woman in a white shirt\", \"Arg1 (looked at)\": \"the group of people\", \"ArgM (direction)\": \"in front of her\", \"ArgM (manner)\": \"with concern\", \"Scene of the Event\": \"inside a building\"}}'}]},\n",
       " {'id': 'v_kHFzcXAU8hg_seg_35_45_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_kHFzcXAU8hg_seg_35_45.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"listen (attend to a sound)\", \"roles\": {\"1\": \"Arg0 (listener)\", \"2\": \"Arg1 (sound or speaker)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (listener)\": \"man in a white hat\", \"Arg1 (sound or speaker)\": \"to the person on the floor\", \"ArgM (manner)\": \"while leaning his head over their head\", \"Scene of the Event\": \"inside a building\"}}'}]},\n",
       " {'id': 'v_kHFzcXAU8hg_seg_35_45_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_kHFzcXAU8hg_seg_35_45.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shake (tremble)\", \"roles\": {\"1\": \"Arg0 (causer of trembling motion)\", \"2\": \"Arg1 (thing trembling)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of trembling motion)\": \"the pot\", \"Arg1 (thing trembling)\": \"on the platter\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"inside a building\"}}'}]},\n",
       " {'id': 'v_Kz234-_khjs_seg_20_30_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Kz234-_khjs_seg_20_30.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"direct (provide direction)\", \"roles\": {\"1\": \"Arg0 (director)\", \"2\": \"Arg1 (thing directed)\", \"3\": \"Arg2 (direction, towards what)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (director)\": \"the woman in the white robe\", \"Arg1 (thing directed)\": \"the man in the white robe\", \"Arg2 (direction, towards what)\": \"towards the bed\", \"Scene of the Event\": \"inside the bedroom\"}}'}]},\n",
       " {'id': 'v_Kz234-_khjs_seg_20_30_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Kz234-_khjs_seg_20_30.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"the man in the white robe\", \"ArgM (direction)\": \"towards the bed\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"inside the bedroom\"}}'}]},\n",
       " {'id': 'v_Kz234-_khjs_seg_20_30_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Kz234-_khjs_seg_20_30.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"clamber (to climb awkwardly)\", \"roles\": {\"1\": \"Arg0 (awkward climber, agent)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (awkward climber, agent)\": \"the man in the white robe\", \"ArgM (direction)\": \"onto the bed\", \"Scene of the Event\": \"in the bedroom\"}}'}]},\n",
       " {'id': 'v_Kz234-_khjs_seg_20_30_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Kz234-_khjs_seg_20_30.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"situate ((cause to) be located)\", \"roles\": {\"1\": \"Arg1 (thing situated)\", \"2\": \"Arg2 (place)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (thing situated)\": \"the man in the white robe\", \"Arg2 (place)\": \"atop the bed\", \"Scene of the Event\": \"inside the bedroom\"}}'}]},\n",
       " {'id': 'v_Kz234-_khjs_seg_20_30_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Kz234-_khjs_seg_20_30.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"disrobe (undress)\", \"roles\": {\"1\": \"Arg0 (person removing clothes)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (person removing clothes)\": \"the woman in the white robe\", \"Scene of the Event\": \"inside the bedroom\"}}'}]},\n",
       " {'id': 'v_Kz234-_khjs_seg_75_85_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Kz234-_khjs_seg_75_85.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"dangle (to hang loosely)\", \"roles\": {\"1\": \"Arg1 (entity dangling)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity dangling)\": \"sheer black stocking\", \"Scene of the Event\": \"bedroom\"}}'}]},\n",
       " {'id': 'v_Kz234-_khjs_seg_75_85_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Kz234-_khjs_seg_75_85.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"toss (throw randomly)\", \"roles\": {\"1\": \"Arg0 (tosser(s))\", \"2\": \"Arg1 (thing tossed)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (tosser(s))\": \"dark-haired woman with coiffed hairstyle and black strapless dress with a plunging neckline\", \"Arg1 (thing tossed)\": \"sheer black stocking\", \"ArgM (direction)\": \"at the happy man laying on the bed\", \"ArgM (manner)\": \"teasingly\", \"Scene of the Event\": \"bedroom\"}}'}]},\n",
       " {'id': 'v_Kz234-_khjs_seg_75_85_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Kz234-_khjs_seg_75_85.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"catch (get)\", \"roles\": {\"1\": \"Arg0 (receiver)\", \"2\": \"Arg1 (thing gotten)\", \"3\": \"Arg2 (giver)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (receiver)\": \"old man with gray hair laying on the bed\", \"Arg1 (thing gotten)\": \"sheer black stocking\", \"Arg2 (giver)\": \"dark-haired woman with coiffed hairstyle and black strapless dress with a plunging neckline\", \"ArgM (location)\": \"bedroom\"}}'}]},\n",
       " {'id': 'v_Kz234-_khjs_seg_75_85_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Kz234-_khjs_seg_75_85.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"ogle (to stare at)\", \"roles\": {\"1\": \"Arg0 (ogler, agent)\", \"2\": \"Arg1 (entity ogled)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (ogler, agent)\": \"old man with gray hair laying on the bed\", \"Arg1 (entity ogled)\": \"dark-haired woman with coiffed hairstyle and black strapless dress with a plunging neckline\", \"Scene of the Event\": \"bedroom\"}}'}]},\n",
       " {'id': 'v_Kz234-_khjs_seg_75_85_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Kz234-_khjs_seg_75_85.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"reach (stretch, grasp)\", \"roles\": {\"1\": \"Arg0 (reacher)\", \"2\": \"Arg1 (body part)\", \"3\": \"Arg2 (goal)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (purpose)\", \"6\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (reacher)\": \"dark-haired woman with coiffed hairstyle and black strapless dress with a plunging neckline\", \"Arg1 (body part)\": \"both hands\", \"Arg2 (goal)\": \"to work on\", \"ArgM (direction)\": \"behind her back\", \"ArgM (purpose)\": \"undoing the back of her dress\", \"Scene of the Event\": \"bedroom\"}}'}]},\n",
       " {'id': 'v_ipt7yPT4Lkw_seg_75_85_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ipt7yPT4Lkw_seg_75_85.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"nod (to lower and raise the head or to express by nodding)\", \"roles\": {\"1\": \"Arg0 (entity with a bobbing head, agent)\", \"2\": \"ArgM (manner)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity with a bobbing head, agent)\": \"woman in a red shirt\", \"ArgM (manner)\": \"man in a white t-shirt\", \"Scene of the Event\": \"in a dining room\"}}'}]},\n",
       " {'id': 'v_ipt7yPT4Lkw_seg_75_85_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ipt7yPT4Lkw_seg_75_85.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a white t-shirt\", \"Arg2 (hearer)\": \"woman in a red shirt\", \"ArgM (manner)\": \"while he eats\", \"Scene of the Event\": \"in a dining room\"}}'}]},\n",
       " {'id': 'v_ipt7yPT4Lkw_seg_75_85_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ipt7yPT4Lkw_seg_75_85.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a white t-shirt\", \"Arg2 (hearer)\": \"woman in a red shirt\", \"ArgM (manner)\": \"while he eats\", \"Scene of the Event\": \"in a dining room\"}}'}]},\n",
       " {'id': 'v_ipt7yPT4Lkw_seg_75_85_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ipt7yPT4Lkw_seg_75_85.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"respond (give an answer, reply)\", \"roles\": {\"1\": \"Arg0 (replier)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (replier)\": \"woman in a red shirt\", \"Scene of the Event\": \"in a dining room\"}}'}]},\n",
       " {'id': 'v_ipt7yPT4Lkw_seg_75_85_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ipt7yPT4Lkw_seg_75_85.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"gesture (body language)\", \"roles\": {\"1\": \"Arg0 (gesturer)\", \"2\": \"Arg1 (gestured at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (gesturer)\": \"woman in a red shirt\", \"Arg1 (gestured at)\": \"man in a white t-shirt\", \"Scene of the Event\": \"in a dining room\"}}'}]},\n",
       " {'id': 'v_us_GLuu2SAc_seg_125_135_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_us_GLuu2SAc_seg_125_135.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"listen (attend to a sound)\", \"roles\": {\"1\": \"Arg0 (listener)\", \"2\": \"Arg1 (sound or speaker)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (listener)\": \"man in a grey t shirt and an animated teddy bear\", \"Arg1 (sound or speaker)\": \"blonde haired woman in a chequered shirt\", \"ArgM (manner)\": \"keenly\", \"Scene of the Event\": \"in a library\"}}'}]},\n",
       " {'id': 'v_us_GLuu2SAc_seg_125_135_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_us_GLuu2SAc_seg_125_135.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"peer (to look searchingly)\", \"roles\": {\"1\": \"Arg0 (looker, searcher, agent)\", \"2\": \"Arg1 (entity peered into/at/over...)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker, searcher, agent)\": \"a teddy bear\", \"Arg1 (entity peered into/at/over...)\": \"different areas of the library\", \"ArgM (direction)\": \"side to side\", \"ArgM (manner)\": \"searchingly\", \"Scene of the Event\": \"in a library\"}}'}]},\n",
       " {'id': 'v_us_GLuu2SAc_seg_125_135_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_us_GLuu2SAc_seg_125_135.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"run (walk quickly, a course or contest)\", \"roles\": {\"1\": \"Arg0 (runner)\", \"2\": \"Arg1 (course, race, distance)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (goal)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (runner)\": \"a teddy bear\", \"Arg1 (course, race, distance)\": \"himself\", \"ArgM (direction)\": \"toward a man in a blue jumper and a woman in a grey top\", \"ArgM (goal)\": \"to get next to the couple\", \"Scene of the Event\": \"in a library\"}}'}]},\n",
       " {'id': 'v_us_GLuu2SAc_seg_125_135_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_us_GLuu2SAc_seg_125_135.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"smoke (smoke cigarettes)\", \"roles\": {\"1\": \"Arg0 (smoker)\", \"2\": \"Arg1 (cigarettes (etc))\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (smoker)\": \"man in a blue jumper\", \"Arg1 (cigarettes (etc))\": \"bong\", \"Scene of the Event\": \"in a library\"}}'}]},\n",
       " {'id': 'v_us_GLuu2SAc_seg_125_135_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_us_GLuu2SAc_seg_125_135.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pass (give)\", \"roles\": {\"1\": \"Arg0 (giver)\", \"2\": \"Arg1 (thing changing hands)\", \"3\": \"Arg2 (getter)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (giver)\": \"man in a blue jumper\", \"Arg1 (thing changing hands)\": \"a bong\", \"Arg2 (getter)\": \"woman in a grey top\", \"ArgM (direction)\": \"to his side\", \"ArgM (location)\": \"seated by the book shelves\"}}'}]},\n",
       " {'id': 'v_d5lyojjyMl0_seg_15_25_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_d5lyojjyMl0_seg_15_25.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"drive (drive a vehicle)\", \"roles\": {\"1\": \"Arg0 (driver)\", \"2\": \"Arg1 (vehicle or path)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (driver)\": \"girl with black hair\", \"Arg1 (vehicle or path)\": \"street\", \"ArgM (direction)\": \"down\", \"ArgM (manner)\": \"nervously\", \"Scene of the Event\": \"in a car\"}}'}]},\n",
       " {'id': 'v_d5lyojjyMl0_seg_15_25_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_d5lyojjyMl0_seg_15_25.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"see (view)\", \"roles\": {\"1\": \"Arg0 (viewer)\", \"2\": \"Arg1 (thing viewed)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (viewer)\": \"girl with black hair\", \"Arg1 (thing viewed)\": \"ghost children\", \"ArgM (direction)\": \"through the window\", \"ArgM (location)\": \"in a car\"}}'}]},\n",
       " {'id': 'v_d5lyojjyMl0_seg_15_25_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_d5lyojjyMl0_seg_15_25.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"react (give a response, reaction)\", \"roles\": {\"1\": \"Arg0 (reactor)\", \"2\": \"Arg1 (reacted-to)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (reactor)\": \"girl with black hair\", \"Arg1 (reacted-to)\": \"ghost children\", \"ArgM (manner)\": \"trying not to hit them\", \"Scene of the Event\": \"in a car\"}}'}]},\n",
       " {'id': 'v_d5lyojjyMl0_seg_15_25_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_d5lyojjyMl0_seg_15_25.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"crash (to break, undergo damage)\", \"roles\": {\"1\": \"Arg1 (entity crashed)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity crashed)\": \"car\", \"ArgM (direction)\": \"into a telephone pole\", \"Scene of the Event\": \"woods\"}}'}]},\n",
       " {'id': 'v_d5lyojjyMl0_seg_15_25_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_d5lyojjyMl0_seg_15_25.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"open (open)\", \"roles\": {\"1\": \"Arg0 (opener)\", \"2\": \"Arg1 (thing opening)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (opener)\": \"girl with black hair\", \"Arg1 (thing opening)\": \"car door\", \"ArgM (manner)\": \"to escape from the car\", \"Scene of the Event\": \"woods\"}}'}]},\n",
       " {'id': 'v_VlfBJLU-8us_seg_10_20_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_VlfBJLU-8us_seg_10_20.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"woman in a black sweater\", \"Arg1 (looked at)\": \"man in a black coat and a white t shirt\", \"ArgM (direction)\": \"over her shoulder\", \"ArgM (manner)\": \"wordlessly\", \"Scene of the Event\": \"in a room\"}}'}]},\n",
       " {'id': 'v_VlfBJLU-8us_seg_10_20_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_VlfBJLU-8us_seg_10_20.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a black coat and a white t shirt\", \"Arg2 (hearer)\": \"a blonde haired man in a black leather jacket\", \"ArgM (location)\": \"by a bathroom mirror\", \"ArgM (manner)\": \"face to face\"}}'}]},\n",
       " {'id': 'v_VlfBJLU-8us_seg_10_20_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_VlfBJLU-8us_seg_10_20.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"gesture (body language)\", \"roles\": {\"1\": \"Arg0 (gesturer)\", \"2\": \"Arg1 (gestured at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (gesturer)\": \"a blonde haired man in a black leather jacket\", \"Arg1 (gestured at)\": \"man in a black coat and a white t shirt and woman in a black sweater\", \"Scene of the Event\": \"in a bathroom\"}}'}]},\n",
       " {'id': 'v_VlfBJLU-8us_seg_10_20_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_VlfBJLU-8us_seg_10_20.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fidget (to behave restlessly, play or fuss)\", \"roles\": {\"1\": \"Arg0 (restless entity, agent)\", \"2\": \"ArgM (manner)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (restless entity, agent)\": \"woman in a black sweater\", \"ArgM (manner)\": \"nervously\", \"Scene of the Event\": \"in a bathroom\"}}'}]},\n",
       " {'id': 'v_VlfBJLU-8us_seg_10_20_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_VlfBJLU-8us_seg_10_20.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"peer (to look searchingly)\", \"roles\": {\"1\": \"Arg0 (looker, searcher, agent)\", \"2\": \"Arg1 (entity peered into/at/over...)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker, searcher, agent)\": \"woman in a black sweater\", \"Arg1 (entity peered into/at/over...)\": \"from the man in a black coat and a white t shirt to a blonde haired man in a black leather jacket\", \"ArgM (direction)\": \"side to side\", \"ArgM (manner)\": \"hurriedly\", \"Scene of the Event\": \"in a bathroom\"}}'}]},\n",
       " {'id': 'v_nvnag6ta7LA_seg_10_20_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_nvnag6ta7LA_seg_10_20.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"vomit (puke)\", \"roles\": {\"1\": \"Arg0 (poor schmo vomiting)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (poor schmo vomiting)\": \"A woman\", \"Scene of the Event\": \"into a jar\"}}'}]},\n",
       " {'id': 'v_nvnag6ta7LA_seg_10_20_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_nvnag6ta7LA_seg_10_20.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"vomit (puke)\", \"roles\": {\"1\": \"Arg0 (poor schmo vomiting)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (poor schmo vomiting)\": \"The woman\", \"Scene of the Event\": \"into the jar\"}}'}]},\n",
       " {'id': 'v_nvnag6ta7LA_seg_10_20_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_nvnag6ta7LA_seg_10_20.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"A man\", \"Arg2 (hearer)\": \"to the woman\", \"ArgM (manner)\": \"calmly\", \"Scene of the Event\": \"holding the jar\"}}'}]},\n",
       " {'id': 'v_nvnag6ta7LA_seg_10_20_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_nvnag6ta7LA_seg_10_20.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"watch (look at)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"The man\", \"Arg1 (thing looked at)\": \"the woman\", \"ArgM (manner)\": \"concerned\", \"Scene of the Event\": \"holding the jar\"}}'}]},\n",
       " {'id': 'v_nvnag6ta7LA_seg_10_20_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_nvnag6ta7LA_seg_10_20.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cry (cry, weep)\", \"roles\": {\"1\": \"Arg0 (cryer)\", \"2\": \"ArgM (manner)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cryer)\": \"The woman\", \"ArgM (manner)\": \"sadly\", \"Scene of the Event\": \"over the jar\"}}'}]},\n",
       " {'id': 'v_ng95gpwSjZU_seg_15_25_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ng95gpwSjZU_seg_15_25.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lean (to incline or cause to incline)\", \"roles\": {\"1\": \"Arg0 (causer of leaning)\", \"2\": \"Arg2 (direction)\", \"3\": \"ArgM (purpose)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of leaning)\": \"skinny man\", \"Arg2 (direction)\": \"a few degrees back\", \"ArgM (purpose)\": \"-\", \"Scene of the Event\": \"interior of a boat\"}}'}]},\n",
       " {'id': 'v_ng95gpwSjZU_seg_15_25_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ng95gpwSjZU_seg_15_25.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sit (be in a position)\", \"roles\": {\"1\": \"Arg1 (thing sitting)\", \"2\": \"Arg2 (location or position)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing sitting)\": \"skinny man\", \"Arg2 (location or position)\": \"in front of the wall\", \"ArgM (manner)\": \"totally still\"}}'}]},\n",
       " {'id': 'v_ng95gpwSjZU_seg_15_25_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ng95gpwSjZU_seg_15_25.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pause (to suspend an action, to hesitate)\", \"roles\": {\"1\": \"Arg0 (thing pausing, agent or action)\", \"2\": \"ArgM (location)\", \"3\": \"ArgM (purpose)\"}, \"nouns\": {\"Arg0 (thing pausing, agent or action)\": \"skinny man\", \"ArgM (location)\": \"in front of the wall\", \"ArgM (purpose)\": \"to wait\"}}'}]},\n",
       " {'id': 'v_ng95gpwSjZU_seg_15_25_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ng95gpwSjZU_seg_15_25.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"advance (move forward or upward)\", \"roles\": {\"1\": \"Arg1 (thing advancing)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (thing advancing)\": \"man in a yellow Navy shirt\", \"Scene of the Event\": \"interior of a boat\"}}'}]},\n",
       " {'id': 'v_ng95gpwSjZU_seg_15_25_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ng95gpwSjZU_seg_15_25.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"advance (move forward or upward)\", \"roles\": {\"1\": \"Arg1 (thing advancing)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (thing advancing)\": \"man in a yellow Navy shirt\", \"Scene of the Event\": \"interior of a boat\"}}'}]},\n",
       " {'id': 'v_c71vLQPwjdU_seg_40_50_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_c71vLQPwjdU_seg_40_50.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hesitate (hesitate)\", \"roles\": {\"1\": \"Arg0 (hesitator)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (hesitator)\": \"man in a tank top\", \"Scene of the Event\": \"building hallway\"}}'}]},\n",
       " {'id': 'v_c71vLQPwjdU_seg_40_50_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_c71vLQPwjdU_seg_40_50.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"withdraw (withdraw, remove oneself)\", \"roles\": {\"1\": \"Arg0 (entity removing)\", \"2\": \"Arg1 (thing being withdrawn (often understood as \\'self\\'))\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity removing)\": \"man in a brown leather jacket\", \"Arg1 (thing being withdrawn (often understood as \\'self\\'))\": \"money\", \"Scene of the Event\": \"building hallway\"}}'}]},\n",
       " {'id': 'v_c71vLQPwjdU_seg_40_50_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_c71vLQPwjdU_seg_40_50.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"open (open)\", \"roles\": {\"1\": \"Arg0 (opener)\", \"2\": \"Arg1 (thing opening)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (opener)\": \"man in a tank top\", \"Arg1 (thing opening)\": \"apartment door\", \"ArgM (manner)\": \"with the key\", \"Scene of the Event\": \"building hallway\"}}'}]},\n",
       " {'id': 'v_c71vLQPwjdU_seg_40_50_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_c71vLQPwjdU_seg_40_50.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pass (go by)\", \"roles\": {\"1\": \"Arg1 (thing passing)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg1 (thing passing)\": \"man in a brown leather jacket\", \"ArgM (direction)\": \"by the man in a tank top\", \"ArgM (location)\": \"outside the apartment door\"}}'}]},\n",
       " {'id': 'v_c71vLQPwjdU_seg_40_50_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_c71vLQPwjdU_seg_40_50.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"enter (enter, go in)\", \"roles\": {\"1\": \"Arg0 (entity entering)\", \"2\": \"Arg1 (place or thing entered)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity entering)\": \"man in a brown leather jacket\", \"Arg1 (place or thing entered)\": \"apartment door\", \"ArgM (manner)\": \"like he\\'s been there before\", \"Scene of the Event\": \"sparsely decorated apartment\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_100_110_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_100_110.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"woman with gray hair\", \"Arg2 (hearer)\": \"man in a vest\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_100_110_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_100_110.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"approach (move towards)\", \"roles\": {\"1\": \"Arg1 (entity in motion)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity in motion)\": \"man in a vest\", \"Arg2 (destination)\": \"doors\", \"ArgM (direction)\": \"forward\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"in a home\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_100_110_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_100_110.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"open (open)\", \"roles\": {\"1\": \"Arg0 (opener)\", \"2\": \"Arg1 (thing opening)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (opener)\": \"man in a vest\", \"Arg1 (thing opening)\": \"doors\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"in a home\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_100_110_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_100_110.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"woman in a gray suit\", \"Arg2 (hearer)\": \"man in a vest\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"in a home\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_100_110_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_100_110.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"woman in a gray suit\", \"Arg2 (hearer)\": \"man in a vest\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"in a home\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_130_140_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_130_140.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"open (open)\", \"roles\": {\"1\": \"Arg0 (opener)\", \"2\": \"Arg1 (thing opening)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (opener)\": \"man in vest\", \"Arg1 (thing opening)\": \"closet\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"bedroom\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_130_140_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_130_140.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"try (Attempt)\", \"roles\": {\"1\": \"Arg0 (Agent/Entity Trying)\", \"2\": \"Arg1 (thing tried)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Agent/Entity Trying)\": \"old woman\", \"Arg1 (thing tried)\": \"to put on makeup\", \"ArgM (manner)\": \"swiping her face taring her skin\", \"Scene of the Event\": \"bedroom\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_130_140_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_130_140.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shock (surprise)\", \"roles\": {\"1\": \"Arg1 (person surprised)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (person surprised)\": \"old woman\", \"Scene of the Event\": \"bedroom\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_130_140_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_130_140.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"surprise (surprise)\", \"roles\": {\"1\": \"Arg1 (person surprised)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (person surprised)\": \"man in vest\", \"Scene of the Event\": \"bedroom\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_130_140_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_130_140.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in vest\", \"Arg2 (hearer)\": \"old woman\", \"ArgM (manner)\": \"kneeling down next to her\", \"Scene of the Event\": \"bedroom\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_5_15_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_5_15.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"the man lying on the bed\", \"Arg1 (looked at)\": \"the ceiling\", \"ArgM (direction)\": \"upward\", \"ArgM (manner)\": \"staring\", \"Scene of the Event\": \"in the room\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_5_15_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_5_15.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"kiss (smooch)\", \"roles\": {\"1\": \"Arg0 (kisser)\", \"2\": \"Arg1 (kissed)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (kisser)\": \"the lady on the bed\", \"Arg1 (kissed)\": \"the man lying on the bed\", \"ArgM (location)\": \"in the room\", \"ArgM (manner)\": \"passionately\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_5_15_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_5_15.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"terrify (scare very badly)\", \"roles\": {\"1\": \"Arg1 (terrified entity)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (terrified entity)\": \"the old woman\", \"Scene of the Event\": \"in the room\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_5_15_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_5_15.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"terrify (scare very badly)\", \"roles\": {\"1\": \"Arg1 (terrified entity)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (terrified entity)\": \"the old woman\", \"Scene of the Event\": \"in the room\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_5_15_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_5_15.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"terrify (scare very badly)\", \"roles\": {\"1\": \"Arg1 (terrified entity)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (terrified entity)\": \"the old woman\", \"Scene of the Event\": \"in the room\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_145_155_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_145_155.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"mutter (speak unclearly)\", \"roles\": {\"1\": \"Arg0 (speaker)\", \"2\": \"Arg2 (listener)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (speaker)\": \"the old woman with gray hair\", \"Arg2 (listener)\": \"no one and/or undisclosed\", \"Scene of the Event\": \"what appears to be a bedroom\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_145_155_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_145_155.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"open (open)\", \"roles\": {\"1\": \"Arg0 (opener)\", \"2\": \"Arg1 (thing opening)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (opener)\": \"unclear / a set of hands belonging to a man\", \"Arg1 (thing opening)\": \"a dresser drawer\", \"ArgM (manner)\": \"frantically\", \"Scene of the Event\": \"what appears to be a bedroom\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_145_155_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_145_155.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"grab (to capture, obtain)\", \"roles\": {\"1\": \"Arg0 (grabber)\", \"2\": \"Arg1 (entity grabbed)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (grabber)\": \"a younger man with a vest on\", \"Arg1 (entity grabbed)\": \"a bottle of what appears to be type of medicine or balm\", \"ArgM (location)\": \"from the dresser drawer\", \"ArgM (manner)\": \"frantically\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_145_155_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_145_155.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"examine (look at closely)\", \"roles\": {\"1\": \"Arg0 (examiner)\", \"2\": \"Arg1 (thing examined)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (examiner)\": \"the younger man with a vest on\", \"Arg1 (thing examined)\": \"the wound on the old woman\\'s face\", \"ArgM (manner)\": \"as if he is prepare to apply the medicine\", \"Scene of the Event\": \"what appears to be a bedroom\"}}'}]},\n",
       " {'id': 'v_8wDlH8jWxYk_seg_145_155_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8wDlH8jWxYk_seg_145_155.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"administer (to manage, distribute, or apply)\", \"roles\": {\"1\": \"Arg0 (administrator, agent)\", \"2\": \"Arg1 (entity administered)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (administrator, agent)\": \"the younger man with a vest on\", \"Arg1 (entity administered)\": \"a bottle of what appears to be type of medicine or balm\", \"Scene of the Event\": \"what appears to be a bedroom\"}}'}]},\n",
       " {'id': 'v_5lkqZP5rBvg_seg_40_50_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_5lkqZP5rBvg_seg_40_50.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a white shirt and a black half coat\", \"Arg2 (hearer)\": \"woman in a grey coat\", \"ArgM (location)\": \"opposite his table\", \"ArgM (manner)\": \"face to face\"}}'}]},\n",
       " {'id': 'v_5lkqZP5rBvg_seg_40_50_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_5lkqZP5rBvg_seg_40_50.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"gesture (body language)\", \"roles\": {\"1\": \"Arg0 (gesturer)\", \"2\": \"Arg1 (gestured at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (gesturer)\": \"man in a white shirt and a black half coat\", \"Arg1 (gestured at)\": \"woman in a grey coat\", \"Scene of the Event\": \"in a restaurant\"}}'}]},\n",
       " {'id': 'v_5lkqZP5rBvg_seg_40_50_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_5lkqZP5rBvg_seg_40_50.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"smoke (smoke cigarettes)\", \"roles\": {\"1\": \"Arg0 (smoker)\", \"2\": \"Arg1 (cigarettes (etc))\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (smoker)\": \"man in a white shirt and a black half coat\", \"Arg1 (cigarettes (etc))\": \"cigarette\", \"Scene of the Event\": \"in a restaurant\"}}'}]},\n",
       " {'id': 'v_5lkqZP5rBvg_seg_40_50_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_5lkqZP5rBvg_seg_40_50.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"nod (to lower and raise the head or to express by nodding)\", \"roles\": {\"1\": \"Arg0 (entity with a bobbing head, agent)\", \"2\": \"ArgM (manner)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity with a bobbing head, agent)\": \"woman in a grey coat\", \"ArgM (manner)\": \"while staring at the man in a white shirt and a black half coat\", \"Scene of the Event\": \"in a restaurant\"}}'}]},\n",
       " {'id': 'v_5lkqZP5rBvg_seg_40_50_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_5lkqZP5rBvg_seg_40_50.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pick (pick up: acquire)\", \"roles\": {\"1\": \"Arg0 (agent, entity acquiring something)\", \"2\": \"Arg1 (thing acquired)\", \"3\": \"Arg2 (seller)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (agent, entity acquiring something)\": \"man in a white shirt and a black half coat\", \"Arg1 (thing acquired)\": \"a glass of water\", \"Arg2 (seller)\": \"himself\", \"ArgM (location)\": \"on the dining table\", \"ArgM (manner)\": \"gently\"}}'}]},\n",
       " {'id': 'v__Ib_lBGuoUQ_seg_5_15_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__Ib_lBGuoUQ_seg_5_15.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"kick (drive or impel with the foot)\", \"roles\": {\"1\": \"Arg0 (kicker)\", \"2\": \"Arg1 (thing kicked)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (kicker)\": \"man in a grey and white t shirt\", \"Arg1 (thing kicked)\": \"man in a black and white t shirt\", \"ArgM (direction)\": \"up\", \"ArgM (location)\": \"on the face\", \"ArgM (manner)\": \"abruptly and with force\"}}'}]},\n",
       " {'id': 'v__Ib_lBGuoUQ_seg_5_15_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__Ib_lBGuoUQ_seg_5_15.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"react (give a response, reaction)\", \"roles\": {\"1\": \"Arg0 (reactor)\", \"2\": \"Arg1 (reacted-to)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (reactor)\": \"woman in a white dress\", \"Arg1 (reacted-to)\": \"man in a black and white t shirt\\'s face kick\", \"ArgM (manner)\": \"as if she is about to faint\", \"Scene of the Event\": \"in a boxing room\"}}'}]},\n",
       " {'id': 'v__Ib_lBGuoUQ_seg_5_15_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__Ib_lBGuoUQ_seg_5_15.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"woman in a white dress\", \"Arg1 (looked at)\": \"injured man in a black and white tshirt\", \"ArgM (direction)\": \"ahead\", \"ArgM (manner)\": \"wordlessly\", \"Scene of the Event\": \"in a boxing room\"}}'}]},\n",
       " {'id': 'v__Ib_lBGuoUQ_seg_5_15_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__Ib_lBGuoUQ_seg_5_15.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lie (more explicit horizontal position)\", \"roles\": {\"1\": \"Arg1 (entity lying down)\", \"2\": \"Arg2 (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (entity lying down)\": \"injured man in a black and white tshirt\", \"Arg2 (location)\": \"on a bed\", \"ArgM (manner)\": \"helplessly with a bloody nose\"}}'}]},\n",
       " {'id': 'v__Ib_lBGuoUQ_seg_5_15_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__Ib_lBGuoUQ_seg_5_15.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"examine (look at closely)\", \"roles\": {\"1\": \"Arg0 (examiner)\", \"2\": \"Arg1 (thing examined)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (examiner)\": \"man in a multi coloured shirt with a cap on\", \"Arg1 (thing examined)\": \"injured man in a black and white tshirt\", \"ArgM (manner)\": \"smilingly\", \"Scene of the Event\": \"in a boxing room\"}}'}]},\n",
       " {'id': 'v_5ArOFrHp9Lo_seg_70_80_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_5ArOFrHp9Lo_seg_70_80.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a white polo style shirt\", \"Arg2 (hearer)\": \"woman in a red shirt\", \"ArgM (manner)\": \"emphatically\", \"Scene of the Event\": \"in an outdoor wooded area\"}}'}]},\n",
       " {'id': 'v_5ArOFrHp9Lo_seg_70_80_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_5ArOFrHp9Lo_seg_70_80.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"respond (give an answer, reply)\", \"roles\": {\"1\": \"Arg0 (replier)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (replier)\": \"woman in a red shirt\", \"Scene of the Event\": \"in an outdoor wooded area\"}}'}]},\n",
       " {'id': 'v_5ArOFrHp9Lo_seg_70_80_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_5ArOFrHp9Lo_seg_70_80.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man in a white polo style shirt\", \"ArgM (direction)\": \"away\", \"ArgM (manner)\": \"towards a building\", \"Scene of the Event\": \"in an outdoor wooded area\"}}'}]},\n",
       " {'id': 'v_5ArOFrHp9Lo_seg_70_80_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_5ArOFrHp9Lo_seg_70_80.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"approach (move towards)\", \"roles\": {\"1\": \"Arg1 (entity in motion)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity in motion)\": \"man in a white polo style shirt\", \"Arg2 (destination)\": \"door of a building\", \"ArgM (direction)\": \"forward\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"in an outdoor wooded area\"}}'}]},\n",
       " {'id': 'v_5ArOFrHp9Lo_seg_70_80_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_5ArOFrHp9Lo_seg_70_80.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a blue shirt\", \"Arg2 (hearer)\": \"-\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"in a home\"}}'}]},\n",
       " {'id': 'v_E7CPLxlfKaw_seg_20_30_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_E7CPLxlfKaw_seg_20_30.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man in tan suit\", \"ArgM (direction)\": \"toward a couch\", \"ArgM (manner)\": \"swiftly\", \"Scene of the Event\": \"living room\"}}'}]},\n",
       " {'id': 'v_E7CPLxlfKaw_seg_20_30_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_E7CPLxlfKaw_seg_20_30.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man in tan suit\", \"ArgM (direction)\": \"toward a couch\", \"ArgM (manner)\": \"swiftly\", \"Scene of the Event\": \"living room\"}}'}]},\n",
       " {'id': 'v_E7CPLxlfKaw_seg_20_30_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_E7CPLxlfKaw_seg_20_30.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pick (pick up: acquire)\", \"roles\": {\"1\": \"Arg0 (agent, entity acquiring something)\", \"2\": \"Arg1 (thing acquired)\", \"3\": \"Arg2 (seller)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (agent, entity acquiring something)\": \"man in tan suit\", \"Arg1 (thing acquired)\": \"remote\", \"Arg2 (seller)\": \"on a table\", \"ArgM (location)\": \"living room\", \"ArgM (manner)\": \"slowly\"}}'}]},\n",
       " {'id': 'v_E7CPLxlfKaw_seg_20_30_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_E7CPLxlfKaw_seg_20_30.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"point (point at, define, make an example of)\", \"roles\": {\"1\": \"Arg0 (pointer)\", \"2\": \"Arg1 (pointed at)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (pointer)\": \"man in tan suit\", \"Arg1 (pointed at)\": \"TV\", \"ArgM (direction)\": \"forward\", \"Scene of the Event\": \"living room\"}}'}]},\n",
       " {'id': 'v_E7CPLxlfKaw_seg_20_30_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_E7CPLxlfKaw_seg_20_30.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"turn (rotation)\", \"roles\": {\"1\": \"Arg0 (turner)\", \"2\": \"Arg1 (thing turning)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (purpose)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (turner)\": \"man in tan suit\", \"Arg1 (thing turning)\": \"man in tan suit\", \"ArgM (direction)\": \"around\", \"ArgM (purpose)\": \"to set the remote back down\", \"Scene of the Event\": \"living room\"}}'}]},\n",
       " {'id': 'v_E7CPLxlfKaw_seg_110_120_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_E7CPLxlfKaw_seg_110_120.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shut (turn off, as a light)\", \"roles\": {\"1\": \"Arg0 (flipper of the switch, agent)\", \"2\": \"Arg1 (light)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (flipper of the switch, agent)\": \"A moustached man\", \"Arg1 (light)\": \"the TV\", \"ArgM (location)\": \"from a chair\", \"ArgM (manner)\": \"angered\"}}'}]},\n",
       " {'id': 'v_E7CPLxlfKaw_seg_110_120_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_E7CPLxlfKaw_seg_110_120.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"drink (ingest liquids)\", \"roles\": {\"1\": \"Arg0 (drinker)\", \"2\": \"Arg1 (liquid)\", \"3\": \"Arg2 (source of liquid)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (drinker)\": \"The man\", \"Arg1 (liquid)\": \"brandy\", \"Arg2 (source of liquid)\": \"from a glass\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"in the chair\"}}'}]},\n",
       " {'id': 'v_E7CPLxlfKaw_seg_110_120_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_E7CPLxlfKaw_seg_110_120.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"The man\", \"ArgM (direction)\": \"out\", \"ArgM (manner)\": \"fast\", \"Scene of the Event\": \"of a cabana\"}}'}]},\n",
       " {'id': 'v_E7CPLxlfKaw_seg_110_120_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_E7CPLxlfKaw_seg_110_120.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"smoke (smoke cigarettes)\", \"roles\": {\"1\": \"Arg0 (smoker)\", \"2\": \"Arg1 (cigarettes (etc))\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (smoker)\": \"A woman\", \"Arg1 (cigarettes (etc))\": \"a cigarette\", \"Scene of the Event\": \"near the front door\"}}'}]},\n",
       " {'id': 'v_E7CPLxlfKaw_seg_110_120_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_E7CPLxlfKaw_seg_110_120.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"approach (move towards)\", \"roles\": {\"1\": \"Arg1 (entity in motion)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity in motion)\": \"The moustached man\", \"Arg2 (destination)\": \"the pool\", \"ArgM (direction)\": \"in front\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"of the cabana\"}}'}]},\n",
       " {'id': 'v_i5jTH89HjTA_seg_70_80_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_i5jTH89HjTA_seg_70_80.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"aim (directed motion)\", \"roles\": {\"1\": \"Arg0 (aimer)\", \"2\": \"Arg1 (thing in motion)\", \"3\": \"Arg2 (target)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (aimer)\": \"man in brown vest and black hat\", \"Arg1 (thing in motion)\": \"rifle\", \"Arg2 (target)\": \"-\", \"Scene of the Event\": \"inside a car by the driver\\'s window\"}}'}]},\n",
       " {'id': 'v_i5jTH89HjTA_seg_70_80_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_i5jTH89HjTA_seg_70_80.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"open (open)\", \"roles\": {\"1\": \"Arg0 (opener)\", \"2\": \"Arg1 (thing opening)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (opener)\": \"man in brown vest and black hat\", \"Arg1 (thing opening)\": \"car door on driver\\'s side\", \"ArgM (manner)\": \"clumsily\", \"Scene of the Event\": \"inside a vehicle by the side of the road\"}}'}]},\n",
       " {'id': 'v_i5jTH89HjTA_seg_70_80_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_i5jTH89HjTA_seg_70_80.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"exit (leave)\", \"roles\": {\"1\": \"Arg0 (departed entity)\", \"2\": \"Arg1 (place exited)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (departed entity)\": \"man in brown vest and black hat\", \"Arg1 (place exited)\": \"dark blue car\", \"Scene of the Event\": \"inside a vehicle by the side of the road\"}}'}]},\n",
       " {'id': 'v_i5jTH89HjTA_seg_70_80_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_i5jTH89HjTA_seg_70_80.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"close (shut)\", \"roles\": {\"1\": \"Arg0 (person doing the closing)\", \"2\": \"Arg1 (thing closing)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (person doing the closing)\": \"man in brown vest and black hat\", \"Arg1 (thing closing)\": \"car door\", \"ArgM (location)\": \"beside a vehicle by the side of the road\", \"ArgM (manner)\": \"clumsily\"}}'}]},\n",
       " {'id': 'v_i5jTH89HjTA_seg_70_80_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_i5jTH89HjTA_seg_70_80.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"run (walk quickly, a course or contest)\", \"roles\": {\"1\": \"Arg0 (runner)\", \"2\": \"Arg1 (course, race, distance)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (goal)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (runner)\": \"man in brown vest and black hat\", \"Arg1 (course, race, distance)\": \"road\", \"ArgM (direction)\": \"along the side of the car\", \"ArgM (goal)\": \"to change his position\", \"Scene of the Event\": \"beside a vehicle by the side of the road\"}}'}]},\n",
       " {'id': 'v_bDAdgXd7Znk_seg_100_110_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bDAdgXd7Znk_seg_100_110.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shoot (propel projectile)\", \"roles\": {\"1\": \"Arg0 (shooter)\", \"2\": \"Arg1 (projectile)\", \"3\": \"Arg2 (target)\", \"4\": \"ArgM (direction)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shooter)\": \"hanging soldier\", \"Arg1 (projectile)\": \"bullet\", \"Arg2 (target)\": \"people next to brick wall\", \"ArgM (direction)\": \"down\", \"Scene of the Event\": \"open brick building\"}}'}]},\n",
       " {'id': 'v_bDAdgXd7Znk_seg_100_110_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bDAdgXd7Znk_seg_100_110.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cut (slice)\", \"roles\": {\"1\": \"Arg0 (cutter)\", \"2\": \"Arg1 (thing cut)\", \"3\": \"Arg2 (medium, source)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cutter)\": \"man with black beret\", \"Arg1 (thing cut)\": \"two people\", \"Arg2 (medium, source)\": \"knife\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"open brick building\"}}'}]},\n",
       " {'id': 'v_bDAdgXd7Znk_seg_100_110_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bDAdgXd7Znk_seg_100_110.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"toss (throw randomly)\", \"roles\": {\"1\": \"Arg0 (tosser(s))\", \"2\": \"Arg1 (thing tossed)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (tosser(s))\": \"soldier\", \"Arg1 (thing tossed)\": \"gun\", \"ArgM (direction)\": \"towards man in black beret\", \"ArgM (manner)\": \"easily\", \"Scene of the Event\": \"open brick building\"}}'}]},\n",
       " {'id': 'v_bDAdgXd7Znk_seg_100_110_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bDAdgXd7Znk_seg_100_110.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"rush (move quickly)\", \"roles\": {\"1\": \"Arg1 (entity in motion)\", \"2\": \"Arg2 (path or secondary action of arg1)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity in motion)\": \"soldier and man in black beret\", \"Arg2 (path or secondary action of arg1)\": \"through open brick building\", \"ArgM (direction)\": \"next to concrete wall\", \"Scene of the Event\": \"open brick building\"}}'}]},\n",
       " {'id': 'v_bDAdgXd7Znk_seg_100_110_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bDAdgXd7Znk_seg_100_110.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"man in black jacket\", \"Arg2 (hearer)\": \"man in red beret\", \"ArgM (location)\": \"near map\", \"ArgM (manner)\": \"with frustration\"}}'}]},\n",
       " {'id': 'v_k4DsinIrAjQ_seg_35_45_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_k4DsinIrAjQ_seg_35_45.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"read (read)\", \"roles\": {\"1\": \"Arg0 (reader)\", \"2\": \"Arg1 (book)\", \"3\": \"Arg3 (text, content)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (reader)\": \"man in black jacket\", \"Arg1 (book)\": \"folder\", \"Arg3 (text, content)\": \"-\", \"ArgM (location)\": \"office\"}}'}]},\n",
       " {'id': 'v_k4DsinIrAjQ_seg_35_45_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_k4DsinIrAjQ_seg_35_45.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man in black jacket\", \"ArgM (direction)\": \"towards desk\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"office\"}}'}]},\n",
       " {'id': 'v_k4DsinIrAjQ_seg_35_45_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_k4DsinIrAjQ_seg_35_45.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sit (be in a position)\", \"roles\": {\"1\": \"Arg1 (thing sitting)\", \"2\": \"Arg2 (location or position)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing sitting)\": \"man with glasses\", \"Arg2 (location or position)\": \"chair\", \"ArgM (manner)\": \"distracted\"}}'}]},\n",
       " {'id': 'v_k4DsinIrAjQ_seg_35_45_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_k4DsinIrAjQ_seg_35_45.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sit (be in a position)\", \"roles\": {\"1\": \"Arg1 (thing sitting)\", \"2\": \"Arg2 (location or position)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing sitting)\": \"man with glasses\", \"Arg2 (location or position)\": \"chair\", \"ArgM (manner)\": \"distracted\"}}'}]},\n",
       " {'id': 'v_k4DsinIrAjQ_seg_35_45_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_k4DsinIrAjQ_seg_35_45.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"read (read)\", \"roles\": {\"1\": \"Arg0 (reader)\", \"2\": \"Arg1 (book)\", \"3\": \"Arg3 (text, content)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (reader)\": \"man with glasses\", \"Arg1 (book)\": \"folder\", \"Arg3 (text, content)\": \"-\", \"ArgM (location)\": \"chair\"}}'}]},\n",
       " {'id': 'v_n0QO2xOuqp0_seg_75_85_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_n0QO2xOuqp0_seg_75_85.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fire (fire a gun)\", \"roles\": {\"1\": \"Arg0 (shooter)\", \"2\": \"Arg1 (gun)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shooter)\": \"many men wearing black\", \"Arg1 (gun)\": \"fire guns\", \"ArgM (direction)\": \"towards two men in red suits\", \"Scene of the Event\": \"on a city street at night\"}}'}]},\n",
       " {'id': 'v_n0QO2xOuqp0_seg_75_85_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_n0QO2xOuqp0_seg_75_85.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fire (fire a gun)\", \"roles\": {\"1\": \"Arg0 (shooter)\", \"2\": \"Arg1 (gun)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shooter)\": \"many men wearing black\", \"Arg1 (gun)\": \"fire guns\", \"ArgM (direction)\": \"towards two men in red suits\", \"Scene of the Event\": \"on a city street at night\"}}'}]},\n",
       " {'id': 'v_n0QO2xOuqp0_seg_75_85_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_n0QO2xOuqp0_seg_75_85.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"run (walk quickly, a course or contest)\", \"roles\": {\"1\": \"Arg0 (runner)\", \"2\": \"Arg1 (course, race, distance)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (goal)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (runner)\": \"two men in red suits\", \"Arg1 (course, race, distance)\": \"run up a set of stairs\", \"ArgM (direction)\": \"towards a metal gate\", \"ArgM (goal)\": \"to get away from the pursuing men with guns\", \"Scene of the Event\": \"on a city street at night\"}}'}]},\n",
       " {'id': 'v_n0QO2xOuqp0_seg_75_85_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_n0QO2xOuqp0_seg_75_85.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"open (open)\", \"roles\": {\"1\": \"Arg0 (opener)\", \"2\": \"Arg1 (thing opening)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (opener)\": \"two men in red suits\", \"Arg1 (thing opening)\": \"open a metal gate\", \"ArgM (manner)\": \"in a hurry\", \"Scene of the Event\": \"outside of a building at night\"}}'}]},\n",
       " {'id': 'v_n0QO2xOuqp0_seg_75_85_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_n0QO2xOuqp0_seg_75_85.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"close (shut)\", \"roles\": {\"1\": \"Arg0 (person doing the closing)\", \"2\": \"Arg1 (thing closing)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (person doing the closing)\": \"two men in red suits\", \"Arg1 (thing closing)\": \"close the metal gate\", \"ArgM (location)\": \"behind them\", \"ArgM (manner)\": \"while locking it\"}}'}]},\n",
       " {'id': 'v_r5ia1XDzIAU_seg_95_105_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_r5ia1XDzIAU_seg_95_105.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"kiss (smooch)\", \"roles\": {\"1\": \"Arg0 (kisser)\", \"2\": \"Arg1 (kissed)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (kisser)\": \"woman on black jacket\", \"Arg1 (kissed)\": \"man on black suit\", \"ArgM (location)\": \"on his lips\", \"ArgM (manner)\": \"quickly\"}}'}]},\n",
       " {'id': 'v_r5ia1XDzIAU_seg_95_105_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_r5ia1XDzIAU_seg_95_105.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"woman on black jacket\", \"ArgM (direction)\": \"down the cliff\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"on a cliff\"}}'}]},\n",
       " {'id': 'v_r5ia1XDzIAU_seg_95_105_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_r5ia1XDzIAU_seg_95_105.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"kick (drive or impel with the foot)\", \"roles\": {\"1\": \"Arg0 (kicker)\", \"2\": \"Arg1 (thing kicked)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (kicker)\": \"woman on black jacket\", \"Arg1 (thing kicked)\": \"man on black suit\", \"ArgM (direction)\": \"towards his groin\", \"ArgM (location)\": \"in the groin\", \"ArgM (manner)\": \"angrily\"}}'}]},\n",
       " {'id': 'v_r5ia1XDzIAU_seg_95_105_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_r5ia1XDzIAU_seg_95_105.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hit (strike)\", \"roles\": {\"1\": \"Arg0 (agent, hitter - animate only!)\", \"2\": \"Arg1 (thing hit)\", \"3\": \"Arg2 (instrument, thing hit by or with)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (agent, hitter - animate only!)\": \"woman on black jacket\", \"Arg1 (thing hit)\": \"man on black suit\", \"Arg2 (instrument, thing hit by or with)\": \"her fist\", \"ArgM (location)\": \"on his face\", \"ArgM (manner)\": \"angrily\"}}'}]},\n",
       " {'id': 'v_r5ia1XDzIAU_seg_95_105_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_r5ia1XDzIAU_seg_95_105.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"push ((try to) cause motion)\", \"roles\": {\"1\": \"Arg0 (pusher)\", \"2\": \"Arg1 (thing pushed)\", \"3\": \"Arg2 (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (pusher)\": \"woman on black jacket\", \"Arg1 (thing pushed)\": \"man on black suit\", \"Arg2 (direction)\": \"down\", \"ArgM (manner)\": \"angrily\", \"Scene of the Event\": \"on a cliff\"}}'}]},\n",
       " {'id': 'v_P6PLrI4R4x4_seg_40_50_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_P6PLrI4R4x4_seg_40_50.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pursue (follow, chase)\", \"roles\": {\"1\": \"Arg0 (thing following)\", \"2\": \"Arg1 (thing followed)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (thing following)\": \"two old men in hats\", \"Arg1 (thing followed)\": \"a white and brown dog\", \"Scene of the Event\": \"in an alley\"}}'}]},\n",
       " {'id': 'v_P6PLrI4R4x4_seg_40_50_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_P6PLrI4R4x4_seg_40_50.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"flee (run away (from))\", \"roles\": {\"1\": \"Arg0 (fleer, runner)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (fleer, runner)\": \"a white and brown dog\", \"Scene of the Event\": \"in an alley\"}}'}]},\n",
       " {'id': 'v_P6PLrI4R4x4_seg_40_50_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_P6PLrI4R4x4_seg_40_50.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"swagger (walk with excessive confidence)\", \"roles\": {\"1\": \"Arg0 (walker, swaggerer)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker, swaggerer)\": \"a white and brown dog\", \"ArgM (direction)\": \"toward a bin on a corner\", \"Scene of the Event\": \"in an alley\"}}'}]},\n",
       " {'id': 'v_P6PLrI4R4x4_seg_40_50_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_P6PLrI4R4x4_seg_40_50.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"trundle (move ungracefully)\", \"roles\": {\"1\": \"Arg0 (entity in motion)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity in motion)\": \"two old men in hats\", \"ArgM (direction)\": \"toward the white and brown dog\", \"Scene of the Event\": \"in an alley\"}}'}]},\n",
       " {'id': 'v_P6PLrI4R4x4_seg_40_50_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_P6PLrI4R4x4_seg_40_50.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"duck (to evade a responsibility or an object)\", \"roles\": {\"1\": \"Arg0 (evader)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (evader)\": \"a white and brown dog\", \"ArgM (direction)\": \"over a staircase\", \"Scene of the Event\": \"in an alley\"}}'}]},\n",
       " {'id': 'v_XnvMGSn4KHQ_seg_50_60_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XnvMGSn4KHQ_seg_50_60.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"struggle (struggle)\", \"roles\": {\"1\": \"Arg0 (first struggler)\", \"2\": \"Arg1 (second struggler)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (first struggler)\": \"man with blood on his face\", \"Arg1 (second struggler)\": \"against his bindings\", \"ArgM (manner)\": \"surreptitiously\", \"Scene of the Event\": \"in a torture chair\"}}'}]},\n",
       " {'id': 'v_XnvMGSn4KHQ_seg_50_60_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XnvMGSn4KHQ_seg_50_60.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man with blood on his face\", \"Arg1 (thing looked at or for or on)\": \"at his torturer\", \"ArgM (direction)\": \"up\", \"ArgM (manner)\": \"with fear\", \"Scene of the Event\": \"in a torture chair\"}}'}]},\n",
       " {'id': 'v_XnvMGSn4KHQ_seg_50_60_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XnvMGSn4KHQ_seg_50_60.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"soldier in uniform\", \"ArgM (direction)\": \"toward man with blood on his face\", \"ArgM (manner)\": \"slowly\", \"Scene of the Event\": \"in a barn\"}}'}]},\n",
       " {'id': 'v_XnvMGSn4KHQ_seg_50_60_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XnvMGSn4KHQ_seg_50_60.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man with blood on his face\", \"Arg1 (looked at)\": \"soldier in uniform\", \"ArgM (direction)\": \"up\", \"ArgM (manner)\": \"with fear and hatred\", \"Scene of the Event\": \"in a torture chair\"}}'}]},\n",
       " {'id': 'v_XnvMGSn4KHQ_seg_50_60_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XnvMGSn4KHQ_seg_50_60.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"soldier in uniform\", \"ArgM (direction)\": \"toward man with blood on his face\", \"ArgM (manner)\": \"slowly\", \"Scene of the Event\": \"in a barn\"}}'}]},\n",
       " {'id': 'v_XnvMGSn4KHQ_seg_60_70_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XnvMGSn4KHQ_seg_60_70.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man in uniform\", \"ArgM (direction)\": \"walks towards man in brown shirt\", \"ArgM (manner)\": \"slowly\", \"Scene of the Event\": \"in a dark open wood structure\"}}'}]},\n",
       " {'id': 'v_XnvMGSn4KHQ_seg_60_70_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XnvMGSn4KHQ_seg_60_70.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"approach (move towards)\", \"roles\": {\"1\": \"Arg1 (entity in motion)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity in motion)\": \"man in uniform\", \"Arg2 (destination)\": \"approaches man in brown shirt\", \"ArgM (direction)\": \"in front of him\", \"ArgM (manner)\": \"while staring at him wordlessly\", \"Scene of the Event\": \"in a dark open wood structure\"}}'}]},\n",
       " {'id': 'v_XnvMGSn4KHQ_seg_60_70_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XnvMGSn4KHQ_seg_60_70.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"drink (ingest liquids)\", \"roles\": {\"1\": \"Arg0 (drinker)\", \"2\": \"Arg1 (liquid)\", \"3\": \"Arg2 (source of liquid)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (drinker)\": \"man in uniform\", \"Arg1 (liquid)\": \"drinks something\", \"Arg2 (source of liquid)\": \"from a flask\", \"ArgM (manner)\": \"while standing next to man in brown shirt\", \"Scene of the Event\": \"in a dark open wood structure\"}}'}]},\n",
       " {'id': 'v_XnvMGSn4KHQ_seg_60_70_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XnvMGSn4KHQ_seg_60_70.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"drink (ingest liquids)\", \"roles\": {\"1\": \"Arg0 (drinker)\", \"2\": \"Arg1 (liquid)\", \"3\": \"Arg2 (source of liquid)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (drinker)\": \"man in uniform\", \"Arg1 (liquid)\": \"drinks something\", \"Arg2 (source of liquid)\": \"from a flask\", \"ArgM (manner)\": \"while standing next to man in brown shirt\", \"Scene of the Event\": \"in a dark open wood structure\"}}'}]},\n",
       " {'id': 'v_XnvMGSn4KHQ_seg_60_70_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XnvMGSn4KHQ_seg_60_70.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man in uniform\", \"Arg1 (thing looked at or for or on)\": \"looks at man in brown shirt\", \"ArgM (direction)\": \"to his side\", \"ArgM (manner)\": \"while putting the lid back on his flask\", \"Scene of the Event\": \"in a dark open wood structure\"}}'}]},\n",
       " {'id': 'v_aIBT3l54BAg_seg_80_90_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_aIBT3l54BAg_seg_80_90.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"struggle (struggle)\", \"roles\": {\"1\": \"Arg0 (first struggler)\", \"2\": \"Arg1 (second struggler)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (first struggler)\": \"two men in suits\", \"Arg1 (second struggler)\": \"-\", \"ArgM (manner)\": \"while force into the air by the woman in black dress\", \"Scene of the Event\": \"in a hallway\"}}'}]},\n",
       " {'id': 'v_aIBT3l54BAg_seg_80_90_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_aIBT3l54BAg_seg_80_90.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hoist (lift, raise)\", \"roles\": {\"1\": \"Arg0 (lifter, raiser)\", \"2\": \"Arg1 (thing going up)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (lifter, raiser)\": \"woman in black dress\", \"Arg1 (thing going up)\": \"a metal briefcase\", \"ArgM (direction)\": \"up to her arms\", \"Scene of the Event\": \"in a hallway\"}}'}]},\n",
       " {'id': 'v_aIBT3l54BAg_seg_80_90_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_aIBT3l54BAg_seg_80_90.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"give (transfer)\", \"roles\": {\"1\": \"Arg0 (giver)\", \"2\": \"Arg1 (thing given)\", \"3\": \"Arg2 (entity given to)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (giver)\": \"woman in black dress\", \"Arg1 (thing given)\": \"a metal briefcase\", \"Arg2 (entity given to)\": \"man in black jacket\", \"Scene of the Event\": \"in a hallway\"}}'}]},\n",
       " {'id': 'v_aIBT3l54BAg_seg_80_90_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_aIBT3l54BAg_seg_80_90.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"roll (move in circular fashion)\", \"roles\": {\"1\": \"Arg0 (roller)\", \"2\": \"Arg1 (thing rolled or rolling)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (roller)\": \"woman in black dress\", \"Arg1 (thing rolled or rolling)\": \"an unconscious man\", \"ArgM (direction)\": \"onto his back\", \"Scene of the Event\": \"in a hallway\"}}'}]},\n",
       " {'id': 'v_aIBT3l54BAg_seg_80_90_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_aIBT3l54BAg_seg_80_90.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"thrust (to push quickly and forcibly)\", \"roles\": {\"1\": \"Arg0 (agent, causer)\", \"2\": \"Arg1 (entity pushed)\", \"3\": \"Arg2 (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, causer)\": \"woman in black dress\", \"Arg1 (entity pushed)\": \"her hands\", \"Arg2 (direction)\": \"into the unconscious man\\'s belly wound\", \"Scene of the Event\": \"in a hallway\"}}'}]},\n",
       " {'id': 'v_NSsW9EXadik_seg_30_40_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NSsW9EXadik_seg_30_40.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"open (open)\", \"roles\": {\"1\": \"Arg0 (opener)\", \"2\": \"Arg1 (thing opening)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (opener)\": \"man with long dark blonde hair\", \"Arg1 (thing opening)\": \"metal gate\", \"ArgM (manner)\": \"jerkily with his left hand\", \"Scene of the Event\": \"dusty compound\"}}'}]},\n",
       " {'id': 'v_NSsW9EXadik_seg_30_40_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NSsW9EXadik_seg_30_40.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pass (go by)\", \"roles\": {\"1\": \"Arg1 (thing passing)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg1 (thing passing)\": \"man with long dark blonde hair\", \"ArgM (direction)\": \"out through\", \"ArgM (location)\": \"the metal gate\"}}'}]},\n",
       " {'id': 'v_NSsW9EXadik_seg_30_40_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NSsW9EXadik_seg_30_40.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"approach (move towards)\", \"roles\": {\"1\": \"Arg1 (entity in motion)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity in motion)\": \"man with long dark blonde hair\", \"Arg2 (destination)\": \"the woman crouching by the wall\", \"ArgM (direction)\": \"from the front\", \"ArgM (manner)\": \"fast to help her\", \"Scene of the Event\": \"dusty compound\"}}'}]},\n",
       " {'id': 'v_NSsW9EXadik_seg_30_40_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NSsW9EXadik_seg_30_40.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"crouch (to bend forward)\", \"roles\": {\"1\": \"Arg0 (entity crouching)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (entity crouching)\": \"man with long dark blonde hair\", \"ArgM (direction)\": \"down\", \"ArgM (location)\": \"in front of the woman\"}}'}]},\n",
       " {'id': 'v_NSsW9EXadik_seg_30_40_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NSsW9EXadik_seg_30_40.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"slap (hit with a flat object)\", \"roles\": {\"1\": \"Arg0 (agent, hitter - animate only!)\", \"2\": \"Arg1 (thing hit)\", \"3\": \"Arg2 (instrument, thing hit by or with)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (agent, hitter - animate only!)\": \"man with long dark blonde hair\", \"Arg1 (thing hit)\": \"the woman crouching by the wall\", \"Arg2 (instrument, thing hit by or with)\": \"his left hand\", \"ArgM (direction)\": \"upside\", \"ArgM (location)\": \"the right side of her head\"}}'}]},\n",
       " {'id': 'v_GKAPU5e7miY_seg_100_110_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_GKAPU5e7miY_seg_100_110.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"man with gun\", \"Arg2 (hearer)\": \"speaks to man with brown hair\", \"ArgM (location)\": \"in front of him\", \"ArgM (manner)\": \"while pointing his gun at him\"}}'}]},\n",
       " {'id': 'v_GKAPU5e7miY_seg_100_110_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_GKAPU5e7miY_seg_100_110.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"release (let go)\", \"roles\": {\"1\": \"Arg0 (releaser)\", \"2\": \"Arg1 (thing released)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (releaser)\": \"man with brown hair\", \"Arg1 (thing released)\": \"releases grip on wounded person\", \"Scene of the Event\": \"during a flashback in a hospital\"}}'}]},\n",
       " {'id': 'v_GKAPU5e7miY_seg_100_110_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_GKAPU5e7miY_seg_100_110.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"reach (stretch, grasp)\", \"roles\": {\"1\": \"Arg0 (reacher)\", \"2\": \"Arg1 (body part)\", \"3\": \"Arg2 (goal)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (purpose)\", \"6\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (reacher)\": \"man with brown hair\", \"Arg1 (body part)\": \"reaches his arm\", \"Arg2 (goal)\": \"towards the wounded person\", \"ArgM (direction)\": \"out\", \"ArgM (purpose)\": \"to try to reach them in vain\", \"Scene of the Event\": \"during a flashback in a hospital\"}}'}]},\n",
       " {'id': 'v_GKAPU5e7miY_seg_100_110_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_GKAPU5e7miY_seg_100_110.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man with brown hair\", \"Arg1 (looked at)\": \"stares at man with gun\", \"ArgM (direction)\": \"in front of him\", \"ArgM (manner)\": \"with eyes narrowed\", \"Scene of the Event\": \"in a dark location\"}}'}]},\n",
       " {'id': 'v_GKAPU5e7miY_seg_100_110_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_GKAPU5e7miY_seg_100_110.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"turn (rotation)\", \"roles\": {\"1\": \"Arg0 (turner)\", \"2\": \"Arg1 (thing turning)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (purpose)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (turner)\": \"man with gun\", \"Arg1 (thing turning)\": \"turns himself\", \"ArgM (direction)\": \"around\", \"ArgM (purpose)\": \"to shoot at someone in the distance\", \"Scene of the Event\": \"in a dark location\"}}'}]},\n",
       " {'id': 'v_GKAPU5e7miY_seg_115_125_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_GKAPU5e7miY_seg_115_125.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"brandish (wave weapons)\", \"roles\": {\"1\": \"Arg0 (waver, agent)\", \"2\": \"Arg1 (weapon)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (waver, agent)\": \"man in black jacket\", \"Arg1 (weapon)\": \"pistol\", \"Scene of the Event\": \"dark room\"}}'}]},\n",
       " {'id': 'v_GKAPU5e7miY_seg_115_125_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_GKAPU5e7miY_seg_115_125.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fall (move downward)\", \"roles\": {\"1\": \"Arg1 (Logical subject, patient, thing falling)\", \"2\": \"Arg3 (start point)\", \"3\": \"Arg4 (end point, end state of arg1)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (manner)\", \"6\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (Logical subject, patient, thing falling)\": \"man in black jacket\", \"Arg3 (start point)\": \"dark room\", \"Arg4 (end point, end state of arg1)\": \"-\", \"ArgM (direction)\": \"down\", \"ArgM (manner)\": \"frightening\", \"Scene of the Event\": \"dark room\"}}'}]},\n",
       " {'id': 'v_GKAPU5e7miY_seg_115_125_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_GKAPU5e7miY_seg_115_125.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fall (move downward)\", \"roles\": {\"1\": \"Arg1 (Logical subject, patient, thing falling)\", \"2\": \"Arg3 (start point)\", \"3\": \"Arg4 (end point, end state of arg1)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (manner)\", \"6\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (Logical subject, patient, thing falling)\": \"man in black jacket\", \"Arg3 (start point)\": \"dark room\", \"Arg4 (end point, end state of arg1)\": \"_\", \"ArgM (direction)\": \"down\", \"ArgM (manner)\": \"frightening\", \"Scene of the Event\": \"dark room\"}}'}]},\n",
       " {'id': 'v_GKAPU5e7miY_seg_115_125_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_GKAPU5e7miY_seg_115_125.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shock (surprise)\", \"roles\": {\"1\": \"Arg1 (person surprised)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (person surprised)\": \"man in flannel shirt\", \"Scene of the Event\": \"dark room\"}}'}]},\n",
       " {'id': 'v_GKAPU5e7miY_seg_115_125_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_GKAPU5e7miY_seg_115_125.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shock (surprise)\", \"roles\": {\"1\": \"Arg1 (person surprised)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (person surprised)\": \"man in flannel shirt\", \"Scene of the Event\": \"dark room\"}}'}]},\n",
       " {'id': 'v_bKWBb1_NJe8_seg_10_20_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bKWBb1_NJe8_seg_10_20.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"disgruntle (upset, annoy)\", \"roles\": {\"1\": \"Arg1 (disgruntled entity)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (disgruntled entity)\": \"man with blonde hair\", \"Scene of the Event\": \"on a rooftop\"}}'}]},\n",
       " {'id': 'v_bKWBb1_NJe8_seg_10_20_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bKWBb1_NJe8_seg_10_20.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"confuse ((cause to) be confused)\", \"roles\": {\"1\": \"Arg1 (entity experiencing confusion)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity experiencing confusion)\": \"girl with blonde hair\", \"Scene of the Event\": \"on a rooftop\"}}'}]},\n",
       " {'id': 'v_bKWBb1_NJe8_seg_10_20_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bKWBb1_NJe8_seg_10_20.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hit (strike)\", \"roles\": {\"1\": \"Arg0 (agent, hitter - animate only!)\", \"2\": \"Arg1 (thing hit)\", \"3\": \"Arg2 (instrument, thing hit by or with)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (agent, hitter - animate only!)\": \"man with blonde hair\", \"Arg1 (thing hit)\": \"guy in red suit\", \"Arg2 (instrument, thing hit by or with)\": \"a chair\", \"ArgM (location)\": \"in the body\", \"ArgM (manner)\": \"violently\"}}'}]},\n",
       " {'id': 'v_bKWBb1_NJe8_seg_10_20_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bKWBb1_NJe8_seg_10_20.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"struggle (struggle)\", \"roles\": {\"1\": \"Arg0 (first struggler)\", \"2\": \"Arg1 (second struggler)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (first struggler)\": \"man with blonde hair\", \"Arg1 (second struggler)\": \"guy in red suit\", \"ArgM (manner)\": \"to get his gun out\", \"Scene of the Event\": \"on a rooftop\"}}'}]},\n",
       " {'id': 'v_bKWBb1_NJe8_seg_10_20_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bKWBb1_NJe8_seg_10_20.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hit (strike)\", \"roles\": {\"1\": \"Arg0 (agent, hitter - animate only!)\", \"2\": \"Arg1 (thing hit)\", \"3\": \"Arg2 (instrument, thing hit by or with)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (agent, hitter - animate only!)\": \"man with blonde hair\", \"Arg1 (thing hit)\": \"guy in red suit\", \"Arg2 (instrument, thing hit by or with)\": \"his elbow\", \"ArgM (location)\": \"in the face\", \"ArgM (manner)\": \"violently\"}}'}]},\n",
       " {'id': 'v_bKWBb1_NJe8_seg_75_85_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bKWBb1_NJe8_seg_75_85.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"swim (move through water)\", \"roles\": {\"1\": \"Arg0 (swimmer)\", \"2\": \"Arg1 (course)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (swimmer)\": \"man in beige suit\", \"Arg1 (course)\": \"swimming pool\", \"ArgM (direction)\": \"towards the edge\", \"ArgM (location)\": \"swimming pool\"}}'}]},\n",
       " {'id': 'v_bKWBb1_NJe8_seg_75_85_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bKWBb1_NJe8_seg_75_85.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"swim (move through water)\", \"roles\": {\"1\": \"Arg0 (swimmer)\", \"2\": \"Arg1 (course)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (swimmer)\": \"man in beige suit\", \"Arg1 (course)\": \"swimming pool\", \"ArgM (direction)\": \"towards the edge\", \"ArgM (location)\": \"swimming pool\"}}'}]},\n",
       " {'id': 'v_bKWBb1_NJe8_seg_75_85_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bKWBb1_NJe8_seg_75_85.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"watch (look at)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"man in dark suit\", \"Arg1 (thing looked at)\": \"scene in front of him\", \"ArgM (manner)\": \"peeking around the corner\", \"Scene of the Event\": \"hotel\"}}'}]},\n",
       " {'id': 'v_bKWBb1_NJe8_seg_75_85_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bKWBb1_NJe8_seg_75_85.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"watch (look at)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"man in dark suit\", \"Arg1 (thing looked at)\": \"scene in front of him\", \"ArgM (manner)\": \"peeking around the corner\", \"Scene of the Event\": \"hotel\"}}'}]},\n",
       " {'id': 'v_bKWBb1_NJe8_seg_75_85_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bKWBb1_NJe8_seg_75_85.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shoot (propel projectile)\", \"roles\": {\"1\": \"Arg0 (shooter)\", \"2\": \"Arg1 (projectile)\", \"3\": \"Arg2 (target)\", \"4\": \"ArgM (direction)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shooter)\": \"man in beige suit\", \"Arg1 (projectile)\": \"bullets\", \"Arg2 (target)\": \"man in dark coat\", \"ArgM (direction)\": \"across the pool area\", \"Scene of the Event\": \"hotel\"}}'}]},\n",
       " {'id': 'v_aGE--b9ilhk_seg_160_170_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_aGE--b9ilhk_seg_160_170.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"woman in white scrubs\", \"Arg1 (thing looked at or for or on)\": \"floor\", \"ArgM (direction)\": \"down\", \"ArgM (manner)\": \"slowly\", \"Scene of the Event\": \"dressing room\"}}'}]},\n",
       " {'id': 'v_aGE--b9ilhk_seg_160_170_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_aGE--b9ilhk_seg_160_170.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"tie (bind with rope (eg))\", \"roles\": {\"1\": \"Arg0 (tie-er)\", \"2\": \"Arg1 (tied)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (tie-er)\": \"woman with hairnet\", \"Arg1 (tied)\": \"black shirt\", \"ArgM (location)\": \"dressing room\"}}'}]},\n",
       " {'id': 'v_aGE--b9ilhk_seg_160_170_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_aGE--b9ilhk_seg_160_170.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"tie (bind with rope (eg))\", \"roles\": {\"1\": \"Arg0 (tie-er)\", \"2\": \"Arg1 (tied)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (tie-er)\": \"woman with hairnet\", \"Arg1 (tied)\": \"black shirt\", \"ArgM (location)\": \"dressing room\"}}'}]},\n",
       " {'id': 'v_aGE--b9ilhk_seg_160_170_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_aGE--b9ilhk_seg_160_170.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"tie (bind with rope (eg))\", \"roles\": {\"1\": \"Arg0 (tie-er)\", \"2\": \"Arg1 (tied)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (tie-er)\": \"woman with hairnet\", \"Arg1 (tied)\": \"black shirt\", \"ArgM (location)\": \"dressing room\"}}'}]},\n",
       " {'id': 'v_aGE--b9ilhk_seg_160_170_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_aGE--b9ilhk_seg_160_170.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"crouch (to bend forward)\", \"roles\": {\"1\": \"Arg0 (entity crouching)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (entity crouching)\": \"woman with hairnet\", \"ArgM (direction)\": \"down\", \"ArgM (location)\": \"dressing room\"}}'}]},\n",
       " {'id': 'v_11Kv8mnxdCM_seg_35_45_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_11Kv8mnxdCM_seg_35_45.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"do (act)\", \"roles\": {\"1\": \"Arg0 (agent, doer)\", \"2\": \"Arg1 (thing done)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, doer)\": \"man with brown hair\", \"Arg1 (thing done)\": \"gnaws on baby corn\", \"Scene of the Event\": \"in a front of a pink bar\"}}'}]},\n",
       " {'id': 'v_11Kv8mnxdCM_seg_35_45_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_11Kv8mnxdCM_seg_35_45.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"do (act)\", \"roles\": {\"1\": \"Arg0 (agent, doer)\", \"2\": \"Arg1 (thing done)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, doer)\": \"man with brown hair\", \"Arg1 (thing done)\": \"gnaws on baby corn\", \"Scene of the Event\": \"in a front of a pink bar\"}}'}]},\n",
       " {'id': 'v_11Kv8mnxdCM_seg_35_45_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_11Kv8mnxdCM_seg_35_45.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"chew (masticate)\", \"roles\": {\"1\": \"Arg0 (chewer)\", \"2\": \"Arg1 (food)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (chewer)\": \"man with brown hair\", \"Arg1 (food)\": \"chews baby corn\", \"Scene of the Event\": \"in a front of a pink bar\"}}'}]},\n",
       " {'id': 'v_11Kv8mnxdCM_seg_35_45_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_11Kv8mnxdCM_seg_35_45.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"chew (masticate)\", \"roles\": {\"1\": \"Arg0 (chewer)\", \"2\": \"Arg1 (food)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (chewer)\": \"man with brown hair\", \"Arg1 (food)\": \"chews baby corn\", \"Scene of the Event\": \"in a front of a pink bar\"}}'}]},\n",
       " {'id': 'v_11Kv8mnxdCM_seg_35_45_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_11Kv8mnxdCM_seg_35_45.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"do (act)\", \"roles\": {\"1\": \"Arg0 (agent, doer)\", \"2\": \"Arg1 (thing done)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, doer)\": \"man with brown hair\", \"Arg1 (thing done)\": \"gnaws on baby corn\", \"Scene of the Event\": \"in a front of a pink bar\"}}'}]},\n",
       " {'id': 'v_gIQWTB6lNlw_seg_40_50_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gIQWTB6lNlw_seg_40_50.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"instruct (impel action)\", \"roles\": {\"1\": \"Arg1 (impelled agent)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (impelled agent)\": \"A balder man\", \"Scene of the Event\": \"on a bridge\"}}'}]},\n",
       " {'id': 'v_gIQWTB6lNlw_seg_40_50_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gIQWTB6lNlw_seg_40_50.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hold (grasp, bear, keep)\", \"roles\": {\"1\": \"Arg0 (holder)\", \"2\": \"Arg1 (thing held)\", \"3\": \"Arg2 (benefactive)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (location)\", \"6\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (holder)\": \"The bald man\", \"Arg1 (thing held)\": \"the arms\", \"Arg2 (benefactive)\": \"of a man with a beard\", \"ArgM (direction)\": \"dangling\", \"ArgM (location)\": \"over a three-headed shark\", \"ArgM (manner)\": \"in peril\"}}'}]},\n",
       " {'id': 'v_gIQWTB6lNlw_seg_40_50_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gIQWTB6lNlw_seg_40_50.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"grab (to capture, obtain)\", \"roles\": {\"1\": \"Arg0 (grabber)\", \"2\": \"Arg1 (entity grabbed)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (grabber)\": \"A man in orange\", \"Arg1 (entity grabbed)\": \"the bars\", \"ArgM (location)\": \"of the bridge\", \"ArgM (manner)\": \"with effort\"}}'}]},\n",
       " {'id': 'v_gIQWTB6lNlw_seg_40_50_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gIQWTB6lNlw_seg_40_50.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"grunt (speak gruntingly)\", \"roles\": {\"1\": \"Arg0 (speaker)\", \"2\": \"ArgM (manner)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (speaker)\": \"The man with the beard\", \"ArgM (manner)\": \"scared\", \"Scene of the Event\": \"on the bridge\"}}'}]},\n",
       " {'id': 'v_gIQWTB6lNlw_seg_40_50_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gIQWTB6lNlw_seg_40_50.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"yell (to cry out loudly)\", \"roles\": {\"1\": \"Arg0 (Yeller)\", \"2\": \"Arg2 (Hearer)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Yeller)\": \"The man in orange\", \"Arg2 (Hearer)\": \"the man with the beard\", \"Scene of the Event\": \"on the bridge\"}}'}]},\n",
       " {'id': 'v_uQLeZO2Z1YQ_seg_75_85_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_uQLeZO2Z1YQ_seg_75_85.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shoot (propel projectile)\", \"roles\": {\"1\": \"Arg0 (shooter)\", \"2\": \"Arg1 (projectile)\", \"3\": \"Arg2 (target)\", \"4\": \"ArgM (direction)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shooter)\": \"blond man\", \"Arg1 (projectile)\": \"a red ball of energy\", \"Arg2 (target)\": \"man in blue outfit\", \"ArgM (direction)\": \"towards man in blue outfit\", \"Scene of the Event\": \"in a desert\"}}'}]},\n",
       " {'id': 'v_uQLeZO2Z1YQ_seg_75_85_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_uQLeZO2Z1YQ_seg_75_85.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shoot (propel projectile)\", \"roles\": {\"1\": \"Arg0 (shooter)\", \"2\": \"Arg1 (projectile)\", \"3\": \"Arg2 (target)\", \"4\": \"ArgM (direction)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shooter)\": \"blond man\", \"Arg1 (projectile)\": \"a red ball of energy\", \"Arg2 (target)\": \"man in blue outfit\", \"ArgM (direction)\": \"towards man in blue outfit\", \"Scene of the Event\": \"in a desert\"}}'}]},\n",
       " {'id': 'v_uQLeZO2Z1YQ_seg_75_85_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_uQLeZO2Z1YQ_seg_75_85.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shoot (propel projectile)\", \"roles\": {\"1\": \"Arg0 (shooter)\", \"2\": \"Arg1 (projectile)\", \"3\": \"Arg2 (target)\", \"4\": \"ArgM (direction)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shooter)\": \"blond man\", \"Arg1 (projectile)\": \"a red ball of energy\", \"Arg2 (target)\": \"man in blue outfit\", \"ArgM (direction)\": \"towards man in blue outfit\", \"Scene of the Event\": \"in a desert\"}}'}]},\n",
       " {'id': 'v_uQLeZO2Z1YQ_seg_75_85_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_uQLeZO2Z1YQ_seg_75_85.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fly (fly through the air, travel via air)\", \"roles\": {\"1\": \"Arg1 (thing actually doing the flying)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing actually doing the flying)\": \"man in blue outfit\", \"ArgM (direction)\": \"backwards\", \"ArgM (location)\": \"in the air\", \"ArgM (manner)\": \"while being pushed by red balls of energy\"}}'}]},\n",
       " {'id': 'v_uQLeZO2Z1YQ_seg_75_85_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_uQLeZO2Z1YQ_seg_75_85.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"collapse (fall down)\", \"roles\": {\"1\": \"Arg1 (thing collapsing)\", \"2\": \"ArgM (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing collapsing)\": \"man in blue outfit\", \"ArgM (location)\": \"onto the ground\", \"ArgM (manner)\": \"slowly\"}}'}]},\n",
       " {'id': 'v_6RbMqRpNqmY_seg_85_95_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_6RbMqRpNqmY_seg_85_95.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"charge (walk quickly)\", \"roles\": {\"1\": \"Arg0 (runner)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (runner)\": \"a trans woman in a red dress\", \"ArgM (direction)\": \"across the room\", \"Scene of the Event\": \"in a house\"}}'}]},\n",
       " {'id': 'v_6RbMqRpNqmY_seg_85_95_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_6RbMqRpNqmY_seg_85_95.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"enter (enter, go in)\", \"roles\": {\"1\": \"Arg0 (entity entering)\", \"2\": \"Arg1 (place or thing entered)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity entering)\": \"a man in a gold and black coat\", \"Arg1 (place or thing entered)\": \"into a room\", \"ArgM (manner)\": \"with his hands clasped together\", \"Scene of the Event\": \"in a house\"}}'}]},\n",
       " {'id': 'v_6RbMqRpNqmY_seg_85_95_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_6RbMqRpNqmY_seg_85_95.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pick (select from a group)\", \"roles\": {\"1\": \"Arg0 (picker)\", \"2\": \"Arg1 (thing picked)\", \"3\": \"Arg2 (group or source)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (picker)\": \"a trans woman in a red dress\", \"Arg1 (thing picked)\": \"a snack\", \"Arg2 (group or source)\": \"from a bowl\", \"ArgM (location)\": \"on a table\", \"ArgM (manner)\": \"gently\"}}'}]},\n",
       " {'id': 'v_6RbMqRpNqmY_seg_85_95_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_6RbMqRpNqmY_seg_85_95.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"a trans woman in a red dress\", \"Arg1 (looked at)\": \"the approaching man in a gold and black coat\", \"ArgM (direction)\": \"ahead\", \"ArgM (manner)\": \"wordlessly\", \"Scene of the Event\": \"in a house\"}}'}]},\n",
       " {'id': 'v_6RbMqRpNqmY_seg_85_95_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_6RbMqRpNqmY_seg_85_95.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"touch (be or come in(to) contact with)\", \"roles\": {\"1\": \"Arg0 (causal agent)\", \"2\": \"Arg1 (thing touched)\", \"3\": \"Arg2 (touched with, if separate from agent)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causal agent)\": \"a man in a gold and black coat\", \"Arg1 (thing touched)\": \"a piece of cloth on trans woman in a red dress\\'s eye\", \"Arg2 (touched with, if separate from agent)\": \"his fingers\", \"ArgM (manner)\": \"gently\", \"Scene of the Event\": \"in a house\"}}'}]},\n",
       " {'id': 'v_Vcgn4EY5_S8_seg_90_100_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Vcgn4EY5_S8_seg_90_100.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hit (strike)\", \"roles\": {\"1\": \"Arg0 (agent, hitter - animate only!)\", \"2\": \"Arg1 (thing hit)\", \"3\": \"Arg2 (instrument, thing hit by or with)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (agent, hitter - animate only!)\": \"woman in tan\", \"Arg1 (thing hit)\": \"ground\", \"Arg2 (instrument, thing hit by or with)\": \"sword\", \"ArgM (location)\": \"dirt field\", \"ArgM (manner)\": \"aggressively\"}}'}]},\n",
       " {'id': 'v_Vcgn4EY5_S8_seg_90_100_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Vcgn4EY5_S8_seg_90_100.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"strike (hit)\", \"roles\": {\"1\": \"Arg0 (agent, hitter - animate only!)\", \"2\": \"Arg1 (thing hit)\", \"3\": \"Arg2 (instrument, thing hit by or with)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, hitter - animate only!)\": \"woman in tan\", \"Arg1 (thing hit)\": \"ground\", \"Arg2 (instrument, thing hit by or with)\": \"sword\", \"Scene of the Event\": \"dirt field\"}}'}]},\n",
       " {'id': 'v_Vcgn4EY5_S8_seg_90_100_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Vcgn4EY5_S8_seg_90_100.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"strike (hit)\", \"roles\": {\"1\": \"Arg0 (agent, hitter - animate only!)\", \"2\": \"Arg1 (thing hit)\", \"3\": \"Arg2 (instrument, thing hit by or with)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, hitter - animate only!)\": \"woman in tan\", \"Arg1 (thing hit)\": \"car door\", \"Arg2 (instrument, thing hit by or with)\": \"sword\", \"Scene of the Event\": \"dirt field\"}}'}]},\n",
       " {'id': 'v_Vcgn4EY5_S8_seg_90_100_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Vcgn4EY5_S8_seg_90_100.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hoist (lift, raise)\", \"roles\": {\"1\": \"Arg0 (lifter, raiser)\", \"2\": \"Arg1 (thing going up)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (lifter, raiser)\": \"woman in tan\", \"Arg1 (thing going up)\": \"car door\", \"ArgM (direction)\": \"upwards\", \"Scene of the Event\": \"dirt field\"}}'}]},\n",
       " {'id': 'v_Vcgn4EY5_S8_seg_90_100_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Vcgn4EY5_S8_seg_90_100.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fall (move downward)\", \"roles\": {\"1\": \"Arg1 (Logical subject, patient, thing falling)\", \"2\": \"Arg3 (start point)\", \"3\": \"Arg4 (end point, end state of arg1)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (manner)\", \"6\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (Logical subject, patient, thing falling)\": \"woman in tan\", \"Arg3 (start point)\": \"in air\", \"Arg4 (end point, end state of arg1)\": \"ground\", \"ArgM (direction)\": \"downward\", \"ArgM (manner)\": \"violently\", \"Scene of the Event\": \"dirt field\"}}'}]},\n",
       " {'id': 'v_I7XHygPKbYI_seg_20_30_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_I7XHygPKbYI_seg_20_30.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"approach (move towards)\", \"roles\": {\"1\": \"Arg1 (entity in motion)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity in motion)\": \"the lady holding the knife\", \"Arg2 (destination)\": \"to approach the lady in pains\", \"ArgM (direction)\": \"downwards\", \"ArgM (manner)\": \"slowly\", \"Scene of the Event\": \"in the house\"}}'}]},\n",
       " {'id': 'v_I7XHygPKbYI_seg_20_30_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_I7XHygPKbYI_seg_20_30.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hurt (be experiencing pain)\", \"roles\": {\"1\": \"Arg1 (patient, entity experiencing pain)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (patient, entity experiencing pain)\": \"the lady on the floor\", \"Scene of the Event\": \"in the house\"}}'}]},\n",
       " {'id': 'v_I7XHygPKbYI_seg_20_30_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_I7XHygPKbYI_seg_20_30.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hurt (be experiencing pain)\", \"roles\": {\"1\": \"Arg1 (patient, entity experiencing pain)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (patient, entity experiencing pain)\": \"the lady on the floor\", \"Scene of the Event\": \"in the house\"}}'}]},\n",
       " {'id': 'v_I7XHygPKbYI_seg_20_30_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_I7XHygPKbYI_seg_20_30.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"the lady on the floor\", \"Arg1 (looked at)\": \"the lady holding the knife\", \"ArgM (direction)\": \"upward\", \"ArgM (manner)\": \"scared\", \"Scene of the Event\": \"in the house\"}}'}]},\n",
       " {'id': 'v_I7XHygPKbYI_seg_20_30_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_I7XHygPKbYI_seg_20_30.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"terrify (scare very badly)\", \"roles\": {\"1\": \"Arg1 (terrified entity)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (terrified entity)\": \"the lady on the floor\", \"Scene of the Event\": \"in the house\"}}'}]},\n",
       " {'id': 'v_vuvmITfWFuo_seg_105_115_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_vuvmITfWFuo_seg_105_115.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"notice (become aware of)\", \"roles\": {\"1\": \"Arg0 (noticer)\", \"2\": \"Arg1 (noticed)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (noticer)\": \"the girl gnome with the red hat on\", \"Arg1 (noticed)\": \"the gnome with the green hat on running towards the edge\", \"ArgM (location)\": \"atop a building\"}}'}]},\n",
       " {'id': 'v_vuvmITfWFuo_seg_105_115_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_vuvmITfWFuo_seg_105_115.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"jump (physically or metaphorically leap)\", \"roles\": {\"1\": \"Arg0 (jumper)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (jumper)\": \"the gnome with the green hat on\", \"ArgM (direction)\": \"off the building\", \"Scene of the Event\": \"to the road down below\"}}'}]},\n",
       " {'id': 'v_vuvmITfWFuo_seg_105_115_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_vuvmITfWFuo_seg_105_115.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"observe (look at, mark)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"the girl gnome with the red hat on\", \"Arg1 (thing looked at)\": \"the gnome with the green hat on parachute down\", \"Scene of the Event\": \"to the top of a vehicle\"}}'}]},\n",
       " {'id': 'v_vuvmITfWFuo_seg_105_115_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_vuvmITfWFuo_seg_105_115.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"jump (physically or metaphorically leap)\", \"roles\": {\"1\": \"Arg0 (jumper)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (jumper)\": \"the girl gnome with the red hat on\", \"ArgM (direction)\": \"towards the moving vehicle\", \"Scene of the Event\": \"off the building\"}}'}]},\n",
       " {'id': 'v_vuvmITfWFuo_seg_105_115_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_vuvmITfWFuo_seg_105_115.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"track (follow)\", \"roles\": {\"1\": \"Arg0 (thing following)\", \"2\": \"Arg1 (thing followed)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (thing following)\": \"the gnomes with the blue hats on\", \"Arg1 (thing followed)\": \"the girl gnome with the red hat on\", \"Scene of the Event\": \"towards the moving vehicle\"}}'}]},\n",
       " {'id': 'v_07mbIgWikmQ_seg_20_30_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_07mbIgWikmQ_seg_20_30.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man in jeans\", \"ArgM (direction)\": \"down a path in the forest\", \"ArgM (manner)\": \"with a child on his back\", \"Scene of the Event\": \"the forest\"}}'}]},\n",
       " {'id': 'v_07mbIgWikmQ_seg_20_30_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_07mbIgWikmQ_seg_20_30.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"tail (follow)\", \"roles\": {\"1\": \"Arg0 (follower, tailer)\", \"2\": \"Arg1 (followed, tailed)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (follower, tailer)\": \"woman with ponytail\", \"Arg1 (followed, tailed)\": \"man in jeans\", \"ArgM (location)\": \"the forest\"}}'}]},\n",
       " {'id': 'v_07mbIgWikmQ_seg_20_30_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_07mbIgWikmQ_seg_20_30.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"graze ((allow to) eat grass)\", \"roles\": {\"1\": \"Arg0 (cow)\", \"2\": \"Arg1 (grass, pasture)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cow)\": \"small animals\", \"Arg1 (grass, pasture)\": \"a dirt area\", \"Scene of the Event\": \"the forest\"}}'}]},\n",
       " {'id': 'v_07mbIgWikmQ_seg_20_30_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_07mbIgWikmQ_seg_20_30.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"graze ((allow to) eat grass)\", \"roles\": {\"1\": \"Arg0 (cow)\", \"2\": \"Arg1 (grass, pasture)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cow)\": \"small animals\", \"Arg1 (grass, pasture)\": \"a dirt area\", \"Scene of the Event\": \"the forest\"}}'}]},\n",
       " {'id': 'v_07mbIgWikmQ_seg_20_30_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_07mbIgWikmQ_seg_20_30.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man in jeans\", \"ArgM (direction)\": \"down a path in the forest\", \"ArgM (manner)\": \"with a child on his back\", \"Scene of the Event\": \"the forest\"}}'}]},\n",
       " {'id': 'v_h_JeXTLSCQk_seg_0_10_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_h_JeXTLSCQk_seg_0_10.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"attend (belong with or at)\", \"roles\": {\"1\": \"Arg0 (thing attending)\", \"2\": \"Arg1 (thing attended)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (thing attending)\": \"Woman\", \"Arg1 (thing attended)\": \"Child\", \"Scene of the Event\": \"Kitchen\"}}'}]},\n",
       " {'id': 'v_h_JeXTLSCQk_seg_0_10_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_h_JeXTLSCQk_seg_0_10.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"attend (belong with or at)\", \"roles\": {\"1\": \"Arg0 (thing attending)\", \"2\": \"Arg1 (thing attended)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (thing attending)\": \"Woman\", \"Arg1 (thing attended)\": \"Child\", \"Scene of the Event\": \"Kitchen\"}}'}]},\n",
       " {'id': 'v_h_JeXTLSCQk_seg_0_10_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_h_JeXTLSCQk_seg_0_10.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"breathe (suck air)\", \"roles\": {\"1\": \"Arg0 (breather)\", \"2\": \"Arg1 (air, we hope)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (breather)\": \"Child\", \"Arg1 (air, we hope)\": \"Air\", \"ArgM (manner)\": \"Labored\", \"Scene of the Event\": \"Kitchen\"}}'}]},\n",
       " {'id': 'v_h_JeXTLSCQk_seg_0_10_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_h_JeXTLSCQk_seg_0_10.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"check (examine)\", \"roles\": {\"1\": \"Arg0 (checker)\", \"2\": \"Arg1 (thing checked)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (checker)\": \"Woman\", \"Arg1 (thing checked)\": \"Child\", \"ArgM (location)\": \"Kitchen\"}}'}]},\n",
       " {'id': 'v_h_JeXTLSCQk_seg_0_10_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_h_JeXTLSCQk_seg_0_10.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"check (examine)\", \"roles\": {\"1\": \"Arg0 (checker)\", \"2\": \"Arg1 (thing checked)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (checker)\": \"Woman\", \"Arg1 (thing checked)\": \"Child\", \"ArgM (location)\": \"Kitchen\"}}'}]},\n",
       " {'id': 'v__nmYaR_ZllQ_seg_5_15_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__nmYaR_ZllQ_seg_5_15.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"close (shut)\", \"roles\": {\"1\": \"Arg0 (person doing the closing)\", \"2\": \"Arg1 (thing closing)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (person doing the closing)\": \"woman in black jacket\", \"Arg1 (thing closing)\": \"a refrigerator door\", \"ArgM (location)\": \"behind her\", \"ArgM (manner)\": \"quickly\"}}'}]},\n",
       " {'id': 'v__nmYaR_ZllQ_seg_5_15_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__nmYaR_ZllQ_seg_5_15.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in black sweater\", \"Arg2 (hearer)\": \"woman in black jacket\", \"ArgM (manner)\": \"while seated\", \"Scene of the Event\": \"in an apartment\"}}'}]},\n",
       " {'id': 'v__nmYaR_ZllQ_seg_5_15_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__nmYaR_ZllQ_seg_5_15.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"woman in black jacket\", \"ArgM (direction)\": \"towards man in black sweater\", \"ArgM (manner)\": \"slowly\", \"Scene of the Event\": \"in an apartment\"}}'}]},\n",
       " {'id': 'v__nmYaR_ZllQ_seg_5_15_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__nmYaR_ZllQ_seg_5_15.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"step (move incrementally)\", \"roles\": {\"1\": \"Arg1 (thing moving)\", \"2\": \"Arg2 (destination, end state)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (thing moving)\": \"woman in black jacket\", \"Arg2 (destination, end state)\": \"near man in black sweater\", \"ArgM (direction)\": \"towards man in black sweater\", \"ArgM (manner)\": \"slowly\", \"Scene of the Event\": \"in an apartment\"}}'}]},\n",
       " {'id': 'v__nmYaR_ZllQ_seg_5_15_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__nmYaR_ZllQ_seg_5_15.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in black sweater\", \"Arg2 (hearer)\": \"woman in black jacket\", \"ArgM (manner)\": \"while face to face\", \"Scene of the Event\": \"in an apartment\"}}'}]},\n",
       " {'id': 'v_G9VI6SExDms_seg_5_15_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_G9VI6SExDms_seg_5_15.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sip (to drink in small quantities )\", \"roles\": {\"1\": \"Arg0 (drinker, agent)\", \"2\": \"Arg1 (drink)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (drinker, agent)\": \"man in purple suit jacket sitting in purple chair\", \"Arg1 (drink)\": \"wine\", \"Scene of the Event\": \"reception room\"}}'}]},\n",
       " {'id': 'v_G9VI6SExDms_seg_5_15_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_G9VI6SExDms_seg_5_15.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"woman in black and red shirt\", \"Arg1 (looked at)\": \"people sitting and eating in another area\", \"ArgM (direction)\": \"forward\", \"ArgM (manner)\": \"annoyed\", \"Scene of the Event\": \"talent area\"}}'}]},\n",
       " {'id': 'v_G9VI6SExDms_seg_5_15_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_G9VI6SExDms_seg_5_15.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"turn (rotation)\", \"roles\": {\"1\": \"Arg0 (turner)\", \"2\": \"Arg1 (thing turning)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (purpose)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (turner)\": \"woman in black and red shirt\", \"Arg1 (thing turning)\": \"her body\", \"ArgM (direction)\": \"around\", \"ArgM (purpose)\": \"focused\", \"Scene of the Event\": \"talent area\"}}'}]},\n",
       " {'id': 'v_G9VI6SExDms_seg_5_15_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_G9VI6SExDms_seg_5_15.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"woman in black and red shirt\", \"ArgM (direction)\": \"forward\", \"ArgM (manner)\": \"focused\", \"Scene of the Event\": \"talent area\"}}'}]},\n",
       " {'id': 'v_G9VI6SExDms_seg_5_15_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_G9VI6SExDms_seg_5_15.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"ready (prepare)\", \"roles\": {\"1\": \"Arg0 (preparer)\", \"2\": \"Arg1 (thing made ready)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (preparer)\": \"woman in black and red shirt\", \"Arg1 (thing made ready)\": \"starting her bow stance\", \"Scene of the Event\": \"talent area\"}}'}]},\n",
       " {'id': 'v_G9VI6SExDms_seg_25_35_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_G9VI6SExDms_seg_25_35.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"draw (pull)\", \"roles\": {\"1\": \"Arg0 (puller)\", \"2\": \"Arg1 (thing pulled)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (puller)\": \"woman with bow\", \"Arg1 (thing pulled)\": \"bow\", \"ArgM (direction)\": \"target\", \"Scene of the Event\": \"large building\"}}'}]},\n",
       " {'id': 'v_G9VI6SExDms_seg_25_35_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_G9VI6SExDms_seg_25_35.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"observe (look at, mark)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"man with hair slicked back\", \"Arg1 (thing looked at)\": \"woman with bow\", \"Scene of the Event\": \"large building\"}}'}]},\n",
       " {'id': 'v_G9VI6SExDms_seg_25_35_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_G9VI6SExDms_seg_25_35.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"release (let go)\", \"roles\": {\"1\": \"Arg0 (releaser)\", \"2\": \"Arg1 (thing released)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (releaser)\": \"woman with bow\", \"Arg1 (thing released)\": \"arrow\", \"Scene of the Event\": \"large building\"}}'}]},\n",
       " {'id': 'v_G9VI6SExDms_seg_25_35_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_G9VI6SExDms_seg_25_35.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"smile (to have or form a smile)\", \"roles\": {\"1\": \"Arg0 (agent smiling)\", \"2\": \"Arg2 (smiled at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent smiling)\": \"man with black hair\", \"Arg2 (smiled at)\": \"target\", \"ArgM (manner)\": \"amused\", \"Scene of the Event\": \"large building\"}}'}]},\n",
       " {'id': 'v_G9VI6SExDms_seg_25_35_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_G9VI6SExDms_seg_25_35.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"observe (look at, mark)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"woman with bow\", \"Arg1 (thing looked at)\": \"target\", \"Scene of the Event\": \"large building\"}}'}]},\n",
       " {'id': 'v_zE2-th0lNbg_seg_15_25_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_zE2-th0lNbg_seg_15_25.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lean (to incline or cause to incline)\", \"roles\": {\"1\": \"Arg0 (causer of leaning)\", \"2\": \"Arg2 (direction)\", \"3\": \"ArgM (purpose)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of leaning)\": \"man in plaid coat\", \"Arg2 (direction)\": \"over\", \"ArgM (purpose)\": \"to let man remove tag\", \"Scene of the Event\": \"woods\"}}'}]},\n",
       " {'id': 'v_zE2-th0lNbg_seg_15_25_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_zE2-th0lNbg_seg_15_25.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"remove (remove)\", \"roles\": {\"1\": \"Arg0 (entity removing)\", \"2\": \"Arg1 (thing being removed)\", \"3\": \"Arg2 (removed from)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity removing)\": \"man in black jacket\", \"Arg1 (thing being removed)\": \"tag\", \"Arg2 (removed from)\": \"mans back\", \"Scene of the Event\": \"woods\"}}'}]},\n",
       " {'id': 'v_zE2-th0lNbg_seg_15_25_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_zE2-th0lNbg_seg_15_25.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man in black jacket\", \"Arg1 (thing looked at or for or on)\": \"tag\", \"ArgM (direction)\": \"down\", \"ArgM (manner)\": \"holding it with one hand\", \"Scene of the Event\": \"woods\"}}'}]},\n",
       " {'id': 'v_zE2-th0lNbg_seg_15_25_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_zE2-th0lNbg_seg_15_25.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hand (give)\", \"roles\": {\"1\": \"Arg0 (giver)\", \"2\": \"Arg1 (thing given)\", \"3\": \"Arg2 (entity given to)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (giver)\": \"man in black jacket\", \"Arg1 (thing given)\": \"tag\", \"Arg2 (entity given to)\": \"man in red coat\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"woods\"}}'}]},\n",
       " {'id': 'v_zE2-th0lNbg_seg_15_25_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_zE2-th0lNbg_seg_15_25.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hand (give)\", \"roles\": {\"1\": \"Arg0 (giver)\", \"2\": \"Arg1 (thing given)\", \"3\": \"Arg2 (entity given to)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (giver)\": \"man in red coat\", \"Arg1 (thing given)\": \"tag\", \"Arg2 (entity given to)\": \"man in trench coat\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"woods\"}}'}]},\n",
       " {'id': 'v_WQXqhk-8h7o_seg_65_75_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WQXqhk-8h7o_seg_65_75.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shout (yell, or announce loudly)\", \"roles\": {\"1\": \"Arg0 (shouter)\", \"2\": \"Arg2 (listener)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shouter)\": \"man in a brown hat\", \"Arg2 (listener)\": \"blonde woman\", \"Scene of the Event\": \"cavernous stone temple\"}}'}]},\n",
       " {'id': 'v_WQXqhk-8h7o_seg_65_75_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WQXqhk-8h7o_seg_65_75.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"flinch (to make a sudden small movement)\", \"roles\": {\"1\": \"Arg0 (entity flinching)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity flinching)\": \"blonde woman\", \"Scene of the Event\": \"cavernous stone temple\"}}'}]},\n",
       " {'id': 'v_WQXqhk-8h7o_seg_65_75_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WQXqhk-8h7o_seg_65_75.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hesitate (hesitate)\", \"roles\": {\"1\": \"Arg0 (hesitator)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (hesitator)\": \"blonde woman\", \"Scene of the Event\": \"cavernous stone temple\"}}'}]},\n",
       " {'id': 'v_WQXqhk-8h7o_seg_65_75_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WQXqhk-8h7o_seg_65_75.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sidle (to walk sideways,ingratiate oneself to)\", \"roles\": {\"1\": \"Arg0 (agent, rider (use only if arg1 is present))\", \"2\": \"Arg1 (path, thing  sidled up to)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, rider (use only if arg1 is present))\": \"blonde woman\", \"Arg1 (path, thing  sidled up to)\": \"the wall covered in scorpions\", \"ArgM (direction)\": \"around\", \"Scene of the Event\": \"cavernous stone temple\"}}'}]},\n",
       " {'id': 'v_WQXqhk-8h7o_seg_65_75_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WQXqhk-8h7o_seg_65_75.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"peer (to look searchingly)\", \"roles\": {\"1\": \"Arg0 (looker, searcher, agent)\", \"2\": \"Arg1 (entity peered into/at/over...)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker, searcher, agent)\": \"blonde woman\", \"Arg1 (entity peered into/at/over...)\": \"a hole in the wall\", \"ArgM (direction)\": \"through\", \"ArgM (manner)\": \"in horror and pain\", \"Scene of the Event\": \"cavernous stone temple\"}}'}]},\n",
       " {'id': 'v_bu9YxTb6gf8_seg_35_45_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bu9YxTb6gf8_seg_35_45.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man with black shirt\", \"Arg2 (hearer)\": \"woman with blonde hair\", \"ArgM (manner)\": \"walking towards her\", \"Scene of the Event\": \"outside some buildings\"}}'}]},\n",
       " {'id': 'v_bu9YxTb6gf8_seg_35_45_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bu9YxTb6gf8_seg_35_45.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man with black shirt\", \"Arg1 (looked at)\": \"woman with blonde hair\", \"ArgM (direction)\": \"in front of him\", \"ArgM (manner)\": \"interested in her\", \"Scene of the Event\": \"outside some buildings\"}}'}]},\n",
       " {'id': 'v_bu9YxTb6gf8_seg_35_45_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bu9YxTb6gf8_seg_35_45.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sing (sing)\", \"roles\": {\"1\": \"Arg0 (singer)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (singer)\": \"man with black shirt\", \"Scene of the Event\": \"outside some buildings\"}}'}]},\n",
       " {'id': 'v_bu9YxTb6gf8_seg_35_45_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bu9YxTb6gf8_seg_35_45.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"smile (to have or form a smile)\", \"roles\": {\"1\": \"Arg0 (agent smiling)\", \"2\": \"Arg2 (smiled at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent smiling)\": \"man with black shirt\", \"Arg2 (smiled at)\": \"woman with blonde hair\", \"ArgM (manner)\": \"trying to impress her\", \"Scene of the Event\": \"outside some buildings\"}}'}]},\n",
       " {'id': 'v_bu9YxTb6gf8_seg_35_45_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bu9YxTb6gf8_seg_35_45.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"leave (move away from)\", \"roles\": {\"1\": \"Arg0 (entity leaving)\", \"2\": \"Arg1 (place, person, or thing left)\", \"3\": \"Arg2 (attribute of arg1)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (entity leaving)\": \"woman with blonde hair\", \"Arg1 (place, person, or thing left)\": \"man with black shirt\", \"Arg2 (attribute of arg1)\": \"on the\", \"ArgM (location)\": \"walkway\"}}'}]},\n",
       " {'id': 'v_bu9YxTb6gf8_seg_45_55_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bu9YxTb6gf8_seg_45_55.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"flee (run away (from))\", \"roles\": {\"1\": \"Arg0 (fleer, runner)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (fleer, runner)\": \"woman with long blonde hair\", \"Scene of the Event\": \"house patio\"}}'}]},\n",
       " {'id': 'v_bu9YxTb6gf8_seg_45_55_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bu9YxTb6gf8_seg_45_55.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shout (yell, or announce loudly)\", \"roles\": {\"1\": \"Arg0 (shouter)\", \"2\": \"Arg2 (listener)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shouter)\": \"man in a dark blue shirt\", \"Arg2 (listener)\": \"woman with long blonde hair\", \"Scene of the Event\": \"house patio\"}}'}]},\n",
       " {'id': 'v_bu9YxTb6gf8_seg_45_55_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bu9YxTb6gf8_seg_45_55.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"taunt (to ridicule)\", \"roles\": {\"1\": \"Arg0 (taunter, agent)\", \"2\": \"Arg1 (entity taunted)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (taunter, agent)\": \"man in a dark blue shirt\", \"Arg1 (entity taunted)\": \"woman with long blonde hair\", \"Scene of the Event\": \"house patio\"}}'}]},\n",
       " {'id': 'v_bu9YxTb6gf8_seg_45_55_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bu9YxTb6gf8_seg_45_55.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"ponder (think about)\", \"roles\": {\"1\": \"Arg0 (thinker)\", \"2\": \"Arg1 (thought)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (thinker)\": \"woman with long blonde hair\", \"Arg1 (thought)\": \"-\", \"Scene of the Event\": \"household kitchen\"}}'}]},\n",
       " {'id': 'v_bu9YxTb6gf8_seg_45_55_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_bu9YxTb6gf8_seg_45_55.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"approach (move towards)\", \"roles\": {\"1\": \"Arg1 (entity in motion)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity in motion)\": \"man in a dark blue shirt\", \"Arg2 (destination)\": \"kitchen doorway\", \"ArgM (direction)\": \"from the outside\", \"ArgM (manner)\": \"with a swagger\", \"Scene of the Event\": \"kitchen and patio\"}}'}]},\n",
       " {'id': 'v_WbFri7eX_YA_seg_80_90_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WbFri7eX_YA_seg_80_90.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"nuzzle (cuddle or snuggle)\", \"roles\": {\"1\": \"Arg0 (hugger)\", \"2\": \"Arg1 (hugged)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (hugger)\": \"the woman with blonde hair\", \"Arg1 (hugged)\": \"the man with black hair\", \"Scene of the Event\": \"in an upstairs room\"}}'}]},\n",
       " {'id': 'v_WbFri7eX_YA_seg_80_90_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WbFri7eX_YA_seg_80_90.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sneak (move stealthily)\", \"roles\": {\"1\": \"Arg0 (entity sneaking)\", \"2\": \"Arg1 (destination)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity sneaking)\": \"the man in the white shirt\", \"Arg1 (destination)\": \"upstairs\", \"Scene of the Event\": \"inside a house\"}}'}]},\n",
       " {'id': 'v_WbFri7eX_YA_seg_80_90_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WbFri7eX_YA_seg_80_90.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sneak (move stealthily)\", \"roles\": {\"1\": \"Arg0 (entity sneaking)\", \"2\": \"Arg1 (destination)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity sneaking)\": \"the man in the white shirt\", \"Arg1 (destination)\": \"upstairs\", \"Scene of the Event\": \"inside a house\"}}'}]},\n",
       " {'id': 'v_WbFri7eX_YA_seg_80_90_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WbFri7eX_YA_seg_80_90.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sneak (move stealthily)\", \"roles\": {\"1\": \"Arg0 (entity sneaking)\", \"2\": \"Arg1 (destination)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity sneaking)\": \"the man in the white shirt\", \"Arg1 (destination)\": \"upstairs\", \"Scene of the Event\": \"inside a house\"}}'}]},\n",
       " {'id': 'v_WbFri7eX_YA_seg_80_90_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WbFri7eX_YA_seg_80_90.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"nuzzle (cuddle or snuggle)\", \"roles\": {\"1\": \"Arg0 (hugger)\", \"2\": \"Arg1 (hugged)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (hugger)\": \"the man with black hair\", \"Arg1 (hugged)\": \"the woman with blonde hair\", \"Scene of the Event\": \"in an upstairs room\"}}'}]},\n",
       " {'id': 'v_V-vgoh3ukPc_seg_80_90_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_V-vgoh3ukPc_seg_80_90.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"woman with dark hair\", \"Arg1 (thing looked at or for or on)\": \"herself\", \"ArgM (direction)\": \"in the chrome wall\", \"ArgM (manner)\": \"looking surprised\", \"Scene of the Event\": \"inside a restaurant\"}}'}]},\n",
       " {'id': 'v_V-vgoh3ukPc_seg_80_90_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_V-vgoh3ukPc_seg_80_90.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"surprise (surprise)\", \"roles\": {\"1\": \"Arg1 (person surprised)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (person surprised)\": \"woman with dark hair\", \"Scene of the Event\": \"inside a restaurant\"}}'}]},\n",
       " {'id': 'v_V-vgoh3ukPc_seg_80_90_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_V-vgoh3ukPc_seg_80_90.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"observe (look at, mark)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"man with beard\", \"Arg1 (thing looked at)\": \"woman with dark hair\", \"Scene of the Event\": \"inside a restaurant\"}}'}]},\n",
       " {'id': 'v_V-vgoh3ukPc_seg_80_90_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_V-vgoh3ukPc_seg_80_90.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"trouble (upset slightly)\", \"roles\": {\"1\": \"Arg1 (experiencer, one upset)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (experiencer, one upset)\": \"woman with dark hair\", \"Scene of the Event\": \"inside a restaurant\"}}'}]},\n",
       " {'id': 'v_V-vgoh3ukPc_seg_80_90_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_V-vgoh3ukPc_seg_80_90.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"turn (rotation)\", \"roles\": {\"1\": \"Arg0 (turner)\", \"2\": \"Arg1 (thing turning)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (purpose)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (turner)\": \"woman with dark hair\", \"Arg1 (thing turning)\": \"her head\", \"ArgM (direction)\": \"to the left\", \"ArgM (purpose)\": \"looking at all the people inside\", \"Scene of the Event\": \"restuarant\"}}'}]},\n",
       " {'id': 'v_V-vgoh3ukPc_seg_95_105_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_V-vgoh3ukPc_seg_95_105.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"charge (walk quickly)\", \"roles\": {\"1\": \"Arg0 (runner)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (runner)\": \"girl in the green striped shirt\", \"ArgM (direction)\": \"towards the trash station\", \"Scene of the Event\": \"spacious coffee shop\"}}'}]},\n",
       " {'id': 'v_V-vgoh3ukPc_seg_95_105_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_V-vgoh3ukPc_seg_95_105.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"do (act)\", \"roles\": {\"1\": \"Arg0 (agent, doer)\", \"2\": \"Arg1 (thing done)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, doer)\": \"girl in the green striped shirt\", \"Arg1 (thing done)\": \"squats down behind the trash station door\", \"Scene of the Event\": \"spacious coffee shop\"}}'}]},\n",
       " {'id': 'v_V-vgoh3ukPc_seg_95_105_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_V-vgoh3ukPc_seg_95_105.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"proffer (offer, give)\", \"roles\": {\"1\": \"Arg0 (giver)\", \"2\": \"Arg1 (thing given)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (giver)\": \"girl in the green striped shirt\", \"Arg1 (thing given)\": \"small easily concealed item\", \"Scene of the Event\": \"spacious coffee shop\"}}'}]},\n",
       " {'id': 'v_V-vgoh3ukPc_seg_95_105_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_V-vgoh3ukPc_seg_95_105.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"point (point at, define, make an example of)\", \"roles\": {\"1\": \"Arg0 (pointer)\", \"2\": \"Arg1 (pointed at)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (pointer)\": \"girl in the green striped shirt\", \"Arg1 (pointed at)\": \"-\", \"ArgM (direction)\": \"off in the distance\", \"Scene of the Event\": \"spacious coffee shop\"}}'}]},\n",
       " {'id': 'v_V-vgoh3ukPc_seg_95_105_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_V-vgoh3ukPc_seg_95_105.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"doff (remove)\", \"roles\": {\"1\": \"Arg0 (remover)\", \"2\": \"Arg1 (clothing removed)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (remover)\": \"girl in the green striped shirt\", \"Arg1 (clothing removed)\": \"her sunglasses\", \"Scene of the Event\": \"spacious coffee shop\"}}'}]},\n",
       " {'id': 'v_lPrOstRqB1o_seg_65_75_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_lPrOstRqB1o_seg_65_75.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"girl\", \"Arg2 (hearer)\": \"guy\", \"ArgM (manner)\": \"matter-of-factly\", \"Scene of the Event\": \"empty school cafeteria\"}}'}]},\n",
       " {'id': 'v_lPrOstRqB1o_seg_65_75_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_lPrOstRqB1o_seg_65_75.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"watch (look at)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"girl\", \"Arg1 (thing looked at)\": \"guy\", \"ArgM (manner)\": \"to see how he walks\", \"Scene of the Event\": \"empty school cafeteria\"}}'}]},\n",
       " {'id': 'v_lPrOstRqB1o_seg_65_75_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_lPrOstRqB1o_seg_65_75.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"watch (look at)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"girl\", \"Arg1 (thing looked at)\": \"guy\", \"ArgM (manner)\": \"to see how he walks\", \"Scene of the Event\": \"empty school cafeteria\"}}'}]},\n",
       " {'id': 'v_lPrOstRqB1o_seg_65_75_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_lPrOstRqB1o_seg_65_75.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"rise (go up)\", \"roles\": {\"1\": \"Arg1 (Logical subject, patient, thing rising)\", \"2\": \"Arg3 (start point)\", \"3\": \"Arg4 (end point)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (Logical subject, patient, thing rising)\": \"girl\", \"Arg3 (start point)\": \"squatting down\", \"Arg4 (end point)\": \"standing up\", \"ArgM (manner)\": \"to practice dancing\", \"Scene of the Event\": \"empty school cafeteria\"}}'}]},\n",
       " {'id': 'v_lPrOstRqB1o_seg_65_75_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_lPrOstRqB1o_seg_65_75.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"move (change location)\", \"roles\": {\"1\": \"Arg1 (moved)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (moved)\": \"girl\", \"Arg2 (destination)\": \"space with room to walk\", \"ArgM (direction)\": \"to the middle of the cafeteria\", \"ArgM (manner)\": \"getting ready to perform\", \"Scene of the Event\": \"empty school cafeteria\"}}'}]},\n",
       " {'id': 'v_SwjKQrYpe-g_seg_160_170_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_SwjKQrYpe-g_seg_160_170.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fight (fight back)\", \"roles\": {\"1\": \"Arg0 (first fighter)\", \"2\": \"Arg1 (second fighter, if separate)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (first fighter)\": \"the man\", \"Arg1 (second fighter, if separate)\": \"the woman\", \"Scene of the Event\": \"battle ground\"}}'}]},\n",
       " {'id': 'v_SwjKQrYpe-g_seg_160_170_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_SwjKQrYpe-g_seg_160_170.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fight (fight back)\", \"roles\": {\"1\": \"Arg0 (first fighter)\", \"2\": \"Arg1 (second fighter, if separate)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (first fighter)\": \"the man\", \"Arg1 (second fighter, if separate)\": \"the woman\", \"Scene of the Event\": \"battle ground\"}}'}]},\n",
       " {'id': 'v_SwjKQrYpe-g_seg_160_170_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_SwjKQrYpe-g_seg_160_170.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fight (fight back)\", \"roles\": {\"1\": \"Arg0 (first fighter)\", \"2\": \"Arg1 (second fighter, if separate)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (first fighter)\": \"the man\", \"Arg1 (second fighter, if separate)\": \"the woman\", \"Scene of the Event\": \"battle ground\"}}'}]},\n",
       " {'id': 'v_SwjKQrYpe-g_seg_160_170_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_SwjKQrYpe-g_seg_160_170.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fight (fight back)\", \"roles\": {\"1\": \"Arg0 (first fighter)\", \"2\": \"Arg1 (second fighter, if separate)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (first fighter)\": \"the man\", \"Arg1 (second fighter, if separate)\": \"the woman\", \"Scene of the Event\": \"battle ground\"}}'}]},\n",
       " {'id': 'v_SwjKQrYpe-g_seg_160_170_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_SwjKQrYpe-g_seg_160_170.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fight (fight back)\", \"roles\": {\"1\": \"Arg0 (first fighter)\", \"2\": \"Arg1 (second fighter, if separate)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (first fighter)\": \"the man\", \"Arg1 (second fighter, if separate)\": \"the woman\", \"Scene of the Event\": \"battle ground\"}}'}]},\n",
       " {'id': 'v_V2weMKLFJLo_seg_25_35_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_V2weMKLFJLo_seg_25_35.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"protest (object to something)\", \"roles\": {\"1\": \"Arg0 (protester)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (protester)\": \"group of people attacking car with sign and jumping on hood\", \"Scene of the Event\": \"outside\"}}'}]},\n",
       " {'id': 'v_V2weMKLFJLo_seg_25_35_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_V2weMKLFJLo_seg_25_35.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man in tan rain coat drinking coffee and blonde haired woman\", \"Arg1 (thing looked at or for or on)\": \"group of people attacking car with sign and jumping on hood\", \"ArgM (direction)\": \"forward\", \"ArgM (manner)\": \"curious\", \"Scene of the Event\": \"outside\"}}'}]},\n",
       " {'id': 'v_V2weMKLFJLo_seg_25_35_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_V2weMKLFJLo_seg_25_35.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"discuss (talk about)\", \"roles\": {\"1\": \"Arg0 (discussant)\", \"2\": \"Arg1 (topic)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (discussant)\": \"man in tan rain coat drinking coffee and blonde haired woman\", \"Arg1 (topic)\": \"group of people attacking car with sign and jumping on hood\", \"Scene of the Event\": \"outside\"}}'}]},\n",
       " {'id': 'v_V2weMKLFJLo_seg_25_35_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_V2weMKLFJLo_seg_25_35.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"yank (pull roughly)\", \"roles\": {\"1\": \"Arg0 (puller)\", \"2\": \"Arg1 (thing pulled)\", \"3\": \"Arg2 (source)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (puller)\": \"Man in tan jacket near protectors\", \"Arg1 (thing pulled)\": \"man in green jacket off hood of car\", \"Arg2 (source)\": \"off the hood\", \"Scene of the Event\": \"outside\"}}'}]},\n",
       " {'id': 'v_V2weMKLFJLo_seg_25_35_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_V2weMKLFJLo_seg_25_35.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"confront (to engage in confrontation)\", \"roles\": {\"1\": \"Arg0 (confrontational entity, agent)\", \"2\": \"Arg1 (entity confronted)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (confrontational entity, agent)\": \"Man in tan jacket near protectors\", \"Arg1 (entity confronted)\": \"person in car\", \"Scene of the Event\": \"outside\"}}'}]},\n",
       " {'id': 'v_eTGHFj1kdsI_seg_45_55_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_eTGHFj1kdsI_seg_45_55.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"turn (rotation)\", \"roles\": {\"1\": \"Arg0 (turner)\", \"2\": \"Arg1 (thing turning)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (purpose)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (turner)\": \"woman in white shirt\", \"Arg1 (thing turning)\": \"turns herself\", \"ArgM (direction)\": \"around\", \"ArgM (purpose)\": \"to leave room\", \"Scene of the Event\": \"in a kitchen\"}}'}]},\n",
       " {'id': 'v_eTGHFj1kdsI_seg_45_55_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_eTGHFj1kdsI_seg_45_55.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"woman in white shirt\", \"ArgM (direction)\": \"walks into a bedroom\", \"ArgM (manner)\": \"along with bearded man\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_eTGHFj1kdsI_seg_45_55_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_eTGHFj1kdsI_seg_45_55.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"set (put, place)\", \"roles\": {\"1\": \"Arg0 (agent, setter)\", \"2\": \"Arg1 (thing set)\", \"3\": \"Arg2 (location or position)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (agent, setter)\": \"woman in white shirt\", \"Arg1 (thing set)\": \"sets her bag down\", \"Arg2 (location or position)\": \"on the bed\", \"ArgM (manner)\": \"with one hand\"}}'}]},\n",
       " {'id': 'v_eTGHFj1kdsI_seg_45_55_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_eTGHFj1kdsI_seg_45_55.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lean (to incline or cause to incline)\", \"roles\": {\"1\": \"Arg0 (causer of leaning)\", \"2\": \"Arg2 (direction)\", \"3\": \"ArgM (purpose)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of leaning)\": \"woman in white shirt\", \"Arg2 (direction)\": \"leans forward\", \"ArgM (purpose)\": \"to support herself on the bed\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_eTGHFj1kdsI_seg_45_55_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_eTGHFj1kdsI_seg_45_55.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"bearded man\", \"Arg1 (looked at)\": \"stares at woman in white shirt\", \"ArgM (direction)\": \"in front of him\", \"ArgM (manner)\": \"with his hands in his pockets\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_-xSV3MoacUw_seg_85_95_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_-xSV3MoacUw_seg_85_95.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"knock (hit)\", \"roles\": {\"1\": \"Arg0 (agent, hitter - animate only!)\", \"2\": \"Arg1 (thing hit)\", \"3\": \"Arg2 (instrument, thing hit by or with)\", \"4\": \"ArgM (direction)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, hitter - animate only!)\": \"the military personnel\", \"Arg1 (thing hit)\": \"the man wearing the black hat\", \"Arg2 (instrument, thing hit by or with)\": \"his hand\", \"ArgM (direction)\": \"forward\", \"Scene of the Event\": \"outside the building\"}}'}]},\n",
       " {'id': 'v_-xSV3MoacUw_seg_85_95_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_-xSV3MoacUw_seg_85_95.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hurt (be experiencing pain)\", \"roles\": {\"1\": \"Arg1 (patient, entity experiencing pain)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (patient, entity experiencing pain)\": \"the military personnel\", \"Scene of the Event\": \"outside the building\"}}'}]},\n",
       " {'id': 'v_-xSV3MoacUw_seg_85_95_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_-xSV3MoacUw_seg_85_95.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"delight (make happy, direct)\", \"roles\": {\"1\": \"Arg0 (agent, pleaser)\", \"2\": \"Arg1 (patient, entity pleased)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, pleaser)\": \"the military personnel\", \"Arg1 (patient, entity pleased)\": \"the lady wearing the red top\", \"Scene of the Event\": \"outside the building\"}}'}]},\n",
       " {'id': 'v_-xSV3MoacUw_seg_85_95_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_-xSV3MoacUw_seg_85_95.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"kiss (smooch)\", \"roles\": {\"1\": \"Arg0 (kisser)\", \"2\": \"Arg1 (kissed)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (kisser)\": \"the lady wearing the red top\", \"Arg1 (kissed)\": \"the military personnel\", \"ArgM (location)\": \"outside the building\", \"ArgM (manner)\": \"passionately\"}}'}]},\n",
       " {'id': 'v_-xSV3MoacUw_seg_85_95_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_-xSV3MoacUw_seg_85_95.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"kiss (smooch)\", \"roles\": {\"1\": \"Arg0 (kisser)\", \"2\": \"Arg1 (kissed)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (kisser)\": \"the lady wearing the red top\", \"Arg1 (kissed)\": \"the military personnel\", \"ArgM (location)\": \"outside the building\", \"ArgM (manner)\": \"passionately\"}}'}]},\n",
       " {'id': 'v_EIz94vt-Opo_seg_65_75_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_EIz94vt-Opo_seg_65_75.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"dream (dream)\", \"roles\": {\"1\": \"Arg0 (dreamer)\", \"2\": \"Arg1 (dream)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (dreamer)\": \"the girl with the bows in her hair\", \"Arg1 (dream)\": \"something\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_EIz94vt-Opo_seg_65_75_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_EIz94vt-Opo_seg_65_75.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"awake (to wake or make aware)\", \"roles\": {\"1\": \"Arg1 (entity awake)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity awake)\": \"the girl with the bows in her hair\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_EIz94vt-Opo_seg_65_75_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_EIz94vt-Opo_seg_65_75.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"the girl with the bows in her hair\", \"Arg2 (hearer)\": \"the girl without bows in her hair\", \"ArgM (manner)\": \"sleepily\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_EIz94vt-Opo_seg_65_75_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_EIz94vt-Opo_seg_65_75.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"scream (speak very loudly)\", \"roles\": {\"1\": \"Arg0 (screamer)\", \"2\": \"ArgM (manner)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (screamer)\": \"the girl with the bows in her hair\", \"ArgM (manner)\": \"alarmingly\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_EIz94vt-Opo_seg_65_75_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_EIz94vt-Opo_seg_65_75.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"ask (ask a question)\", \"roles\": {\"1\": \"Arg0 (asker)\", \"2\": \"Arg1 (question)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (asker)\": \"the girl without bows in her hair\", \"Arg1 (question)\": \"what was wrong\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_vBasqtPRco0_seg_125_135_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_vBasqtPRco0_seg_125_135.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a blue shirt\", \"Arg2 (hearer)\": \"someone\", \"ArgM (manner)\": \"while smiling and nodding\", \"Scene of the Event\": \"in a studio\"}}'}]},\n",
       " {'id': 'v_vBasqtPRco0_seg_125_135_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_vBasqtPRco0_seg_125_135.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a blue shirt\", \"Arg2 (hearer)\": \"someone\", \"ArgM (manner)\": \"while smiling and nodding\", \"Scene of the Event\": \"in a studio\"}}'}]},\n",
       " {'id': 'v_vBasqtPRco0_seg_125_135_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_vBasqtPRco0_seg_125_135.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"phone (to telephone)\", \"roles\": {\"1\": \"Arg0 (agent making a call)\", \"2\": \"Arg1 (receiver)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent making a call)\": \"man in a white shirt\", \"Arg1 (receiver)\": \"someone\", \"Scene of the Event\": \"in an office\"}}'}]},\n",
       " {'id': 'v_vBasqtPRco0_seg_125_135_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_vBasqtPRco0_seg_125_135.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a light blue shirt\", \"Arg2 (hearer)\": \"someone nearby\", \"ArgM (manner)\": \"while standing up\", \"Scene of the Event\": \"in an office\"}}'}]},\n",
       " {'id': 'v_vBasqtPRco0_seg_125_135_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_vBasqtPRco0_seg_125_135.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"examine (look at closely)\", \"roles\": {\"1\": \"Arg0 (examiner)\", \"2\": \"Arg1 (thing examined)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (examiner)\": \"man in a light blue shirt\", \"Arg1 (thing examined)\": \"a monitor\", \"ArgM (manner)\": \"while leaning forward\", \"Scene of the Event\": \"in an office\"}}'}]},\n",
       " {'id': 'v_sG8uXeC_jNg_seg_135_145_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_sG8uXeC_jNg_seg_135_145.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shoot (kill with gun)\", \"roles\": {\"1\": \"Arg0 (shooter)\", \"2\": \"Arg1 (corpse)\", \"3\": \"Arg2 (gun)\", \"4\": \"ArgM (direction)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shooter)\": \"man with long hair\", \"Arg1 (corpse)\": \"man on a white shirt\", \"Arg2 (gun)\": \"short handgun\", \"ArgM (direction)\": \"towards his chest\", \"Scene of the Event\": \"inside a van\"}}'}]},\n",
       " {'id': 'v_sG8uXeC_jNg_seg_135_145_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_sG8uXeC_jNg_seg_135_145.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shoot (kill with gun)\", \"roles\": {\"1\": \"Arg0 (shooter)\", \"2\": \"Arg1 (corpse)\", \"3\": \"Arg2 (gun)\", \"4\": \"ArgM (direction)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shooter)\": \"man with long hair\", \"Arg1 (corpse)\": \"his leg\", \"Arg2 (gun)\": \"short handgun\", \"ArgM (direction)\": \"on his lap\", \"Scene of the Event\": \"inside a van\"}}'}]},\n",
       " {'id': 'v_sG8uXeC_jNg_seg_135_145_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_sG8uXeC_jNg_seg_135_145.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hurt (be experiencing pain)\", \"roles\": {\"1\": \"Arg1 (patient, entity experiencing pain)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (patient, entity experiencing pain)\": \"man with long hair\", \"Scene of the Event\": \"inside a van\"}}'}]},\n",
       " {'id': 'v_sG8uXeC_jNg_seg_135_145_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_sG8uXeC_jNg_seg_135_145.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"touch (be or come in(to) contact with)\", \"roles\": {\"1\": \"Arg0 (causal agent)\", \"2\": \"Arg1 (thing touched)\", \"3\": \"Arg2 (touched with, if separate from agent)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causal agent)\": \"man with long hair\", \"Arg1 (thing touched)\": \"a person lying inside the van\", \"Arg2 (touched with, if separate from agent)\": \"his hand\", \"ArgM (manner)\": \"painfully\", \"Scene of the Event\": \"inside a van\"}}'}]},\n",
       " {'id': 'v_sG8uXeC_jNg_seg_135_145_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_sG8uXeC_jNg_seg_135_145.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hold (grasp, bear, keep)\", \"roles\": {\"1\": \"Arg0 (holder)\", \"2\": \"Arg1 (thing held)\", \"3\": \"Arg2 (benefactive)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (location)\", \"6\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (holder)\": \"man with long hair\", \"Arg1 (thing held)\": \"a person lying inside the van\", \"Arg2 (benefactive)\": \"...\", \"ArgM (direction)\": \"on the clothes\", \"ArgM (location)\": \"on the clothes\", \"ArgM (manner)\": \"tightly\"}}'}]},\n",
       " {'id': 'v_QJVsS-vIDdc_seg_10_20_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QJVsS-vIDdc_seg_10_20.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"prime (make ready)\", \"roles\": {\"1\": \"Arg1 (thing made ready)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (thing made ready)\": \"man with blood on his face\", \"Scene of the Event\": \"in a war zone\"}}'}]},\n",
       " {'id': 'v_QJVsS-vIDdc_seg_10_20_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QJVsS-vIDdc_seg_10_20.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"throw (throw)\", \"roles\": {\"1\": \"Arg0 (thrower)\", \"2\": \"Arg1 (thing thrown)\", \"3\": \"Arg2 (thrown at, to, over, etc)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (thrower)\": \"man with blood on his face\", \"Arg1 (thing thrown)\": \"a brown object\", \"Arg2 (thrown at, to, over, etc)\": \"soldier with a black hat\", \"ArgM (manner)\": \"soldier with a black hat\", \"Scene of the Event\": \"in a war zone\"}}'}]},\n",
       " {'id': 'v_QJVsS-vIDdc_seg_10_20_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QJVsS-vIDdc_seg_10_20.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hit (strike)\", \"roles\": {\"1\": \"Arg0 (agent, hitter - animate only!)\", \"2\": \"Arg1 (thing hit)\", \"3\": \"Arg2 (instrument, thing hit by or with)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (agent, hitter - animate only!)\": \"man with blood on his face\", \"Arg1 (thing hit)\": \"soldier with a black hat\", \"Arg2 (instrument, thing hit by or with)\": \"a shield\", \"ArgM (location)\": \"on his body\", \"ArgM (manner)\": \"violently\"}}'}]},\n",
       " {'id': 'v_QJVsS-vIDdc_seg_10_20_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QJVsS-vIDdc_seg_10_20.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stab (poke with sharp object,   perhaps fatally)\", \"roles\": {\"1\": \"Arg0 (stabber)\", \"2\": \"Arg1 (thing stabbed)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (stabber)\": \"man with long hair\", \"Arg1 (thing stabbed)\": \"man with yellow vest\", \"Scene of the Event\": \"in a war zone\"}}'}]},\n",
       " {'id': 'v_QJVsS-vIDdc_seg_10_20_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QJVsS-vIDdc_seg_10_20.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"strike (hit)\", \"roles\": {\"1\": \"Arg0 (agent, hitter - animate only!)\", \"2\": \"Arg1 (thing hit)\", \"3\": \"Arg2 (instrument, thing hit by or with)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, hitter - animate only!)\": \"man with long hair\", \"Arg1 (thing hit)\": \"man with yellow vest\", \"Arg2 (instrument, thing hit by or with)\": \"his arm\", \"Scene of the Event\": \"in a war zone\"}}'}]},\n",
       " {'id': 'v_7wSQMwlqy0s_seg_100_110_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_7wSQMwlqy0s_seg_100_110.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"ram (to hit or push with force)\", \"roles\": {\"1\": \"Arg0 (hitter, agent or instrument)\", \"2\": \"Arg1 (entity hit)\", \"3\": \"Arg2 (entity rammed into/against)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (hitter, agent or instrument)\": \"small orange bull with horns\", \"Arg1 (entity hit)\": \"trash cans by the road\", \"Arg2 (entity rammed into/against)\": \"the side\", \"Scene of the Event\": \"front lawn\"}}'}]},\n",
       " {'id': 'v_7wSQMwlqy0s_seg_100_110_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_7wSQMwlqy0s_seg_100_110.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"knock (hit)\", \"roles\": {\"1\": \"Arg0 (agent, hitter - animate only!)\", \"2\": \"Arg1 (thing hit)\", \"3\": \"Arg2 (instrument, thing hit by or with)\", \"4\": \"ArgM (direction)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, hitter - animate only!)\": \"gray bull\", \"Arg1 (thing hit)\": \"midget in a gray hoodie\", \"Arg2 (instrument, thing hit by or with)\": \"with its head\", \"ArgM (direction)\": \"down\", \"Scene of the Event\": \"front lawn\"}}'}]},\n",
       " {'id': 'v_7wSQMwlqy0s_seg_100_110_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_7wSQMwlqy0s_seg_100_110.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"encircle ((cause to) be around)\", \"roles\": {\"1\": \"Arg1 (thing encircling, being around)\", \"2\": \"Arg2 (thing surrounded)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (thing encircling, being around)\": \"gray bull\", \"Arg2 (thing surrounded)\": \"midget in a gray hoodie\", \"Scene of the Event\": \"front lawn\"}}'}]},\n",
       " {'id': 'v_7wSQMwlqy0s_seg_100_110_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_7wSQMwlqy0s_seg_100_110.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"retreat (run away!)\", \"roles\": {\"1\": \"Arg0 (retreater)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (retreater)\": \"gray bull\", \"Scene of the Event\": \"front lawn\"}}'}]},\n",
       " {'id': 'v_7wSQMwlqy0s_seg_100_110_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_7wSQMwlqy0s_seg_100_110.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"retreat (run away!)\", \"roles\": {\"1\": \"Arg0 (retreater)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (retreater)\": \"two men in black\", \"Scene of the Event\": \"front lawn and white wood lattice partition\"}}'}]},\n",
       " {'id': 'v_0mE11Cy_xAo_seg_10_20_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0mE11Cy_xAo_seg_10_20.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"disturb (bother)\", \"roles\": {\"1\": \"Arg0 (disturber)\", \"2\": \"Arg1 (disturbed)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (disturber)\": \"A thought\", \"Arg1 (disturbed)\": \"the lady wearing the black robe\", \"Scene of the Event\": \"in the room\"}}'}]},\n",
       " {'id': 'v_0mE11Cy_xAo_seg_10_20_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0mE11Cy_xAo_seg_10_20.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"disturb (bother)\", \"roles\": {\"1\": \"Arg0 (disturber)\", \"2\": \"Arg1 (disturbed)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (disturber)\": \"A thought\", \"Arg1 (disturbed)\": \"the lady wearing the black robe\", \"Scene of the Event\": \"in the room\"}}'}]},\n",
       " {'id': 'v_0mE11Cy_xAo_seg_10_20_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0mE11Cy_xAo_seg_10_20.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"disturb (bother)\", \"roles\": {\"1\": \"Arg0 (disturber)\", \"2\": \"Arg1 (disturbed)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (disturber)\": \"A thought\", \"Arg1 (disturbed)\": \"the lady wearing the black robe\", \"Scene of the Event\": \"in the room\"}}'}]},\n",
       " {'id': 'v_0mE11Cy_xAo_seg_10_20_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0mE11Cy_xAo_seg_10_20.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"disturb (bother)\", \"roles\": {\"1\": \"Arg0 (disturber)\", \"2\": \"Arg1 (disturbed)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (disturber)\": \"A thought\", \"Arg1 (disturbed)\": \"the lady wearing the black robe\", \"Scene of the Event\": \"in the room\"}}'}]},\n",
       " {'id': 'v_0mE11Cy_xAo_seg_10_20_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0mE11Cy_xAo_seg_10_20.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"disturb (bother)\", \"roles\": {\"1\": \"Arg0 (disturber)\", \"2\": \"Arg1 (disturbed)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (disturber)\": \"A thought\", \"Arg1 (disturbed)\": \"the lady wearing the black robe\", \"Scene of the Event\": \"in the room\"}}'}]},\n",
       " {'id': 'v_kytDzjuBGJI_seg_45_55_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_kytDzjuBGJI_seg_45_55.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"motion (to direct with a gesture)\", \"roles\": {\"1\": \"Arg0 (gesturer)\", \"2\": \"Arg1 (gestured at)\", \"3\": \"Arg2 (for what)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (gesturer)\": \"man in a grey long sleeved t shirt\", \"Arg1 (gestured at)\": \"man in a white vest\", \"Arg2 (for what)\": \"to move very slowly\", \"Scene of the Event\": \"in a dungeon\"}}'}]},\n",
       " {'id': 'v_kytDzjuBGJI_seg_45_55_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_kytDzjuBGJI_seg_45_55.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man in a white vest\", \"Arg1 (looked at)\": \"a huge anaconda\", \"ArgM (direction)\": \"ahead\", \"ArgM (manner)\": \"in shock\", \"Scene of the Event\": \"in a dungeon\"}}'}]},\n",
       " {'id': 'v_kytDzjuBGJI_seg_45_55_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_kytDzjuBGJI_seg_45_55.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"bend ((cause to) form a curve)\", \"roles\": {\"1\": \"Arg0 (bender)\", \"2\": \"Arg1 (thing forming a curve)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (purpose)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (bender)\": \"man in a white vest\", \"Arg1 (thing forming a curve)\": \"his body\", \"ArgM (direction)\": \"down\", \"ArgM (purpose)\": \"to cross under the slithering anaconda\", \"Scene of the Event\": \"in a dungeon\"}}'}]},\n",
       " {'id': 'v_kytDzjuBGJI_seg_45_55_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_kytDzjuBGJI_seg_45_55.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"plod (walk slowly)\", \"roles\": {\"1\": \"Arg0 (walker, plodder)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker, plodder)\": \"man in a white vest\", \"ArgM (direction)\": \"toward the slithering anaconda\", \"Scene of the Event\": \"in a dungeon\"}}'}]},\n",
       " {'id': 'v_kytDzjuBGJI_seg_45_55_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_kytDzjuBGJI_seg_45_55.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"step (move incrementally)\", \"roles\": {\"1\": \"Arg1 (thing moving)\", \"2\": \"Arg2 (destination, end state)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (thing moving)\": \"man in a white vest\", \"Arg2 (destination, end state)\": \"toward the man in a grey long sleeved t shirt\", \"ArgM (direction)\": \"under the slithering anaconda\", \"ArgM (manner)\": \"silently\", \"Scene of the Event\": \"in a dungeon\"}}'}]},\n",
       " {'id': 'v_eVUsVW87kSk_seg_15_25_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_eVUsVW87kSk_seg_15_25.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"remove (remove)\", \"roles\": {\"1\": \"Arg0 (entity removing)\", \"2\": \"Arg1 (thing being removed)\", \"3\": \"Arg2 (removed from)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity removing)\": \"man in tshirt\", \"Arg1 (thing being removed)\": \"jacket\", \"Arg2 (removed from)\": \"his body\", \"Scene of the Event\": \"beach\"}}'}]},\n",
       " {'id': 'v_eVUsVW87kSk_seg_15_25_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_eVUsVW87kSk_seg_15_25.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"kick (drive or impel with the foot)\", \"roles\": {\"1\": \"Arg0 (kicker)\", \"2\": \"Arg1 (thing kicked)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (kicker)\": \"man in tshirt\", \"Arg1 (thing kicked)\": \"man in coat\", \"ArgM (direction)\": \"in\", \"ArgM (location)\": \"the face\", \"ArgM (manner)\": \"violently\"}}'}]},\n",
       " {'id': 'v_eVUsVW87kSk_seg_15_25_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_eVUsVW87kSk_seg_15_25.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"grab (to capture, obtain)\", \"roles\": {\"1\": \"Arg0 (grabber)\", \"2\": \"Arg1 (entity grabbed)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (grabber)\": \"man in coat\", \"Arg1 (entity grabbed)\": \"man in tshirt\", \"ArgM (location)\": \"by the leg\", \"ArgM (manner)\": \"to fight back\"}}'}]},\n",
       " {'id': 'v_eVUsVW87kSk_seg_15_25_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_eVUsVW87kSk_seg_15_25.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"flip (throw, turn over)\", \"roles\": {\"1\": \"Arg0 (flipper, agent)\", \"2\": \"Arg1 (thing flipped)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (flipper, agent)\": \"man in coat\", \"Arg1 (thing flipped)\": \"man in tshirt\", \"ArgM (direction)\": \"away from him\", \"Scene of the Event\": \"beach\"}}'}]},\n",
       " {'id': 'v_eVUsVW87kSk_seg_15_25_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_eVUsVW87kSk_seg_15_25.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"try (Attempt)\", \"roles\": {\"1\": \"Arg0 (Agent/Entity Trying)\", \"2\": \"Arg1 (thing tried)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Agent/Entity Trying)\": \"man in coat\", \"Arg1 (thing tried)\": \"to hurt man in tshirt\", \"ArgM (manner)\": \"with his elbow\", \"Scene of the Event\": \"beach\"}}'}]},\n",
       " {'id': 'v_toctHJpW6no_seg_15_25_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_toctHJpW6no_seg_15_25.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"read (read)\", \"roles\": {\"1\": \"Arg0 (reader)\", \"2\": \"Arg1 (book)\", \"3\": \"Arg3 (text, content)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (reader)\": \"man with light hair\", \"Arg1 (book)\": \"newspaper\", \"Arg3 (text, content)\": \"about a murder\", \"ArgM (location)\": \"in front of him\"}}'}]},\n",
       " {'id': 'v_toctHJpW6no_seg_15_25_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_toctHJpW6no_seg_15_25.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"read (read)\", \"roles\": {\"1\": \"Arg0 (reader)\", \"2\": \"Arg1 (book)\", \"3\": \"Arg3 (text, content)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (reader)\": \"man with light hair\", \"Arg1 (book)\": \"newspaper\", \"Arg3 (text, content)\": \"about a murder\", \"ArgM (location)\": \"in front of him\"}}'}]},\n",
       " {'id': 'v_toctHJpW6no_seg_15_25_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_toctHJpW6no_seg_15_25.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"agree (agree)\", \"roles\": {\"1\": \"Arg0 (agreer)\", \"2\": \"Arg2 (other entity agreeing)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agreer)\": \"man with dark hair\", \"Arg2 (other entity agreeing)\": \"man with light hair\", \"Scene of the Event\": \"parlor\"}}'}]},\n",
       " {'id': 'v_toctHJpW6no_seg_15_25_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_toctHJpW6no_seg_15_25.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"open (open)\", \"roles\": {\"1\": \"Arg0 (opener)\", \"2\": \"Arg1 (thing opening)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (opener)\": \"man with light hair\", \"Arg1 (thing opening)\": \"newspaper\", \"ArgM (manner)\": \"with both hands\", \"Scene of the Event\": \"parlor\"}}'}]},\n",
       " {'id': 'v_toctHJpW6no_seg_15_25_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_toctHJpW6no_seg_15_25.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man with dark hair\", \"Arg2 (hearer)\": \"man with light hair\", \"ArgM (manner)\": \"with a look of concern\", \"Scene of the Event\": \"parlor\"}}'}]},\n",
       " {'id': 'v_QZO_QFM5j_I_seg_90_100_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QZO_QFM5j_I_seg_90_100.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cry (cry, weep)\", \"roles\": {\"1\": \"Arg0 (cryer)\", \"2\": \"ArgM (manner)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cryer)\": \"woman in golden dress\", \"ArgM (manner)\": \"loudly\", \"Scene of the Event\": \"on stage with no audience\"}}'}]},\n",
       " {'id': 'v_QZO_QFM5j_I_seg_90_100_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QZO_QFM5j_I_seg_90_100.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cry (cry, weep)\", \"roles\": {\"1\": \"Arg0 (cryer)\", \"2\": \"ArgM (manner)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cryer)\": \"woman in golden dress\", \"ArgM (manner)\": \"while holding both hands out\", \"Scene of the Event\": \"on stage with no audience\"}}'}]},\n",
       " {'id': 'v_QZO_QFM5j_I_seg_90_100_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QZO_QFM5j_I_seg_90_100.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cry (cry, weep)\", \"roles\": {\"1\": \"Arg0 (cryer)\", \"2\": \"ArgM (manner)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cryer)\": \"woman in golden dress\", \"ArgM (manner)\": \"while holding her stomach\", \"Scene of the Event\": \"on stage with no audience\"}}'}]},\n",
       " {'id': 'v_QZO_QFM5j_I_seg_90_100_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QZO_QFM5j_I_seg_90_100.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cry (cry, weep)\", \"roles\": {\"1\": \"Arg0 (cryer)\", \"2\": \"ArgM (manner)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cryer)\": \"woman in golden dress\", \"ArgM (manner)\": \"while holding her stomach\", \"Scene of the Event\": \"on stage with no audience\"}}'}]},\n",
       " {'id': 'v_QZO_QFM5j_I_seg_90_100_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QZO_QFM5j_I_seg_90_100.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cry (cry, weep)\", \"roles\": {\"1\": \"Arg0 (cryer)\", \"2\": \"ArgM (manner)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cryer)\": \"woman in golden dress\", \"ArgM (manner)\": \"while holding her stomach\", \"Scene of the Event\": \"on stage with no audience\"}}'}]},\n",
       " {'id': 'v_UwhUd2cPOYE_seg_75_85_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_UwhUd2cPOYE_seg_75_85.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"terrify (scare very badly)\", \"roles\": {\"1\": \"Arg1 (terrified entity)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (terrified entity)\": \"the flying crew\", \"Scene of the Event\": \"in the airplane\"}}'}]},\n",
       " {'id': 'v_UwhUd2cPOYE_seg_75_85_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_UwhUd2cPOYE_seg_75_85.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"terrify (scare very badly)\", \"roles\": {\"1\": \"Arg1 (terrified entity)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (terrified entity)\": \"the flying crew\", \"Scene of the Event\": \"in the airplane\"}}'}]},\n",
       " {'id': 'v_UwhUd2cPOYE_seg_75_85_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_UwhUd2cPOYE_seg_75_85.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"terrify (scare very badly)\", \"roles\": {\"1\": \"Arg1 (terrified entity)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (terrified entity)\": \"the flying crew\", \"Scene of the Event\": \"in the airplane\"}}'}]},\n",
       " {'id': 'v_UwhUd2cPOYE_seg_75_85_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_UwhUd2cPOYE_seg_75_85.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"terrify (scare very badly)\", \"roles\": {\"1\": \"Arg1 (terrified entity)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (terrified entity)\": \"the flying crew\", \"Scene of the Event\": \"in the airplane\"}}'}]},\n",
       " {'id': 'v_UwhUd2cPOYE_seg_75_85_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_UwhUd2cPOYE_seg_75_85.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fly (fly through the air, travel via air)\", \"roles\": {\"1\": \"Arg1 (thing actually doing the flying)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing actually doing the flying)\": \"the airplane\", \"ArgM (direction)\": \"upward\", \"ArgM (location)\": \"in the air\", \"ArgM (manner)\": \"speedily\"}}'}]},\n",
       " {'id': 'v_oKW6UxOdICg_seg_105_115_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_oKW6UxOdICg_seg_105_115.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fix (repair)\", \"roles\": {\"1\": \"Arg0 (fixer)\", \"2\": \"Arg1 (thing fixed)\", \"3\": \"Arg2 (benefactive)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (fixer)\": \"man in white shirt\", \"Arg1 (thing fixed)\": \"fridge\", \"Arg2 (benefactive)\": \"to get it working again\", \"ArgM (manner)\": \"bent down on the backside looking inside\", \"Scene of the Event\": \"kitchen\"}}'}]},\n",
       " {'id': 'v_oKW6UxOdICg_seg_105_115_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_oKW6UxOdICg_seg_105_115.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fix (repair)\", \"roles\": {\"1\": \"Arg0 (fixer)\", \"2\": \"Arg1 (thing fixed)\", \"3\": \"Arg2 (benefactive)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (fixer)\": \"man in white shirt\", \"Arg1 (thing fixed)\": \"fridge\", \"Arg2 (benefactive)\": \"to get it working again\", \"ArgM (manner)\": \"bent down on the backside looking inside\", \"Scene of the Event\": \"kitchen\"}}'}]},\n",
       " {'id': 'v_oKW6UxOdICg_seg_105_115_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_oKW6UxOdICg_seg_105_115.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"put (location)\", \"roles\": {\"1\": \"Arg0 (putter)\", \"2\": \"Arg1 (thing put)\", \"3\": \"Arg2 (where put)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (putter)\": \"man in white shirt\", \"Arg1 (thing put)\": \"screwdriver\", \"Arg2 (where put)\": \"on a part\", \"ArgM (manner)\": \"carefully\", \"Scene of the Event\": \"kitchen\"}}'}]},\n",
       " {'id': 'v_oKW6UxOdICg_seg_105_115_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_oKW6UxOdICg_seg_105_115.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"observe (look at, mark)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"man in yellow shirt\", \"Arg1 (thing looked at)\": \"man in white shirt\", \"Scene of the Event\": \"kitchen\"}}'}]},\n",
       " {'id': 'v_oKW6UxOdICg_seg_105_115_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_oKW6UxOdICg_seg_105_115.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in yellow shirt\", \"Arg2 (hearer)\": \"man in white shirt\", \"ArgM (manner)\": \"leaning up against the counter\", \"Scene of the Event\": \"kitchen\"}}'}]},\n",
       " {'id': 'v_Oum7mEtv05g_seg_30_40_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Oum7mEtv05g_seg_30_40.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cut (slice)\", \"roles\": {\"1\": \"Arg0 (cutter)\", \"2\": \"Arg1 (thing cut)\", \"3\": \"Arg2 (medium, source)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cutter)\": \"A man in red uniform\", \"Arg1 (thing cut)\": \"the rope\", \"Arg2 (medium, source)\": \"Near the cliff\", \"ArgM (manner)\": \"With all his might\", \"Scene of the Event\": \"Near a cliff\"}}'}]},\n",
       " {'id': 'v_Oum7mEtv05g_seg_30_40_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Oum7mEtv05g_seg_30_40.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"release (let go)\", \"roles\": {\"1\": \"Arg0 (releaser)\", \"2\": \"Arg1 (thing released)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (releaser)\": \"A man in red uniform\", \"Arg1 (thing released)\": \"A man in beige outfit\", \"Scene of the Event\": \"Near a cliff\"}}'}]},\n",
       " {'id': 'v_Oum7mEtv05g_seg_30_40_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Oum7mEtv05g_seg_30_40.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"free (to make free)\", \"roles\": {\"1\": \"Arg0 (entity providing freedom, agent)\", \"2\": \"Arg1 (entity made free)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity providing freedom, agent)\": \"A man in red uniform\", \"Arg1 (entity made free)\": \"A man in beige outfit\", \"Scene of the Event\": \"Near a cliff\"}}'}]},\n",
       " {'id': 'v_Oum7mEtv05g_seg_30_40_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Oum7mEtv05g_seg_30_40.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"order (request to be delivered)\", \"roles\": {\"1\": \"Arg0 (orderer)\", \"2\": \"Arg1 (thing ordered)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (orderer)\": \"A man in black uniform and is sitting on a horse\", \"Arg1 (thing ordered)\": \"For his soldiers to capture the man in beige outfit\", \"Scene of the Event\": \"in the woods\"}}'}]},\n",
       " {'id': 'v_Oum7mEtv05g_seg_30_40_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Oum7mEtv05g_seg_30_40.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"charge (walk quickly)\", \"roles\": {\"1\": \"Arg0 (runner)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (runner)\": \"Some soldiers in black uniform\", \"ArgM (direction)\": \"A man in beige outfit\", \"Scene of the Event\": \"in the woods\"}}'}]},\n",
       " {'id': 'v_CGHuALdM57s_seg_5_15_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CGHuALdM57s_seg_5_15.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"march (to walk steadily)\", \"roles\": {\"1\": \"Arg0 (agent walking)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent walking)\": \"woman in a white bathrobe\", \"ArgM (direction)\": \"across the room\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_CGHuALdM57s_seg_5_15_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CGHuALdM57s_seg_5_15.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"woman in a white bathrobe\", \"Arg1 (looked at)\": \"the mirror\", \"ArgM (direction)\": \"ahead\", \"ArgM (manner)\": \"wordlessly\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_CGHuALdM57s_seg_5_15_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CGHuALdM57s_seg_5_15.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"don (start to wear, put on)\", \"roles\": {\"1\": \"Arg0 (wearer)\", \"2\": \"Arg1 (clothing)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (wearer)\": \"woman in a white bathrobe\", \"Arg1 (clothing)\": \"earrings\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_CGHuALdM57s_seg_5_15_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CGHuALdM57s_seg_5_15.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"blonde haired man\", \"Arg2 (hearer)\": \"woman in a white bathrobe\", \"ArgM (location)\": \"in a bathtub\", \"ArgM (manner)\": \"face to face\"}}'}]},\n",
       " {'id': 'v_CGHuALdM57s_seg_5_15_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CGHuALdM57s_seg_5_15.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"gesture (body language)\", \"roles\": {\"1\": \"Arg0 (gesturer)\", \"2\": \"Arg1 (gestured at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (gesturer)\": \"blonde haired man in a bathtub\", \"Arg1 (gestured at)\": \"woman in a white bathrobe\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_x5ajdqqytyA_seg_50_60_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x5ajdqqytyA_seg_50_60.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"enter (enter, go in)\", \"roles\": {\"1\": \"Arg0 (entity entering)\", \"2\": \"Arg1 (place or thing entered)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity entering)\": \"guy with black hair\", \"Arg1 (place or thing entered)\": \"the house\", \"ArgM (manner)\": \"seemingly not wanting to\", \"Scene of the Event\": \"the living room\"}}'}]},\n",
       " {'id': 'v_x5ajdqqytyA_seg_50_60_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x5ajdqqytyA_seg_50_60.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"close (shut)\", \"roles\": {\"1\": \"Arg0 (person doing the closing)\", \"2\": \"Arg1 (thing closing)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (person doing the closing)\": \"guy with black hair\", \"Arg1 (thing closing)\": \"the front door\", \"ArgM (location)\": \"behind him\", \"ArgM (manner)\": \"slowly\"}}'}]},\n",
       " {'id': 'v_x5ajdqqytyA_seg_50_60_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x5ajdqqytyA_seg_50_60.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"guy with black hair\", \"Arg1 (looked at)\": \"guy in plaid shirt\", \"ArgM (direction)\": \"in front of him\", \"ArgM (manner)\": \"not looking happy\", \"Scene of the Event\": \"the living room\"}}'}]},\n",
       " {'id': 'v_x5ajdqqytyA_seg_50_60_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x5ajdqqytyA_seg_50_60.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"watch (look at)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"guy in plaid shirt\", \"Arg1 (thing looked at)\": \"guy with black hair\", \"ArgM (manner)\": \"speechless\", \"Scene of the Event\": \"the living room\"}}'}]},\n",
       " {'id': 'v_x5ajdqqytyA_seg_50_60_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x5ajdqqytyA_seg_50_60.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"guy with black hair\", \"Arg2 (hearer)\": \"guy in plaid shirt\", \"ArgM (manner)\": \"upset about something\", \"Scene of the Event\": \"the living room\"}}'}]},\n",
       " {'id': 'v_x5ajdqqytyA_seg_115_125_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x5ajdqqytyA_seg_115_125.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"tell (pass along information)\", \"roles\": {\"1\": \"Arg0 (Speaker)\", \"2\": \"Arg1 (Utterance)\", \"3\": \"Arg2 (Hearer)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Speaker)\": \"man by door\", \"Arg1 (Utterance)\": \"something\", \"Arg2 (Hearer)\": \"man in plaid shirt\", \"Scene of the Event\": \"in a dark house\"}}'}]},\n",
       " {'id': 'v_x5ajdqqytyA_seg_115_125_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x5ajdqqytyA_seg_115_125.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man by door\", \"ArgM (direction)\": \"out the door\", \"ArgM (manner)\": \"-\", \"Scene of the Event\": \"in a dark house\"}}'}]},\n",
       " {'id': 'v_x5ajdqqytyA_seg_115_125_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x5ajdqqytyA_seg_115_125.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"close (shut)\", \"roles\": {\"1\": \"Arg0 (person doing the closing)\", \"2\": \"Arg1 (thing closing)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (person doing the closing)\": \"man by door\", \"Arg1 (thing closing)\": \"the door\", \"ArgM (location)\": \"behind him\", \"ArgM (manner)\": \"-\"}}'}]},\n",
       " {'id': 'v_x5ajdqqytyA_seg_115_125_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x5ajdqqytyA_seg_115_125.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man in plaid shirt\", \"Arg1 (looked at)\": \"nothing\", \"ArgM (direction)\": \"ahead\", \"ArgM (manner)\": \"blankly\", \"Scene of the Event\": \"in a dark house\"}}'}]},\n",
       " {'id': 'v_x5ajdqqytyA_seg_115_125_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x5ajdqqytyA_seg_115_125.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stand ((cause to) be in a vertical position)\", \"roles\": {\"1\": \"Arg1 (thing standing)\", \"2\": \"Arg2 (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing standing)\": \"a church\", \"Arg2 (location)\": \"in an area with trees\", \"ArgM (manner)\": \"tall\"}}'}]},\n",
       " {'id': 'v_oGxBx8RzzrM_seg_110_120_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_oGxBx8RzzrM_seg_110_120.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"dance (dance!)\", \"roles\": {\"1\": \"Arg0 (dancer)\", \"2\": \"Arg2 (partner)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (dancer)\": \"woman in a skirt\", \"Arg2 (partner)\": \"person in a striped shirt\", \"ArgM (location)\": \"on a yellow brick road\", \"ArgM (manner)\": \"happily\"}}'}]},\n",
       " {'id': 'v_oGxBx8RzzrM_seg_110_120_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_oGxBx8RzzrM_seg_110_120.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"dance (dance!)\", \"roles\": {\"1\": \"Arg0 (dancer)\", \"2\": \"Arg2 (partner)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (dancer)\": \"woman in a skirt\", \"Arg2 (partner)\": \"person in a striped shirt\", \"ArgM (location)\": \"on a yellow brick road\", \"ArgM (manner)\": \"happily\"}}'}]},\n",
       " {'id': 'v_oGxBx8RzzrM_seg_110_120_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_oGxBx8RzzrM_seg_110_120.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"dance (dance!)\", \"roles\": {\"1\": \"Arg0 (dancer)\", \"2\": \"Arg2 (partner)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (dancer)\": \"woman in a skirt\", \"Arg2 (partner)\": \"person in a striped shirt\", \"ArgM (location)\": \"on a yellow brick road\", \"ArgM (manner)\": \"happily\"}}'}]},\n",
       " {'id': 'v_oGxBx8RzzrM_seg_110_120_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_oGxBx8RzzrM_seg_110_120.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"dance (dance!)\", \"roles\": {\"1\": \"Arg0 (dancer)\", \"2\": \"Arg2 (partner)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (dancer)\": \"woman in a skirt\", \"Arg2 (partner)\": \"person in a striped shirt\", \"ArgM (location)\": \"on a yellow brick road\", \"ArgM (manner)\": \"happily\"}}'}]},\n",
       " {'id': 'v_oGxBx8RzzrM_seg_110_120_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_oGxBx8RzzrM_seg_110_120.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"dance (dance!)\", \"roles\": {\"1\": \"Arg0 (dancer)\", \"2\": \"Arg2 (partner)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (dancer)\": \"woman in a skirt\", \"Arg2 (partner)\": \"person in a striped shirt\", \"ArgM (location)\": \"on a yellow brick road\", \"ArgM (manner)\": \"happily\"}}'}]},\n",
       " {'id': 'v_inAlpz8a0aU_seg_75_85_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_inAlpz8a0aU_seg_75_85.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"email (send a message electronically)\", \"roles\": {\"1\": \"Arg0 (emailer)\", \"2\": \"Arg1 (message, email)\", \"3\": \"Arg2 (recipient, mailed-to)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (emailer)\": \"blonde haired girl in a grey t shirt\", \"Arg1 (message, email)\": \"friendly email\", \"Arg2 (recipient, mailed-to)\": \"unknown recipient\", \"Scene of the Event\": \"in a room\"}}'}]},\n",
       " {'id': 'v_inAlpz8a0aU_seg_75_85_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_inAlpz8a0aU_seg_75_85.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"blonde haired girl in a grey t shirt\", \"Arg2 (hearer)\": \"unknown receiver\", \"ArgM (location)\": \"in her room\", \"ArgM (manner)\": \"via a phone call\"}}'}]},\n",
       " {'id': 'v_inAlpz8a0aU_seg_75_85_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_inAlpz8a0aU_seg_75_85.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"a girl in a stripped t shirt\", \"Arg1 (looked at)\": \"her computer\", \"ArgM (direction)\": \"ahead\", \"ArgM (manner)\": \"wordlessly\", \"Scene of the Event\": \"in her room\"}}'}]},\n",
       " {'id': 'v_inAlpz8a0aU_seg_75_85_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_inAlpz8a0aU_seg_75_85.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"email (send a message electronically)\", \"roles\": {\"1\": \"Arg0 (emailer)\", \"2\": \"Arg1 (message, email)\", \"3\": \"Arg2 (recipient, mailed-to)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (emailer)\": \"blonde haired girl in a grey t shirt\", \"Arg1 (message, email)\": \"friendly email\", \"Arg2 (recipient, mailed-to)\": \"a boy in an orange and grey college jacket\", \"Scene of the Event\": \"in her room\"}}'}]},\n",
       " {'id': 'v_inAlpz8a0aU_seg_75_85_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_inAlpz8a0aU_seg_75_85.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"read (read)\", \"roles\": {\"1\": \"Arg0 (reader)\", \"2\": \"Arg1 (book)\", \"3\": \"Arg3 (text, content)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (reader)\": \"a boy in an orange and grey college jacket\", \"Arg1 (book)\": \"phone\", \"Arg3 (text, content)\": \"a friendly text message\", \"ArgM (location)\": \"on his phone\"}}'}]},\n",
       " {'id': 'v_MOA_WeKu76o_seg_15_25_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MOA_WeKu76o_seg_15_25.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cock (set at an angle)\", \"roles\": {\"1\": \"Arg0 (setter at angle)\", \"2\": \"Arg1 (angled thing)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (setter at angle)\": \"A young man\", \"Arg1 (angled thing)\": \"his gun\", \"Scene of the Event\": \"in the grass\"}}'}]},\n",
       " {'id': 'v_MOA_WeKu76o_seg_15_25_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MOA_WeKu76o_seg_15_25.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"The young man\", \"ArgM (direction)\": \"toward a prisoner\", \"ArgM (manner)\": \"assured\", \"Scene of the Event\": \"in the grass\"}}'}]},\n",
       " {'id': 'v_MOA_WeKu76o_seg_15_25_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MOA_WeKu76o_seg_15_25.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"beg (beg)\", \"roles\": {\"1\": \"Arg0 (begger, appealer)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (begger, appealer)\": \"The prisoner\", \"Scene of the Event\": \"on his knees\"}}'}]},\n",
       " {'id': 'v_MOA_WeKu76o_seg_15_25_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MOA_WeKu76o_seg_15_25.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"push ((try to) cause motion)\", \"roles\": {\"1\": \"Arg0 (pusher)\", \"2\": \"Arg1 (thing pushed)\", \"3\": \"Arg2 (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (pusher)\": \"An older soldier\", \"Arg1 (thing pushed)\": \"the prisoner\", \"Arg2 (direction)\": \"forward\", \"ArgM (manner)\": \"aggressively\", \"Scene of the Event\": \"in the grass\"}}'}]},\n",
       " {'id': 'v_MOA_WeKu76o_seg_15_25_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MOA_WeKu76o_seg_15_25.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"The prisoner\", \"Arg2 (hearer)\": \"to the older soldier\", \"ArgM (manner)\": \"begging\", \"Scene of the Event\": \"in the grass\"}}'}]},\n",
       " {'id': 'v_MOA_WeKu76o_seg_40_50_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MOA_WeKu76o_seg_40_50.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"yell (to cry out loudly)\", \"roles\": {\"1\": \"Arg0 (Yeller)\", \"2\": \"Arg2 (Hearer)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Yeller)\": \"man with dark hair\", \"Arg2 (Hearer)\": \"man wearing glasses\", \"Scene of the Event\": \"in a field\"}}'}]},\n",
       " {'id': 'v_MOA_WeKu76o_seg_40_50_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MOA_WeKu76o_seg_40_50.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man with dark hair\", \"Arg2 (hearer)\": \"his group of friends\", \"ArgM (manner)\": \"like he is in control of the situation\", \"Scene of the Event\": \"in the middle of a field\"}}'}]},\n",
       " {'id': 'v_MOA_WeKu76o_seg_40_50_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MOA_WeKu76o_seg_40_50.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"push ((try to) cause motion)\", \"roles\": {\"1\": \"Arg0 (pusher)\", \"2\": \"Arg1 (thing pushed)\", \"3\": \"Arg2 (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (pusher)\": \"man with long hair\", \"Arg1 (thing pushed)\": \"gun\", \"Arg2 (direction)\": \"down\", \"ArgM (manner)\": \"on top of man wearing glasses\", \"Scene of the Event\": \"in the grass\"}}'}]},\n",
       " {'id': 'v_MOA_WeKu76o_seg_40_50_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MOA_WeKu76o_seg_40_50.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"try (Attempt)\", \"roles\": {\"1\": \"Arg0 (Agent/Entity Trying)\", \"2\": \"Arg1 (thing tried)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Agent/Entity Trying)\": \"man wearing glasses\", \"Arg1 (thing tried)\": \"to push away guns\", \"ArgM (manner)\": \"with his left hand\", \"Scene of the Event\": \"on the ground\"}}'}]},\n",
       " {'id': 'v_MOA_WeKu76o_seg_40_50_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MOA_WeKu76o_seg_40_50.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"yell (to cry out loudly)\", \"roles\": {\"1\": \"Arg0 (Yeller)\", \"2\": \"Arg2 (Hearer)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Yeller)\": \"man with dark hair\", \"Arg2 (Hearer)\": \"man wearing glasses\", \"Scene of the Event\": \"in a field\"}}'}]},\n",
       " {'id': 'v_NGeFA2fWzX8_seg_65_75_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NGeFA2fWzX8_seg_65_75.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"enter (enter, go in)\", \"roles\": {\"1\": \"Arg0 (entity entering)\", \"2\": \"Arg1 (place or thing entered)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity entering)\": \"the bald man\", \"Arg1 (place or thing entered)\": \"the moving car\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"on a highway\"}}'}]},\n",
       " {'id': 'v_NGeFA2fWzX8_seg_65_75_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NGeFA2fWzX8_seg_65_75.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"celebrate (have a party)\", \"roles\": {\"1\": \"Arg0 (celebrator(s))\", \"2\": \"Arg1 (party, occasion)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (celebrator(s))\": \"the two men in the car\", \"Arg1 (party, occasion)\": \"the other man getting into the moving car\", \"Scene of the Event\": \"on a highway\"}}'}]},\n",
       " {'id': 'v_NGeFA2fWzX8_seg_65_75_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NGeFA2fWzX8_seg_65_75.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"move (change location)\", \"roles\": {\"1\": \"Arg1 (moved)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (moved)\": \"the tank\", \"Arg2 (destination)\": \"unknown\", \"ArgM (direction)\": \"down the road\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"on a highway\"}}'}]},\n",
       " {'id': 'v_NGeFA2fWzX8_seg_65_75_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NGeFA2fWzX8_seg_65_75.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"chase (follow, pursue)\", \"roles\": {\"1\": \"Arg0 (follower)\", \"2\": \"Arg1 (thing followed)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (follower)\": \"the blue car\", \"Arg1 (thing followed)\": \"the tank\", \"ArgM (direction)\": \"down the road\", \"Scene of the Event\": \"on a highway\"}}'}]},\n",
       " {'id': 'v_NGeFA2fWzX8_seg_65_75_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NGeFA2fWzX8_seg_65_75.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"the man driving the tank\", \"Arg2 (hearer)\": \"the tank commander\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"inside the moving tank\"}}'}]},\n",
       " {'id': 'v_uDffmOSVnBM_seg_5_15_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_uDffmOSVnBM_seg_5_15.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lean (to incline or cause to incline)\", \"roles\": {\"1\": \"Arg0 (causer of leaning)\", \"2\": \"Arg2 (direction)\", \"3\": \"ArgM (purpose)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of leaning)\": \"dark haired man\", \"Arg2 (direction)\": \"towards the mirror\", \"ArgM (purpose)\": \"to keep talking to himself\", \"Scene of the Event\": \"interior of a home\"}}'}]},\n",
       " {'id': 'v_uDffmOSVnBM_seg_5_15_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_uDffmOSVnBM_seg_5_15.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"dark haired man\", \"Arg2 (hearer)\": \"himself\", \"ArgM (location)\": \"in the mirror\", \"ArgM (manner)\": \"to give himself courage\"}}'}]},\n",
       " {'id': 'v_uDffmOSVnBM_seg_5_15_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_uDffmOSVnBM_seg_5_15.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"dark haired man\", \"Arg2 (hearer)\": \"himself\", \"ArgM (location)\": \"in the mirror\", \"ArgM (manner)\": \"to give himself courage\"}}'}]},\n",
       " {'id': 'v_uDffmOSVnBM_seg_5_15_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_uDffmOSVnBM_seg_5_15.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"watch (look at)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"long haired woman\", \"Arg1 (thing looked at)\": \"computer screen\", \"ArgM (manner)\": \"intently\", \"Scene of the Event\": \"home interior\"}}'}]},\n",
       " {'id': 'v_uDffmOSVnBM_seg_5_15_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_uDffmOSVnBM_seg_5_15.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"long haired woman\", \"Arg1 (looked at)\": \"computer screen\", \"ArgM (direction)\": \"in front of her\", \"ArgM (manner)\": \"unblinkingly\", \"Scene of the Event\": \"interior of a home\"}}'}]},\n",
       " {'id': 'v_QQAd5xx0XHc_seg_130_140_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QQAd5xx0XHc_seg_130_140.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"give (transfer)\", \"roles\": {\"1\": \"Arg0 (giver)\", \"2\": \"Arg1 (thing given)\", \"3\": \"Arg2 (entity given to)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (giver)\": \"man in blue suit\", \"Arg1 (thing given)\": \"a gun\", \"Arg2 (entity given to)\": \"man  with brown hair\", \"Scene of the Event\": \"in the living room\"}}'}]},\n",
       " {'id': 'v_QQAd5xx0XHc_seg_130_140_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QQAd5xx0XHc_seg_130_140.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fire (fire a gun)\", \"roles\": {\"1\": \"Arg0 (shooter)\", \"2\": \"Arg1 (gun)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shooter)\": \"man in gray suit\", \"Arg1 (gun)\": \"pistol\", \"ArgM (direction)\": \"towards the house the two men are in\", \"Scene of the Event\": \"outside the house\"}}'}]},\n",
       " {'id': 'v_QQAd5xx0XHc_seg_130_140_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QQAd5xx0XHc_seg_130_140.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"observe (look at, mark)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"man in gray suit\", \"Arg1 (thing looked at)\": \"the area around him to make sure no one is watching\", \"Scene of the Event\": \"outside the house\"}}'}]},\n",
       " {'id': 'v_QQAd5xx0XHc_seg_130_140_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QQAd5xx0XHc_seg_130_140.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"close (shut)\", \"roles\": {\"1\": \"Arg0 (person doing the closing)\", \"2\": \"Arg1 (thing closing)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (person doing the closing)\": \"man in gray suit\", \"Arg1 (thing closing)\": \"the trunk of the car\", \"ArgM (location)\": \"in front of him\", \"ArgM (manner)\": \"so he can see better hiding behind the car\"}}'}]},\n",
       " {'id': 'v_QQAd5xx0XHc_seg_130_140_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QQAd5xx0XHc_seg_130_140.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"aim (directed motion)\", \"roles\": {\"1\": \"Arg0 (aimer)\", \"2\": \"Arg1 (thing in motion)\", \"3\": \"Arg2 (target)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (aimer)\": \"man  with brown hair\", \"Arg1 (thing in motion)\": \"his gun\", \"Arg2 (target)\": \"man in gray suit\", \"Scene of the Event\": \"in the living room\"}}'}]},\n",
       " {'id': 'v_ZcvlWuqqv48_seg_115_125_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ZcvlWuqqv48_seg_115_125.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"glance (look at briefly)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked-at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man in suit\", \"Arg1 (looked-at)\": \"the writing on the mirror\", \"ArgM (direction)\": \"-\", \"ArgM (manner)\": \"briefly\", \"Scene of the Event\": \"in an airport bathroom\"}}'}]},\n",
       " {'id': 'v_ZcvlWuqqv48_seg_115_125_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ZcvlWuqqv48_seg_115_125.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"threaten (threaten)\", \"roles\": {\"1\": \"Arg0 (agent, entity making a threat)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, entity making a threat)\": \"man in suit\", \"Scene of the Event\": \"in an airport bathroom\"}}'}]},\n",
       " {'id': 'v_ZcvlWuqqv48_seg_115_125_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ZcvlWuqqv48_seg_115_125.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"wipe (move with wiping action)\", \"roles\": {\"1\": \"Arg0 (causer of motion, agent)\", \"2\": \"Arg1 (thing moved)\", \"3\": \"Arg2 (source)\", \"4\": \"Arg3 (instrument)\", \"5\": \"ArgM (direction)\", \"6\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of motion, agent)\": \"man in suit\", \"Arg1 (thing moved)\": \"the writing on the mirror\", \"Arg2 (source)\": \"with\", \"Arg3 (instrument)\": \"tissues\", \"ArgM (direction)\": \"away\", \"Scene of the Event\": \"in an airport bathroom\"}}'}]},\n",
       " {'id': 'v_ZcvlWuqqv48_seg_115_125_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ZcvlWuqqv48_seg_115_125.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"grab (to capture, obtain)\", \"roles\": {\"1\": \"Arg0 (grabber)\", \"2\": \"Arg1 (entity grabbed)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (grabber)\": \"man in suit\", \"Arg1 (entity grabbed)\": \"more tissues\", \"ArgM (location)\": \"from the tissue holder\", \"ArgM (manner)\": \"quickly\"}}'}]},\n",
       " {'id': 'v_ZcvlWuqqv48_seg_115_125_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ZcvlWuqqv48_seg_115_125.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"begin (start)\", \"roles\": {\"1\": \"Arg0 (beginner, Agent)\", \"2\": \"Arg1 (Theme(-Creation))\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (beginner, Agent)\": \"man in suit\", \"Arg1 (Theme(-Creation))\": \"wiping more of the writing from the mirror\", \"Scene of the Event\": \"in an airport bathroom\"}}'}]},\n",
       " {'id': 'v_LJq_hnR6CHc_seg_215_225_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LJq_hnR6CHc_seg_215_225.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"assist (help, assist)\", \"roles\": {\"1\": \"Arg0 (assistant)\", \"2\": \"Arg1 (assisted)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (assistant)\": \"the boy wearing the red cap\", \"Arg1 (assisted)\": \"the man on the floor\", \"Scene of the Event\": \"in the building\"}}'}]},\n",
       " {'id': 'v_LJq_hnR6CHc_seg_215_225_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LJq_hnR6CHc_seg_215_225.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"assist (help, assist)\", \"roles\": {\"1\": \"Arg0 (assistant)\", \"2\": \"Arg1 (assisted)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (assistant)\": \"the boy wearing the red cap\", \"Arg1 (assisted)\": \"the man on the floor\", \"Scene of the Event\": \"in the building\"}}'}]},\n",
       " {'id': 'v_LJq_hnR6CHc_seg_215_225_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LJq_hnR6CHc_seg_215_225.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hurt (be experiencing pain)\", \"roles\": {\"1\": \"Arg1 (patient, entity experiencing pain)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (patient, entity experiencing pain)\": \"the man on the floor\", \"Scene of the Event\": \"in the building\"}}'}]},\n",
       " {'id': 'v_LJq_hnR6CHc_seg_215_225_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LJq_hnR6CHc_seg_215_225.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hurt (be experiencing pain)\", \"roles\": {\"1\": \"Arg1 (patient, entity experiencing pain)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (patient, entity experiencing pain)\": \"the man on the floor\", \"Scene of the Event\": \"in the building\"}}'}]},\n",
       " {'id': 'v_LJq_hnR6CHc_seg_215_225_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LJq_hnR6CHc_seg_215_225.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hurt (be experiencing pain)\", \"roles\": {\"1\": \"Arg1 (patient, entity experiencing pain)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (patient, entity experiencing pain)\": \"the man on the floor\", \"Scene of the Event\": \"in the building\"}}'}]},\n",
       " {'id': 'v_adjuOPzkpw4_seg_35_45_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_adjuOPzkpw4_seg_35_45.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"gesture (body language)\", \"roles\": {\"1\": \"Arg0 (gesturer)\", \"2\": \"Arg1 (gestured at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (gesturer)\": \"man in a grey suit\", \"Arg1 (gestured at)\": \"the pilot\", \"Scene of the Event\": \"in a helicopter\"}}'}]},\n",
       " {'id': 'v_adjuOPzkpw4_seg_35_45_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_adjuOPzkpw4_seg_35_45.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"turn (rotation)\", \"roles\": {\"1\": \"Arg0 (turner)\", \"2\": \"Arg1 (thing turning)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (purpose)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (turner)\": \"the pilot\", \"Arg1 (thing turning)\": \"helicopter\", \"ArgM (direction)\": \"around\", \"ArgM (purpose)\": \"to head back\", \"Scene of the Event\": \"on the skies\"}}'}]},\n",
       " {'id': 'v_adjuOPzkpw4_seg_35_45_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_adjuOPzkpw4_seg_35_45.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cower (shrink away in fear, cringe)\", \"roles\": {\"1\": \"Arg0 (afraid entity)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (afraid entity)\": \"man in a grey suit\", \"Scene of the Event\": \"in a helicopter\"}}'}]},\n",
       " {'id': 'v_adjuOPzkpw4_seg_35_45_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_adjuOPzkpw4_seg_35_45.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a grey suit\", \"Arg2 (hearer)\": \"the pilot\", \"ArgM (location)\": \"from the back seat of a helicopter\", \"ArgM (manner)\": \"panickly\"}}'}]},\n",
       " {'id': 'v_adjuOPzkpw4_seg_35_45_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_adjuOPzkpw4_seg_35_45.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"panic (be all afluster)\", \"roles\": {\"1\": \"Arg1 (panicker)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (panicker)\": \"man in a grey suit\", \"Scene of the Event\": \"in a helicopter\"}}'}]},\n",
       " {'id': 'v_adjuOPzkpw4_seg_150_160_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_adjuOPzkpw4_seg_150_160.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"reach (stretch, grasp)\", \"roles\": {\"1\": \"Arg0 (reacher)\", \"2\": \"Arg1 (body part)\", \"3\": \"Arg2 (goal)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (purpose)\", \"6\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (reacher)\": \"man in SCUBA gear\", \"Arg1 (body part)\": \"his right hand\", \"Arg2 (goal)\": \"blonde man\", \"ArgM (direction)\": \"towards\", \"ArgM (purpose)\": \"to get help\", \"Scene of the Event\": \"open water\"}}'}]},\n",
       " {'id': 'v_adjuOPzkpw4_seg_150_160_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_adjuOPzkpw4_seg_150_160.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stand (rise)\", \"roles\": {\"1\": \"Arg1 (riser)\", \"2\": \"ArgM (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (riser)\": \"blonde man\", \"ArgM (location)\": \"in the small red watercraft\", \"ArgM (manner)\": \"while bracing himself and leaning over\"}}'}]},\n",
       " {'id': 'v_adjuOPzkpw4_seg_150_160_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_adjuOPzkpw4_seg_150_160.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"heft (to hoist of heave)\", \"roles\": {\"1\": \"Arg1 (thing hefted)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (thing hefted)\": \"man in SCUBA gear\", \"Scene of the Event\": \"open water\"}}'}]},\n",
       " {'id': 'v_adjuOPzkpw4_seg_150_160_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_adjuOPzkpw4_seg_150_160.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"celebrate (have a party)\", \"roles\": {\"1\": \"Arg0 (celebrator(s))\", \"2\": \"Arg1 (party, occasion)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (celebrator(s))\": \"blonde man\", \"Arg1 (party, occasion)\": \"the man in SCUBA gear returning to the small red watercraft\", \"Scene of the Event\": \"open water\"}}'}]},\n",
       " {'id': 'v_adjuOPzkpw4_seg_150_160_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_adjuOPzkpw4_seg_150_160.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shout (yell, or announce loudly)\", \"roles\": {\"1\": \"Arg0 (shouter)\", \"2\": \"Arg2 (listener)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shouter)\": \"blonde man\", \"Arg2 (listener)\": \"man in SCUBA gear\", \"Scene of the Event\": \"open water\"}}'}]},\n",
       " {'id': 'v_MxDtKTClKGI_seg_20_30_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MxDtKTClKGI_seg_20_30.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"boy in short sleeve shirt\", \"Arg2 (hearer)\": \"woman with blonde hair\", \"ArgM (location)\": \"back yard\", \"ArgM (manner)\": \"with confident words\"}}'}]},\n",
       " {'id': 'v_MxDtKTClKGI_seg_20_30_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MxDtKTClKGI_seg_20_30.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"woman with blonde hair\", \"Arg2 (hearer)\": \"boy in short sleeve shirt\", \"ArgM (location)\": \"back yard\", \"ArgM (manner)\": \"via encouraging words\"}}'}]},\n",
       " {'id': 'v_MxDtKTClKGI_seg_20_30_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MxDtKTClKGI_seg_20_30.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"move (change location)\", \"roles\": {\"1\": \"Arg1 (moved)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (moved)\": \"man in gray shirt\", \"Arg2 (destination)\": \"to a spacious area\", \"ArgM (direction)\": \"forward\", \"ArgM (manner)\": \"with careful steps\", \"Scene of the Event\": \"back yard\"}}'}]},\n",
       " {'id': 'v_MxDtKTClKGI_seg_20_30_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MxDtKTClKGI_seg_20_30.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"yell (to cry out loudly)\", \"roles\": {\"1\": \"Arg0 (Yeller)\", \"2\": \"Arg2 (Hearer)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Yeller)\": \"man in gray shirt\", \"Arg2 (Hearer)\": \"boy in short sleeve shirt\", \"Scene of the Event\": \"back yard\"}}'}]},\n",
       " {'id': 'v_MxDtKTClKGI_seg_20_30_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MxDtKTClKGI_seg_20_30.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"yell (to cry out loudly)\", \"roles\": {\"1\": \"Arg0 (Yeller)\", \"2\": \"Arg2 (Hearer)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Yeller)\": \"woman with blonde hair\", \"Arg2 (Hearer)\": \"man in gray shirt\", \"Scene of the Event\": \"back yard\"}}'}]},\n",
       " {'id': 'v_QQq6L1Sw4Ck_seg_45_55_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QQq6L1Sw4Ck_seg_45_55.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man in a blue sleeveless tshirt\", \"Arg1 (looked at)\": \"man in a striped white and brown t shirt\", \"ArgM (direction)\": \"ahead\", \"ArgM (manner)\": \"wordlessly\", \"Scene of the Event\": \"on a street\"}}'}]},\n",
       " {'id': 'v_QQq6L1Sw4Ck_seg_45_55_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QQq6L1Sw4Ck_seg_45_55.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"strike (hit)\", \"roles\": {\"1\": \"Arg0 (agent, hitter - animate only!)\", \"2\": \"Arg1 (thing hit)\", \"3\": \"Arg2 (instrument, thing hit by or with)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, hitter - animate only!)\": \"man in a striped white and brown t shirt\", \"Arg1 (thing hit)\": \"man in a blue sleeveless tshirt\", \"Arg2 (instrument, thing hit by or with)\": \"his fist\", \"Scene of the Event\": \"on a street\"}}'}]},\n",
       " {'id': 'v_QQq6L1Sw4Ck_seg_45_55_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QQq6L1Sw4Ck_seg_45_55.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"kick (drive or impel with the foot)\", \"roles\": {\"1\": \"Arg0 (kicker)\", \"2\": \"Arg1 (thing kicked)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (kicker)\": \"man in a blue sleeveless tshirt\", \"Arg1 (thing kicked)\": \"man in a striped white and brown t shirt\", \"ArgM (direction)\": \"ahead\", \"ArgM (location)\": \"on his side\", \"ArgM (manner)\": \"hard and with force\"}}'}]},\n",
       " {'id': 'v_QQq6L1Sw4Ck_seg_45_55_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QQq6L1Sw4Ck_seg_45_55.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"knock (hit)\", \"roles\": {\"1\": \"Arg0 (agent, hitter - animate only!)\", \"2\": \"Arg1 (thing hit)\", \"3\": \"Arg2 (instrument, thing hit by or with)\", \"4\": \"ArgM (direction)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, hitter - animate only!)\": \"man in a grey shirt\", \"Arg1 (thing hit)\": \"man in a blue sleeveless tshirt\", \"Arg2 (instrument, thing hit by or with)\": \"his fist\", \"ArgM (direction)\": \"out\", \"Scene of the Event\": \"on a street\"}}'}]},\n",
       " {'id': 'v_QQq6L1Sw4Ck_seg_45_55_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QQq6L1Sw4Ck_seg_45_55.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"attack (to make an attack, criticize strongly)\", \"roles\": {\"1\": \"Arg0 (attacker)\", \"2\": \"Arg1 (entity attacked)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (attacker)\": \"man in a blue sleeveless tshirt\", \"Arg1 (entity attacked)\": \"man in a stripped shirt\", \"Scene of the Event\": \"on a street\"}}'}]},\n",
       " {'id': 'v_v3IyV96FX74_seg_10_20_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_v3IyV96FX74_seg_10_20.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"observe (look at, mark)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"Coast Guard\", \"Arg1 (thing looked at)\": \"a yacht\", \"Scene of the Event\": \"ocean\"}}'}]},\n",
       " {'id': 'v_v3IyV96FX74_seg_10_20_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_v3IyV96FX74_seg_10_20.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sail (to move along, navigate)\", \"roles\": {\"1\": \"Arg0 (entity sailing)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity sailing)\": \"a yacht\", \"ArgM (direction)\": \"towards the Coast Guard ship\", \"Scene of the Event\": \"ocean\"}}'}]},\n",
       " {'id': 'v_v3IyV96FX74_seg_10_20_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_v3IyV96FX74_seg_10_20.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man\", \"ArgM (direction)\": \"across the deck\", \"ArgM (manner)\": \"gliding his hand along the rope\", \"Scene of the Event\": \"on the yacht\"}}'}]},\n",
       " {'id': 'v_v3IyV96FX74_seg_10_20_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_v3IyV96FX74_seg_10_20.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sail (to move along, navigate)\", \"roles\": {\"1\": \"Arg0 (entity sailing)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity sailing)\": \"a yacht\", \"ArgM (direction)\": \"alongside the Coast Guard\", \"Scene of the Event\": \"ocean\"}}'}]},\n",
       " {'id': 'v_v3IyV96FX74_seg_10_20_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_v3IyV96FX74_seg_10_20.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"float (not sink in water)\", \"roles\": {\"1\": \"Arg1 (thing floating)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg1 (thing floating)\": \"Coast Guard ship\", \"ArgM (direction)\": \"Into the waves\", \"ArgM (location)\": \"ocean\"}}'}]},\n",
       " {'id': 'v_1c15w3kCHkw_seg_110_120_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_1c15w3kCHkw_seg_110_120.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"aim (directed motion)\", \"roles\": {\"1\": \"Arg0 (aimer)\", \"2\": \"Arg1 (thing in motion)\", \"3\": \"Arg2 (target)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (aimer)\": \"A man in a cowboy hat\", \"Arg1 (thing in motion)\": \"a hand gun\", \"Arg2 (target)\": \"at a woman\\'s head\", \"Scene of the Event\": \"in a room\"}}'}]},\n",
       " {'id': 'v_1c15w3kCHkw_seg_110_120_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_1c15w3kCHkw_seg_110_120.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"The man in the hat\", \"Arg2 (hearer)\": \"to a man in a white t-shirt\", \"ArgM (manner)\": \"slowly\", \"Scene of the Event\": \"at a woman\\'s head\"}}'}]},\n",
       " {'id': 'v_1c15w3kCHkw_seg_110_120_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_1c15w3kCHkw_seg_110_120.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"signal (show, cause to see)\", \"roles\": {\"1\": \"Arg0 (shower)\", \"2\": \"Arg1 (thing seen/shown)\", \"3\": \"Arg2 (seer)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shower)\": \"A motel sign\", \"Arg1 (thing seen/shown)\": \"\\\\\"MOTEL\\\\\"\", \"Arg2 (seer)\": \"to passer\\'s by\", \"Scene of the Event\": \"outside the motel\"}}'}]},\n",
       " {'id': 'v_1c15w3kCHkw_seg_110_120_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_1c15w3kCHkw_seg_110_120.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"flicker (emit light randomly)\", \"roles\": {\"1\": \"Arg1 (source of light)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (source of light)\": \"The motel sign\", \"Scene of the Event\": \"outside the motel\"}}'}]},\n",
       " {'id': 'v_1c15w3kCHkw_seg_110_120_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_1c15w3kCHkw_seg_110_120.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"enter (enter, go in)\", \"roles\": {\"1\": \"Arg0 (entity entering)\", \"2\": \"Arg1 (place or thing entered)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity entering)\": \"The man in white\", \"Arg1 (place or thing entered)\": \"a motel room\", \"ArgM (manner)\": \"slowly\", \"Scene of the Event\": \"in the motel\"}}'}]},\n",
       " {'id': 'v_VmCRT88HTWE_seg_80_90_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_VmCRT88HTWE_seg_80_90.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"dangle (to hang loosely)\", \"roles\": {\"1\": \"Arg1 (entity dangling)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity dangling)\": \"dark-haired man in a dark suit\", \"Scene of the Event\": \"over the edge of a tall apartment building\"}}'}]},\n",
       " {'id': 'v_VmCRT88HTWE_seg_80_90_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_VmCRT88HTWE_seg_80_90.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"witness (to observe, see, or be a site of )\", \"roles\": {\"1\": \"Arg0 (agent, entity witnessing)\", \"2\": \"Arg1 (thing witnessed)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, entity witnessing)\": \"a gray-haired man in a gray suit and tie, and a brown-haired man in a brown suit and tie\", \"Arg1 (thing witnessed)\": \"dark-haired man in a dark suit\", \"Scene of the Event\": \"street below the tall apartment building\"}}'}]},\n",
       " {'id': 'v_VmCRT88HTWE_seg_80_90_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_VmCRT88HTWE_seg_80_90.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hasten (to speed up)\", \"roles\": {\"1\": \"Arg0 (agent, causer)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, causer)\": \"situation the dangling man is in\", \"ArgM (direction)\": \"toward\", \"Scene of the Event\": \"street below the tall apartment building\"}}'}]},\n",
       " {'id': 'v_VmCRT88HTWE_seg_80_90_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_VmCRT88HTWE_seg_80_90.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"exit (leave)\", \"roles\": {\"1\": \"Arg0 (departed entity)\", \"2\": \"Arg1 (place exited)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (departed entity)\": \"man in black cowboy hat, black shirt, and half-put-on leather jacket\", \"Arg1 (place exited)\": \"apartment\", \"Scene of the Event\": \"brick apartment\"}}'}]},\n",
       " {'id': 'v_VmCRT88HTWE_seg_80_90_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_VmCRT88HTWE_seg_80_90.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"notice (become aware of)\", \"roles\": {\"1\": \"Arg0 (noticer)\", \"2\": \"Arg1 (noticed)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (noticer)\": \"man in black cowboy hat, black shirt, and half-put-on leather jacket\", \"Arg1 (noticed)\": \"out of frame entity\", \"ArgM (location)\": \"brick apartment\"}}'}]},\n",
       " {'id': 'v_MFd88DSTPgI_seg_85_95_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MFd88DSTPgI_seg_85_95.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"nod (to lower and raise the head or to express by nodding)\", \"roles\": {\"1\": \"Arg0 (entity with a bobbing head, agent)\", \"2\": \"ArgM (manner)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity with a bobbing head, agent)\": \"man with dark hair\", \"ArgM (manner)\": \"in agreement\", \"Scene of the Event\": \"art gallery\"}}'}]},\n",
       " {'id': 'v_MFd88DSTPgI_seg_85_95_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MFd88DSTPgI_seg_85_95.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"smile (to have or form a smile)\", \"roles\": {\"1\": \"Arg0 (agent smiling)\", \"2\": \"Arg2 (smiled at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent smiling)\": \"man with dark hair\", \"Arg2 (smiled at)\": \"blonde woman\", \"ArgM (manner)\": \"with his lips taut and closed\", \"Scene of the Event\": \"art gallery\"}}'}]},\n",
       " {'id': 'v_MFd88DSTPgI_seg_85_95_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MFd88DSTPgI_seg_85_95.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shine (produce light)\", \"roles\": {\"1\": \"Arg0 (cause of illumination, agent)\", \"2\": \"Arg1 (light itself)\", \"3\": \"Arg2 (thing illuminated)\", \"4\": \"ArgM (direction)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cause of illumination, agent)\": \"-\", \"Arg1 (light itself)\": \"sun\", \"Arg2 (thing illuminated)\": \"the tops of the trees\", \"ArgM (direction)\": \"from behind\", \"Scene of the Event\": \"park with lots of greenery\"}}'}]},\n",
       " {'id': 'v_MFd88DSTPgI_seg_85_95_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MFd88DSTPgI_seg_85_95.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"flicker (emit light randomly)\", \"roles\": {\"1\": \"Arg1 (source of light)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (source of light)\": \"sun\", \"Scene of the Event\": \"park with lots of greenery\"}}'}]},\n",
       " {'id': 'v_MFd88DSTPgI_seg_85_95_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MFd88DSTPgI_seg_85_95.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stroll (to walk at a leisurely pace)\", \"roles\": {\"1\": \"Arg0 (walker, stroller)\", \"2\": \"Arg1 (path)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker, stroller)\": \"man with dark hair\", \"Arg1 (path)\": \"brick walk way\", \"ArgM (direction)\": \"with the sun to his left\", \"Scene of the Event\": \"park with lots of greenery\"}}'}]},\n",
       " {'id': 'v_x2W8BqPt7mI_seg_45_55_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x2W8BqPt7mI_seg_45_55.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"observe (look at, mark)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"man with beard\", \"Arg1 (thing looked at)\": \"man on phone\", \"Scene of the Event\": \"inside a house\"}}'}]},\n",
       " {'id': 'v_x2W8BqPt7mI_seg_45_55_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x2W8BqPt7mI_seg_45_55.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man with dark hair\", \"Arg2 (hearer)\": \"man in long coat\", \"ArgM (manner)\": \"over the phone\", \"Scene of the Event\": \"inside a house\"}}'}]},\n",
       " {'id': 'v_x2W8BqPt7mI_seg_45_55_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x2W8BqPt7mI_seg_45_55.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"respond (give an answer, reply)\", \"roles\": {\"1\": \"Arg0 (replier)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (replier)\": \"man in long coat\", \"Scene of the Event\": \"inside a house\"}}'}]},\n",
       " {'id': 'v_x2W8BqPt7mI_seg_45_55_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x2W8BqPt7mI_seg_45_55.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"respond (give an answer, reply)\", \"roles\": {\"1\": \"Arg0 (replier)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (replier)\": \"man with dark hair\", \"Scene of the Event\": \"inside a house\"}}'}]},\n",
       " {'id': 'v_x2W8BqPt7mI_seg_45_55_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x2W8BqPt7mI_seg_45_55.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"yell (to cry out loudly)\", \"roles\": {\"1\": \"Arg0 (Yeller)\", \"2\": \"Arg2 (Hearer)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Yeller)\": \"man in long coat\", \"Arg2 (Hearer)\": \"man with dark hair\", \"Scene of the Event\": \"inside a house\"}}'}]},\n",
       " {'id': 'v_x2W8BqPt7mI_seg_20_30_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x2W8BqPt7mI_seg_20_30.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"chat (talk idly)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"a man holding a cell phone\", \"Arg2 (hearer)\": \"someone on the phone\", \"Scene of the Event\": \"near a window\"}}'}]},\n",
       " {'id': 'v_x2W8BqPt7mI_seg_20_30_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x2W8BqPt7mI_seg_20_30.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"chat (talk idly)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"a man holding a cell phone\", \"Arg2 (hearer)\": \"a man holding a cell phone\", \"Scene of the Event\": \"near a window\"}}'}]},\n",
       " {'id': 'v_x2W8BqPt7mI_seg_20_30_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x2W8BqPt7mI_seg_20_30.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"chat (talk idly)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"a man holding a cell phone\", \"Arg2 (hearer)\": \"someone on the phone\", \"Scene of the Event\": \"-\"}}'}]},\n",
       " {'id': 'v_x2W8BqPt7mI_seg_20_30_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x2W8BqPt7mI_seg_20_30.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"chat (talk idly)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"a man holding a cell phone\", \"Arg2 (hearer)\": \"someone on the phone\", \"Scene of the Event\": \"-\"}}'}]},\n",
       " {'id': 'v_x2W8BqPt7mI_seg_20_30_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_x2W8BqPt7mI_seg_20_30.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"chat (talk idly)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"a man holding a cell phone\", \"Arg2 (hearer)\": \"someone on the phone\", \"Scene of the Event\": \"near a window\"}}'}]},\n",
       " {'id': 'v_KA2ziAAXoqE_seg_30_40_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_KA2ziAAXoqE_seg_30_40.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a blue shirt\", \"Arg2 (hearer)\": \"man in a black tank top\", \"ArgM (manner)\": \"on the phone\", \"Scene of the Event\": \"in an office\"}}'}]},\n",
       " {'id': 'v_KA2ziAAXoqE_seg_30_40_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_KA2ziAAXoqE_seg_30_40.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a blue shirt\", \"Arg2 (hearer)\": \"man in a black tank top\", \"ArgM (manner)\": \"on the phone\", \"Scene of the Event\": \"in an office\"}}'}]},\n",
       " {'id': 'v_KA2ziAAXoqE_seg_30_40_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_KA2ziAAXoqE_seg_30_40.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"listen (attend to a sound)\", \"roles\": {\"1\": \"Arg0 (listener)\", \"2\": \"Arg1 (sound or speaker)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (listener)\": \"man in a black tank top\", \"Arg1 (sound or speaker)\": \"man in a blue shirt\", \"ArgM (manner)\": \"on the phone\", \"Scene of the Event\": \"in a gym\"}}'}]},\n",
       " {'id': 'v_KA2ziAAXoqE_seg_30_40_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_KA2ziAAXoqE_seg_30_40.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a blue shirt\", \"Arg2 (hearer)\": \"man in a black tank top\", \"ArgM (manner)\": \"on the phone\", \"Scene of the Event\": \"in an office\"}}'}]},\n",
       " {'id': 'v_KA2ziAAXoqE_seg_30_40_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_KA2ziAAXoqE_seg_30_40.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a blue shirt\", \"Arg2 (hearer)\": \"man in a black tank top\", \"ArgM (manner)\": \"on the phone\", \"Scene of the Event\": \"in an office\"}}'}]},\n",
       " {'id': 'v_fk2MU617-Bc_seg_0_10_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_fk2MU617-Bc_seg_0_10.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"run (walk quickly, a course or contest)\", \"roles\": {\"1\": \"Arg0 (runner)\", \"2\": \"Arg1 (course, race, distance)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (goal)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (runner)\": \"the men\", \"Arg1 (course, race, distance)\": \"unknown\", \"ArgM (direction)\": \"forward\", \"ArgM (goal)\": \"to survive\", \"Scene of the Event\": \"in the desert\"}}'}]},\n",
       " {'id': 'v_fk2MU617-Bc_seg_0_10_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_fk2MU617-Bc_seg_0_10.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"run (walk quickly, a course or contest)\", \"roles\": {\"1\": \"Arg0 (runner)\", \"2\": \"Arg1 (course, race, distance)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (goal)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (runner)\": \"the men\", \"Arg1 (course, race, distance)\": \"unknown\", \"ArgM (direction)\": \"forward\", \"ArgM (goal)\": \"to survive\", \"Scene of the Event\": \"in the desert\"}}'}]},\n",
       " {'id': 'v_fk2MU617-Bc_seg_0_10_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_fk2MU617-Bc_seg_0_10.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"run (walk quickly, a course or contest)\", \"roles\": {\"1\": \"Arg0 (runner)\", \"2\": \"Arg1 (course, race, distance)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (goal)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (runner)\": \"the men\", \"Arg1 (course, race, distance)\": \"unknown\", \"ArgM (direction)\": \"forward\", \"ArgM (goal)\": \"to survive\", \"Scene of the Event\": \"in the desert\"}}'}]},\n",
       " {'id': 'v_fk2MU617-Bc_seg_0_10_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_fk2MU617-Bc_seg_0_10.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"halt (stop)\", \"roles\": {\"1\": \"Arg0 (causer of stopping)\", \"2\": \"Arg1 (Theme (action or object being stopped))\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of stopping)\": \"the men\", \"Arg1 (Theme (action or object being stopped))\": \"running\", \"Scene of the Event\": \"in the desert\"}}'}]},\n",
       " {'id': 'v_fk2MU617-Bc_seg_0_10_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_fk2MU617-Bc_seg_0_10.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"halt (stop)\", \"roles\": {\"1\": \"Arg0 (causer of stopping)\", \"2\": \"Arg1 (Theme (action or object being stopped))\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of stopping)\": \"the men\", \"Arg1 (Theme (action or object being stopped))\": \"running\", \"Scene of the Event\": \"in the desert\"}}'}]},\n",
       " {'id': 'v_zhhLFNr_Jio_seg_145_155_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_zhhLFNr_Jio_seg_145_155.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lie (more explicit horizontal position)\", \"roles\": {\"1\": \"Arg1 (entity lying down)\", \"2\": \"Arg2 (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (entity lying down)\": \"man in zipper shirt\", \"Arg2 (location)\": \"on the concrete\", \"ArgM (manner)\": \"with blood pooling from his head\"}}'}]},\n",
       " {'id': 'v_zhhLFNr_Jio_seg_145_155_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_zhhLFNr_Jio_seg_145_155.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"glare (to look at)\", \"roles\": {\"1\": \"Arg0 (glarer, agent)\", \"2\": \"Arg1 (entity glared at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (glarer, agent)\": \"man in suit\", \"Arg1 (entity glared at)\": \"man in zipper shirt\", \"ArgM (manner)\": \"angrily\", \"Scene of the Event\": \"in a parking garage\"}}'}]},\n",
       " {'id': 'v_zhhLFNr_Jio_seg_145_155_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_zhhLFNr_Jio_seg_145_155.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"see (view)\", \"roles\": {\"1\": \"Arg0 (viewer)\", \"2\": \"Arg1 (thing viewed)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (viewer)\": \"man in suit\", \"Arg1 (thing viewed)\": \"two onlookers\", \"ArgM (direction)\": \"in front of him\", \"ArgM (location)\": \"some distance from him\"}}'}]},\n",
       " {'id': 'v_zhhLFNr_Jio_seg_145_155_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_zhhLFNr_Jio_seg_145_155.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man in suit\", \"Arg1 (thing looked at or for or on)\": \"two onlookers\", \"ArgM (direction)\": \"in front of him\", \"ArgM (manner)\": \"with fear\", \"Scene of the Event\": \"in a parking garage\"}}'}]},\n",
       " {'id': 'v_zhhLFNr_Jio_seg_145_155_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_zhhLFNr_Jio_seg_145_155.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"glance (look at briefly)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked-at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man in suit\", \"Arg1 (looked-at)\": \"-\", \"ArgM (direction)\": \"around the parking garage\", \"ArgM (manner)\": \"nervously\", \"Scene of the Event\": \"in a parking garage\"}}'}]},\n",
       " {'id': 'v_XNZRK35VNrk_seg_70_80_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XNZRK35VNrk_seg_70_80.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"struggle (struggle)\", \"roles\": {\"1\": \"Arg0 (first struggler)\", \"2\": \"Arg1 (second struggler)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (first struggler)\": \"dark-haired man with a patterned hawaiian shirt\", \"Arg1 (second struggler)\": \"dark-haired man in a dark shirt\", \"ArgM (manner)\": \"violently on the ground until one of them fires a gun\", \"Scene of the Event\": \"hallway all boarded up\"}}'}]},\n",
       " {'id': 'v_XNZRK35VNrk_seg_70_80_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XNZRK35VNrk_seg_70_80.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"release (let go)\", \"roles\": {\"1\": \"Arg0 (releaser)\", \"2\": \"Arg1 (thing released)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (releaser)\": \"dark-haired man with a patterned hawaiian shirt\", \"Arg1 (thing released)\": \"dark-haired man in a dark shirt\", \"Scene of the Event\": \"hallway all boarded up\"}}'}]},\n",
       " {'id': 'v_XNZRK35VNrk_seg_70_80_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XNZRK35VNrk_seg_70_80.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"target (take aim at)\", \"roles\": {\"1\": \"Arg0 (targeter)\", \"2\": \"Arg1 (thing aimed at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (targeter)\": \"dark-haired man with a patterned hawaiian shirt\", \"Arg1 (thing aimed at)\": \"dark-haired man in a dark shirt\", \"ArgM (manner)\": \"with one arm extended, while the other man also points his gun at him\", \"Scene of the Event\": \"hallway all boarded up\"}}'}]},\n",
       " {'id': 'v_XNZRK35VNrk_seg_70_80_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XNZRK35VNrk_seg_70_80.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"target (take aim at)\", \"roles\": {\"1\": \"Arg0 (targeter)\", \"2\": \"Arg1 (thing aimed at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (targeter)\": \"dark-haired man with a patterned hawaiian shirt\", \"Arg1 (thing aimed at)\": \"dark-haired man in a dark shirt\", \"ArgM (manner)\": \"with one arm extended, while the other man also points his gun at him\", \"Scene of the Event\": \"hallway all boarded up\"}}'}]},\n",
       " {'id': 'v_XNZRK35VNrk_seg_70_80_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XNZRK35VNrk_seg_70_80.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"dark-haired man in a dark shirt\", \"Arg1 (looked at)\": \"dark-haired man with a patterned hawaiian shirt\", \"ArgM (direction)\": \"directly at\", \"ArgM (manner)\": \"breathing heavily and pointing the gun\", \"Scene of the Event\": \"hallway all boarded up\"}}'}]},\n",
       " {'id': 'v_PENNRVb6OBM_seg_65_75_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_PENNRVb6OBM_seg_65_75.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"a long dark haired woman\", \"Arg2 (hearer)\": \"soldiers\", \"ArgM (manner)\": \"aggressively\", \"Scene of the Event\": \"near a concrete wall\"}}'}]},\n",
       " {'id': 'v_PENNRVb6OBM_seg_65_75_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_PENNRVb6OBM_seg_65_75.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"turn (rotation)\", \"roles\": {\"1\": \"Arg0 (turner)\", \"2\": \"Arg1 (thing turning)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (purpose)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (turner)\": \"a long dark haired woman\", \"Arg1 (thing turning)\": \"herself\", \"ArgM (direction)\": \"away from the soldier\", \"ArgM (purpose)\": \"-\", \"Scene of the Event\": \"a city street near a concrete wall\"}}'}]},\n",
       " {'id': 'v_PENNRVb6OBM_seg_65_75_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_PENNRVb6OBM_seg_65_75.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"duck (to evade a responsibility or an object)\", \"roles\": {\"1\": \"Arg0 (evader)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (evader)\": \"a long dark haired woman and the soldier\", \"ArgM (direction)\": \"down and backwards\", \"Scene of the Event\": \"a city street near a concrete wall\"}}'}]},\n",
       " {'id': 'v_PENNRVb6OBM_seg_65_75_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_PENNRVb6OBM_seg_65_75.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"run (walk quickly, a course or contest)\", \"roles\": {\"1\": \"Arg0 (runner)\", \"2\": \"Arg1 (course, race, distance)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (goal)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (runner)\": \"a long dark haired woman, a dark haired man and the soldier\", \"Arg1 (course, race, distance)\": \"along a city street\", \"ArgM (direction)\": \"away from their previous location outside of frame\", \"ArgM (goal)\": \"towards another location outside of frame\", \"Scene of the Event\": \"near a building\"}}'}]},\n",
       " {'id': 'v_PENNRVb6OBM_seg_65_75_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_PENNRVb6OBM_seg_65_75.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fly (fly through the air, travel via air)\", \"roles\": {\"1\": \"Arg1 (thing actually doing the flying)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing actually doing the flying)\": \"a spaceship\", \"ArgM (direction)\": \"towards a long dark haired woman, a dark haired man and the soldier\", \"ArgM (location)\": \"a city street near burning building\", \"ArgM (manner)\": \"slowly\"}}'}]},\n",
       " {'id': 'v_ARgghWSmq7Q_seg_20_30_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ARgghWSmq7Q_seg_20_30.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cry (cry, weep)\", \"roles\": {\"1\": \"Arg0 (cryer)\", \"2\": \"ArgM (manner)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cryer)\": \"man in blue pajamas\", \"ArgM (manner)\": \"visibly upset\", \"Scene of the Event\": \"in a hospital room\"}}'}]},\n",
       " {'id': 'v_ARgghWSmq7Q_seg_20_30_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ARgghWSmq7Q_seg_20_30.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"assist (help, assist)\", \"roles\": {\"1\": \"Arg0 (assistant)\", \"2\": \"Arg1 (assisted)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (assistant)\": \"man in white doctors coat\", \"Arg1 (assisted)\": \"man in blue pajamas to the bed\", \"Scene of the Event\": \"in a hospital room\"}}'}]},\n",
       " {'id': 'v_ARgghWSmq7Q_seg_20_30_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ARgghWSmq7Q_seg_20_30.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"grab (to capture, obtain)\", \"roles\": {\"1\": \"Arg0 (grabber)\", \"2\": \"Arg1 (entity grabbed)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (grabber)\": \"woman in nurse outfit\", \"Arg1 (entity grabbed)\": \"a big needle\", \"ArgM (location)\": \"off the table\", \"ArgM (manner)\": \"quickly\"}}'}]},\n",
       " {'id': 'v_ARgghWSmq7Q_seg_20_30_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ARgghWSmq7Q_seg_20_30.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hurt (be experiencing pain)\", \"roles\": {\"1\": \"Arg1 (patient, entity experiencing pain)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (patient, entity experiencing pain)\": \"man in blue pajamas\", \"Scene of the Event\": \"in a hospital room\"}}'}]},\n",
       " {'id': 'v_ARgghWSmq7Q_seg_20_30_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ARgghWSmq7Q_seg_20_30.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"woman in nurse outfit\", \"Arg2 (hearer)\": \"man in white doctors coat\", \"ArgM (manner)\": \"holding a big needle\", \"Scene of the Event\": \"in a hospital room\"}}'}]},\n",
       " {'id': 'v_vG8-BVdJ9_U_seg_10_20_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_vG8-BVdJ9_U_seg_10_20.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"battle (fight (with))\", \"roles\": {\"1\": \"Arg0 (combatant)\", \"2\": \"Arg1 (fight or other combatant, if separate)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (combatant)\": \"Army on horses\", \"Arg1 (fight or other combatant, if separate)\": \"enemy in the distance\", \"Scene of the Event\": \"hillside\"}}'}]},\n",
       " {'id': 'v_vG8-BVdJ9_U_seg_10_20_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_vG8-BVdJ9_U_seg_10_20.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"charge (walk quickly)\", \"roles\": {\"1\": \"Arg0 (runner)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (runner)\": \"lady on horse back in red outfit\", \"ArgM (direction)\": \"forward\", \"Scene of the Event\": \"hillside\"}}'}]},\n",
       " {'id': 'v_vG8-BVdJ9_U_seg_10_20_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_vG8-BVdJ9_U_seg_10_20.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"lady on horse back in red outfit\", \"Arg1 (thing looked at or for or on)\": \"forward down the battlefield\", \"ArgM (direction)\": \"in front\", \"ArgM (manner)\": \"readying for abttle\", \"Scene of the Event\": \"hillside\"}}'}]},\n",
       " {'id': 'v_vG8-BVdJ9_U_seg_10_20_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_vG8-BVdJ9_U_seg_10_20.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"drag ((try to) cause motion)\", \"roles\": {\"1\": \"Arg0 (dragger)\", \"2\": \"Arg1 (thing dragged)\", \"3\": \"Arg2 (direction)\", \"4\": \"ArgM (goal)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (dragger)\": \"horse\", \"Arg1 (thing dragged)\": \"object made out of sticks\", \"Arg2 (direction)\": \"forward\", \"ArgM (goal)\": \"-\", \"Scene of the Event\": \"battlefield\"}}'}]},\n",
       " {'id': 'v_vG8-BVdJ9_U_seg_10_20_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_vG8-BVdJ9_U_seg_10_20.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"ride (as a horse)\", \"roles\": {\"1\": \"Arg0 (rider)\", \"2\": \"Arg1 (steed)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (rider)\": \"Man in gray blue outfit\", \"Arg1 (steed)\": \"brown horse\", \"ArgM (direction)\": \"forward\", \"ArgM (manner)\": \"hurrying\", \"Scene of the Event\": \"battlefield\"}}'}]},\n",
       " {'id': 'v_PJQgGszBO9s_seg_110_120_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_PJQgGszBO9s_seg_110_120.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a white dress shirt and tie\", \"Arg2 (hearer)\": \"man in a suit with a blue tie\", \"ArgM (manner)\": \"emotionally\", \"Scene of the Event\": \"in a boardroom\"}}'}]},\n",
       " {'id': 'v_PJQgGszBO9s_seg_110_120_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_PJQgGszBO9s_seg_110_120.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a white dress shirt and tie\", \"Arg2 (hearer)\": \"man in a suit with a blue tie\", \"ArgM (manner)\": \"emotionally\", \"Scene of the Event\": \"in a boardroom\"}}'}]},\n",
       " {'id': 'v_PJQgGszBO9s_seg_110_120_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_PJQgGszBO9s_seg_110_120.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a white dress shirt and tie\", \"Arg2 (hearer)\": \"man in a suit with a blue tie\", \"ArgM (manner)\": \"emotionally\", \"Scene of the Event\": \"in a boardroom\"}}'}]},\n",
       " {'id': 'v_PJQgGszBO9s_seg_110_120_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_PJQgGszBO9s_seg_110_120.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"watch (look at)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"man in a suit with a blue tie\", \"Arg1 (thing looked at)\": \"man in a white dress shirt and tie\", \"ArgM (manner)\": \"sternly\", \"Scene of the Event\": \"in a boardroom\"}}'}]},\n",
       " {'id': 'v_PJQgGszBO9s_seg_110_120_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_PJQgGszBO9s_seg_110_120.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a white dress shirt and tie\", \"Arg2 (hearer)\": \"man in a suit with a blue tie\", \"ArgM (manner)\": \"emotionally\", \"Scene of the Event\": \"in a boardroom\"}}'}]},\n",
       " {'id': 'v_7d4Sd1W25xs_seg_65_75_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_7d4Sd1W25xs_seg_65_75.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"threaten (threaten)\", \"roles\": {\"1\": \"Arg0 (agent, entity making a threat)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, entity making a threat)\": \"the person in the white mask\", \"Scene of the Event\": \"in a torture room\"}}'}]},\n",
       " {'id': 'v_7d4Sd1W25xs_seg_65_75_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_7d4Sd1W25xs_seg_65_75.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cower (shrink away in fear, cringe)\", \"roles\": {\"1\": \"Arg0 (afraid entity)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (afraid entity)\": \"the woman with the bag on her head\", \"Scene of the Event\": \"in a torture room\"}}'}]},\n",
       " {'id': 'v_7d4Sd1W25xs_seg_65_75_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_7d4Sd1W25xs_seg_65_75.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cower (shrink away in fear, cringe)\", \"roles\": {\"1\": \"Arg0 (afraid entity)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (afraid entity)\": \"the woman with the bag on her head\", \"Scene of the Event\": \"in a torture room\"}}'}]},\n",
       " {'id': 'v_7d4Sd1W25xs_seg_65_75_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_7d4Sd1W25xs_seg_65_75.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"the person in the white mask\", \"Arg2 (hearer)\": \"the woman with the bag on her head\", \"ArgM (manner)\": \"evilly\", \"Scene of the Event\": \"in a torture room\"}}'}]},\n",
       " {'id': 'v_7d4Sd1W25xs_seg_65_75_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_7d4Sd1W25xs_seg_65_75.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"the person in the white mask\", \"Arg2 (hearer)\": \"the woman with the bag on her head\", \"ArgM (manner)\": \"evilly\", \"Scene of the Event\": \"in a torture room\"}}'}]},\n",
       " {'id': 'v_nprJvYKz3QQ_seg_95_105_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_nprJvYKz3QQ_seg_95_105.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stand (rise)\", \"roles\": {\"1\": \"Arg1 (riser)\", \"2\": \"ArgM (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (riser)\": \"man with dark hair\", \"ArgM (location)\": \"up off the ground\", \"ArgM (manner)\": \"pushing himself up with his left hand\"}}'}]},\n",
       " {'id': 'v_nprJvYKz3QQ_seg_95_105_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_nprJvYKz3QQ_seg_95_105.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pick (pick up: acquire)\", \"roles\": {\"1\": \"Arg0 (agent, entity acquiring something)\", \"2\": \"Arg1 (thing acquired)\", \"3\": \"Arg2 (seller)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (agent, entity acquiring something)\": \"woman in a white top\", \"Arg1 (thing acquired)\": \"white hand bag\", \"Arg2 (seller)\": \"-\", \"ArgM (location)\": \"from off the ground\", \"ArgM (manner)\": \"with her right hand\"}}'}]},\n",
       " {'id': 'v_nprJvYKz3QQ_seg_95_105_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_nprJvYKz3QQ_seg_95_105.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"leave (move away from)\", \"roles\": {\"1\": \"Arg0 (entity leaving)\", \"2\": \"Arg1 (place, person, or thing left)\", \"3\": \"Arg2 (attribute of arg1)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (entity leaving)\": \"woman in a white top\", \"Arg1 (place, person, or thing left)\": \"man with dark hair\", \"Arg2 (attribute of arg1)\": \"distractedly\", \"ArgM (location)\": \"around the corner\"}}'}]},\n",
       " {'id': 'v_nprJvYKz3QQ_seg_95_105_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_nprJvYKz3QQ_seg_95_105.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"tail (follow)\", \"roles\": {\"1\": \"Arg0 (follower, tailer)\", \"2\": \"Arg1 (followed, tailed)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (follower, tailer)\": \"man with dark hair\", \"Arg1 (followed, tailed)\": \"woman in a white top\", \"ArgM (location)\": \"around the corner\"}}'}]},\n",
       " {'id': 'v_nprJvYKz3QQ_seg_95_105_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_nprJvYKz3QQ_seg_95_105.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"search (search, seek)\", \"roles\": {\"1\": \"Arg0 (searcher)\", \"2\": \"Arg1 (Area searched)\", \"3\": \"Arg2 (searched for)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (searcher)\": \"woman in a white top\", \"Arg1 (Area searched)\": \"white hand bag\", \"Arg2 (searched for)\": \"-\", \"ArgM (location)\": \"inside\"}}'}]},\n",
       " {'id': 'v_gNSs_gF1T_Q_seg_50_60_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gNSs_gF1T_Q_seg_50_60.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man in a black shirt\", \"ArgM (direction)\": \"forward\", \"ArgM (manner)\": \"while grabbing something out of his mouth\", \"Scene of the Event\": \"in a kitchen\"}}'}]},\n",
       " {'id': 'v_gNSs_gF1T_Q_seg_50_60_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gNSs_gF1T_Q_seg_50_60.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"throw (throw)\", \"roles\": {\"1\": \"Arg0 (thrower)\", \"2\": \"Arg1 (thing thrown)\", \"3\": \"Arg2 (thrown at, to, over, etc)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (thrower)\": \"man in a black shirt\", \"Arg1 (thing thrown)\": \"something\", \"Arg2 (thrown at, to, over, etc)\": \"to the ground\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"in a kitchen\"}}'}]},\n",
       " {'id': 'v_gNSs_gF1T_Q_seg_50_60_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gNSs_gF1T_Q_seg_50_60.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a black shirt\", \"Arg2 (hearer)\": \"woman in a white shirt\", \"ArgM (manner)\": \"while walking forward\", \"Scene of the Event\": \"in a kitchen\"}}'}]},\n",
       " {'id': 'v_gNSs_gF1T_Q_seg_50_60_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gNSs_gF1T_Q_seg_50_60.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a black shirt\", \"Arg2 (hearer)\": \"woman in a white shirt\", \"ArgM (manner)\": \"while walking towards her\", \"Scene of the Event\": \"in a kitchen\"}}'}]},\n",
       " {'id': 'v_gNSs_gF1T_Q_seg_50_60_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gNSs_gF1T_Q_seg_50_60.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a black shirt\", \"Arg2 (hearer)\": \"woman in a white shirt\", \"ArgM (manner)\": \"while grabbing her face\", \"Scene of the Event\": \"in a kitchen\"}}'}]},\n",
       " {'id': 'v_JEbShXn2-Vs_seg_35_45_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_JEbShXn2-Vs_seg_35_45.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"scoot (move moderately quickly)\", \"roles\": {\"1\": \"Arg0 (entity in motion)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity in motion)\": \"man with  glasses\", \"ArgM (direction)\": \"backwards\", \"Scene of the Event\": \"corner\"}}'}]},\n",
       " {'id': 'v_JEbShXn2-Vs_seg_35_45_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_JEbShXn2-Vs_seg_35_45.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"grab (to capture, obtain)\", \"roles\": {\"1\": \"Arg0 (grabber)\", \"2\": \"Arg1 (entity grabbed)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (grabber)\": \"man in green\", \"Arg1 (entity grabbed)\": \"wall\", \"ArgM (location)\": \"wooden wall\", \"ArgM (manner)\": \"scared\"}}'}]},\n",
       " {'id': 'v_JEbShXn2-Vs_seg_35_45_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_JEbShXn2-Vs_seg_35_45.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"terrify (scare very badly)\", \"roles\": {\"1\": \"Arg1 (terrified entity)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (terrified entity)\": \"man with  glasses\", \"Scene of the Event\": \"corner\"}}'}]},\n",
       " {'id': 'v_JEbShXn2-Vs_seg_35_45_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_JEbShXn2-Vs_seg_35_45.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"man with  glasses\", \"Arg2 (hearer)\": \"man in green\", \"ArgM (location)\": \"corner\", \"ArgM (manner)\": \"scared\"}}'}]},\n",
       " {'id': 'v_JEbShXn2-Vs_seg_35_45_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_JEbShXn2-Vs_seg_35_45.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stand (rise)\", \"roles\": {\"1\": \"Arg1 (riser)\", \"2\": \"ArgM (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (riser)\": \"man with  glasses\", \"ArgM (location)\": \"corner\", \"ArgM (manner)\": \"scared\"}}'}]},\n",
       " {'id': 'v_JEbShXn2-Vs_seg_150_160_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_JEbShXn2-Vs_seg_150_160.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"anger (to make angry)\", \"roles\": {\"1\": \"Arg1 (experiencer)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (experiencer)\": \"a man wearing a brown jacket\", \"Scene of the Event\": \"outside of a house\"}}'}]},\n",
       " {'id': 'v_JEbShXn2-Vs_seg_150_160_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_JEbShXn2-Vs_seg_150_160.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"anger (to make angry)\", \"roles\": {\"1\": \"Arg1 (experiencer)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (experiencer)\": \"a man wearing a brown jacket\", \"Scene of the Event\": \"outside of a house\"}}'}]},\n",
       " {'id': 'v_JEbShXn2-Vs_seg_150_160_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_JEbShXn2-Vs_seg_150_160.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"restrain (stop, prevent)\", \"roles\": {\"1\": \"Arg0 (Agent)\", \"2\": \"Arg1 (Theme (action or object being prevented))\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Agent)\": \"a man wearing glasses\", \"Arg1 (Theme (action or object being prevented))\": \"a man wearing a brown jacket\", \"Scene of the Event\": \"outside of a house\"}}'}]},\n",
       " {'id': 'v_JEbShXn2-Vs_seg_150_160_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_JEbShXn2-Vs_seg_150_160.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"prevent (stop, prevent)\", \"roles\": {\"1\": \"Arg0 (Agent)\", \"2\": \"Arg1 (Theme (action or object being prevented))\", \"3\": \"Arg2 (secondary predication or action)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Agent)\": \"a man wearing glasses\", \"Arg1 (Theme (action or object being prevented))\": \"a man wearing a brown jacket\", \"Arg2 (secondary predication or action)\": \"from going after someone\", \"Scene of the Event\": \"outside of a house\"}}'}]},\n",
       " {'id': 'v_JEbShXn2-Vs_seg_150_160_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_JEbShXn2-Vs_seg_150_160.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"prevent (stop, prevent)\", \"roles\": {\"1\": \"Arg0 (Agent)\", \"2\": \"Arg1 (Theme (action or object being prevented))\", \"3\": \"Arg2 (secondary predication or action)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Agent)\": \"a man wearing glasses\", \"Arg1 (Theme (action or object being prevented))\": \"a man wearing a brown jacket\", \"Arg2 (secondary predication or action)\": \"from going after someone\", \"Scene of the Event\": \"outside of a house\"}}'}]},\n",
       " {'id': 'v_8zYGzyIpue8_seg_75_85_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8zYGzyIpue8_seg_75_85.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fly (fly through the air, travel via air)\", \"roles\": {\"1\": \"Arg1 (thing actually doing the flying)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing actually doing the flying)\": \"the machine\", \"ArgM (direction)\": \"forward\", \"ArgM (location)\": \"in the air\", \"ArgM (manner)\": \"speedily\"}}'}]},\n",
       " {'id': 'v_8zYGzyIpue8_seg_75_85_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8zYGzyIpue8_seg_75_85.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cycle (to ride a bicycle)\", \"roles\": {\"1\": \"Arg0 (cyclist, agent)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cyclist, agent)\": \"the man wearing the black jacket\", \"ArgM (direction)\": \"forward\", \"Scene of the Event\": \"on the road\"}}'}]},\n",
       " {'id': 'v_8zYGzyIpue8_seg_75_85_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8zYGzyIpue8_seg_75_85.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fly (fly through the air, travel via air)\", \"roles\": {\"1\": \"Arg1 (thing actually doing the flying)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing actually doing the flying)\": \"the bike and the man wearing the black jacket\", \"ArgM (direction)\": \"forward\", \"ArgM (location)\": \"in the air\", \"ArgM (manner)\": \"speedily\"}}'}]},\n",
       " {'id': 'v_8zYGzyIpue8_seg_75_85_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8zYGzyIpue8_seg_75_85.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"land (bring to land, from water or air)\", \"roles\": {\"1\": \"Arg1 (thing landing)\", \"2\": \"ArgM (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing landing)\": \"the bike and the man wearing the black jacket\", \"ArgM (location)\": \"on the road\", \"ArgM (manner)\": \"stylishly\"}}'}]},\n",
       " {'id': 'v_8zYGzyIpue8_seg_75_85_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_8zYGzyIpue8_seg_75_85.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cycle (to ride a bicycle)\", \"roles\": {\"1\": \"Arg0 (cyclist, agent)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cyclist, agent)\": \"the man wearing the black jacket\", \"ArgM (direction)\": \"forward\", \"Scene of the Event\": \"on the road\"}}'}]},\n",
       " {'id': 'v_XhwgtlCns34_seg_45_55_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XhwgtlCns34_seg_45_55.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"woman with long skirt\", \"ArgM (direction)\": \"walks forward\", \"ArgM (manner)\": \"with wide steps\", \"Scene of the Event\": \"in an art gallery\"}}'}]},\n",
       " {'id': 'v_XhwgtlCns34_seg_45_55_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XhwgtlCns34_seg_45_55.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"enter (enter, go in)\", \"roles\": {\"1\": \"Arg0 (entity entering)\", \"2\": \"Arg1 (place or thing entered)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity entering)\": \"woman with long skirt and child\", \"Arg1 (place or thing entered)\": \"enter a large room\", \"ArgM (manner)\": \"while walking with purpose\", \"Scene of the Event\": \"in an art gallery\"}}'}]},\n",
       " {'id': 'v_XhwgtlCns34_seg_45_55_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XhwgtlCns34_seg_45_55.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lead (directed motion)\", \"roles\": {\"1\": \"Arg0 (leader)\", \"2\": \"Arg1 (thing led)\", \"3\": \"Arg4 (end point)\", \"4\": \"ArgM (direction)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (leader)\": \"woman with long skirt\", \"Arg1 (thing led)\": \"leads child\", \"Arg4 (end point)\": \"toward a particular painting\", \"ArgM (direction)\": \"across the room\", \"Scene of the Event\": \"in an art gallery\"}}'}]},\n",
       " {'id': 'v_XhwgtlCns34_seg_45_55_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XhwgtlCns34_seg_45_55.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lead (directed motion)\", \"roles\": {\"1\": \"Arg0 (leader)\", \"2\": \"Arg1 (thing led)\", \"3\": \"Arg4 (end point)\", \"4\": \"ArgM (direction)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (leader)\": \"woman with long skirt\", \"Arg1 (thing led)\": \"leads child\", \"Arg4 (end point)\": \"toward a particular painting\", \"ArgM (direction)\": \"across the room\", \"Scene of the Event\": \"in an art gallery\"}}'}]},\n",
       " {'id': 'v_XhwgtlCns34_seg_45_55_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_XhwgtlCns34_seg_45_55.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"halt (stop)\", \"roles\": {\"1\": \"Arg0 (causer of stopping)\", \"2\": \"Arg1 (Theme (action or object being stopped))\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of stopping)\": \"woman with long skirt\", \"Arg1 (Theme (action or object being stopped))\": \"comes to a stop in front of the painting\", \"Scene of the Event\": \"in an art gallery\"}}'}]},\n",
       " {'id': 'v_SMJqQ3VrcCA_seg_145_155_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_SMJqQ3VrcCA_seg_145_155.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"rock (tremble)\", \"roles\": {\"1\": \"Arg0 (causer of trembling motion)\", \"2\": \"Arg1 (thing trembling)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of trembling motion)\": \"the waves\", \"Arg1 (thing trembling)\": \"rock a rowboat\", \"Scene of the Event\": \"on a body of water in the fog\"}}'}]},\n",
       " {'id': 'v_SMJqQ3VrcCA_seg_145_155_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_SMJqQ3VrcCA_seg_145_155.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"reach (stretch, grasp)\", \"roles\": {\"1\": \"Arg0 (reacher)\", \"2\": \"Arg1 (body part)\", \"3\": \"Arg2 (goal)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (purpose)\", \"6\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (reacher)\": \"woman wrapped in a shawl\", \"Arg1 (body part)\": \"reaches her arm\", \"Arg2 (goal)\": \"to man with brown hair\", \"ArgM (direction)\": \"out\", \"ArgM (purpose)\": \"to try to alert him\", \"Scene of the Event\": \"on a rowboat in the fog\"}}'}]},\n",
       " {'id': 'v_SMJqQ3VrcCA_seg_145_155_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_SMJqQ3VrcCA_seg_145_155.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"woman wrapped in a shawl\", \"Arg2 (hearer)\": \"speaks to man with brown hair\", \"ArgM (location)\": \"in front of her\", \"ArgM (manner)\": \"while gazing behind him\"}}'}]},\n",
       " {'id': 'v_SMJqQ3VrcCA_seg_145_155_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_SMJqQ3VrcCA_seg_145_155.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"smile (to have or form a smile)\", \"roles\": {\"1\": \"Arg0 (agent smiling)\", \"2\": \"Arg2 (smiled at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent smiling)\": \"woman wrapped in a shawl\", \"Arg2 (smiled at)\": \"smiles to herself\", \"ArgM (manner)\": \"while looking at something behind the man with brown hair\", \"Scene of the Event\": \"on a rowboat in the fog\"}}'}]},\n",
       " {'id': 'v_SMJqQ3VrcCA_seg_145_155_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_SMJqQ3VrcCA_seg_145_155.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"woman wrapped in a shawl\", \"Arg2 (hearer)\": \"speaks to man with brown hair\", \"ArgM (location)\": \"in front of her\", \"ArgM (manner)\": \"while reaching her arm towards him\"}}'}]},\n",
       " {'id': 'v_rFy2252ierA_seg_10_20_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_rFy2252ierA_seg_10_20.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"drive (drive a vehicle)\", \"roles\": {\"1\": \"Arg0 (driver)\", \"2\": \"Arg1 (vehicle or path)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (driver)\": \"man\", \"Arg1 (vehicle or path)\": \"rv\", \"ArgM (direction)\": \"down the road\", \"ArgM (manner)\": \"bored\", \"Scene of the Event\": \"rv\"}}'}]},\n",
       " {'id': 'v_rFy2252ierA_seg_10_20_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_rFy2252ierA_seg_10_20.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"approach (move towards)\", \"roles\": {\"1\": \"Arg1 (entity in motion)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity in motion)\": \"woman\", \"Arg2 (destination)\": \"passenger seat of rv\", \"ArgM (direction)\": \"towards the front of the rv\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"rv\"}}'}]},\n",
       " {'id': 'v_rFy2252ierA_seg_10_20_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_rFy2252ierA_seg_10_20.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sit (be in a position)\", \"roles\": {\"1\": \"Arg1 (thing sitting)\", \"2\": \"Arg2 (location or position)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing sitting)\": \"woman\", \"Arg2 (location or position)\": \"passenger seat of rv\", \"ArgM (manner)\": \"quickly\"}}'}]},\n",
       " {'id': 'v_rFy2252ierA_seg_10_20_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_rFy2252ierA_seg_10_20.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"proffer (offer, give)\", \"roles\": {\"1\": \"Arg0 (giver)\", \"2\": \"Arg1 (thing given)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (giver)\": \"woman\", \"Arg1 (thing given)\": \"sandwich\", \"Scene of the Event\": \"rv\"}}'}]},\n",
       " {'id': 'v_rFy2252ierA_seg_10_20_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_rFy2252ierA_seg_10_20.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"bite (to cut or tear with or as if with the teeth )\", \"roles\": {\"1\": \"Arg0 (biter, agent)\", \"2\": \"Arg1 (entity bitten)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (biter, agent)\": \"man\", \"Arg1 (entity bitten)\": \"sandwich\", \"Scene of the Event\": \"rv\"}}'}]},\n",
       " {'id': 'v_pnaWqq2eRcc_seg_120_130_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_pnaWqq2eRcc_seg_120_130.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"glance (look at briefly)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked-at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"blonde haired woman driving a car\", \"Arg1 (looked-at)\": \"a phone ringing in her car\", \"ArgM (direction)\": \"down\", \"ArgM (manner)\": \"curiously\", \"Scene of the Event\": \"in a vehicle\"}}'}]},\n",
       " {'id': 'v_pnaWqq2eRcc_seg_120_130_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_pnaWqq2eRcc_seg_120_130.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pick (pick up: acquire)\", \"roles\": {\"1\": \"Arg0 (agent, entity acquiring something)\", \"2\": \"Arg1 (thing acquired)\", \"3\": \"Arg2 (seller)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (agent, entity acquiring something)\": \"blonde haired woman driving a car\", \"Arg1 (thing acquired)\": \"a phone receiver\", \"Arg2 (seller)\": \"from the cars console\", \"ArgM (location)\": \"between the seats\", \"ArgM (manner)\": \"carefully\"}}'}]},\n",
       " {'id': 'v_pnaWqq2eRcc_seg_120_130_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_pnaWqq2eRcc_seg_120_130.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"inquire (to ask about)\", \"roles\": {\"1\": \"Arg0 (asker)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (asker)\": \"blonde haired woman driving a car  on the motive of the caller\", \"Scene of the Event\": \"in a vehicle\"}}'}]},\n",
       " {'id': 'v_pnaWqq2eRcc_seg_120_130_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_pnaWqq2eRcc_seg_120_130.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a white stripped shirt\", \"Arg2 (hearer)\": \"blonde haired woman driving a car\", \"ArgM (manner)\": \"all flustered\", \"Scene of the Event\": \"in an office\"}}'}]},\n",
       " {'id': 'v_pnaWqq2eRcc_seg_120_130_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_pnaWqq2eRcc_seg_120_130.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"respond (give an answer, reply)\", \"roles\": {\"1\": \"Arg0 (replier)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (replier)\": \"blonde haired woman driving a car\", \"Scene of the Event\": \"in a vehicle\"}}'}]},\n",
       " {'id': 'v_yvcIugB8yt4_seg_85_95_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_yvcIugB8yt4_seg_85_95.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"converse (make conversation)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"Woman\", \"Scene of the Event\": \"Garden\"}}'}]},\n",
       " {'id': 'v_yvcIugB8yt4_seg_85_95_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_yvcIugB8yt4_seg_85_95.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"gesture (body language)\", \"roles\": {\"1\": \"Arg0 (gesturer)\", \"2\": \"Arg1 (gestured at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (gesturer)\": \"Man\", \"Arg1 (gestured at)\": \"Woman\", \"Scene of the Event\": \"Garden\"}}'}]},\n",
       " {'id': 'v_yvcIugB8yt4_seg_85_95_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_yvcIugB8yt4_seg_85_95.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"nuzzle (cuddle or snuggle)\", \"roles\": {\"1\": \"Arg0 (hugger)\", \"2\": \"Arg1 (hugged)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (hugger)\": \"Woman\", \"Arg1 (hugged)\": \"Man\", \"Scene of the Event\": \"Garden\"}}'}]},\n",
       " {'id': 'v_yvcIugB8yt4_seg_85_95_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_yvcIugB8yt4_seg_85_95.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"notice (become aware of)\", \"roles\": {\"1\": \"Arg0 (noticer)\", \"2\": \"Arg1 (noticed)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (noticer)\": \"Couple\", \"Arg1 (noticed)\": \"Old Man\", \"ArgM (location)\": \"Garden\"}}'}]},\n",
       " {'id': 'v_yvcIugB8yt4_seg_85_95_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_yvcIugB8yt4_seg_85_95.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"near (to approach)\", \"roles\": {\"1\": \"Arg1 (entity in motion)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity in motion)\": \"Old Man\", \"Scene of the Event\": \"Garden\"}}'}]},\n",
       " {'id': 'v_fluKR9XbEjQ_seg_10_20_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_fluKR9XbEjQ_seg_10_20.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"man with beard\", \"Arg2 (hearer)\": \"-\", \"ArgM (location)\": \"office\", \"ArgM (manner)\": \"with confidence\"}}'}]},\n",
       " {'id': 'v_fluKR9XbEjQ_seg_10_20_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_fluKR9XbEjQ_seg_10_20.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man in coat and red hat\", \"ArgM (direction)\": \"towards store\", \"ArgM (manner)\": \"briskly\", \"Scene of the Event\": \"city street\"}}'}]},\n",
       " {'id': 'v_fluKR9XbEjQ_seg_10_20_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_fluKR9XbEjQ_seg_10_20.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"enter (enter, go in)\", \"roles\": {\"1\": \"Arg0 (entity entering)\", \"2\": \"Arg1 (place or thing entered)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity entering)\": \"man in coat and red hat\", \"Arg1 (place or thing entered)\": \"store\", \"ArgM (manner)\": \"briskly\", \"Scene of the Event\": \"city street\"}}'}]},\n",
       " {'id': 'v_fluKR9XbEjQ_seg_10_20_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_fluKR9XbEjQ_seg_10_20.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"leave (move away from)\", \"roles\": {\"1\": \"Arg0 (entity leaving)\", \"2\": \"Arg1 (place, person, or thing left)\", \"3\": \"Arg2 (attribute of arg1)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (entity leaving)\": \"policeman\", \"Arg1 (place, person, or thing left)\": \"store\", \"Arg2 (attribute of arg1)\": \"from the\", \"ArgM (location)\": \"city street\"}}'}]},\n",
       " {'id': 'v_fluKR9XbEjQ_seg_10_20_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_fluKR9XbEjQ_seg_10_20.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"examine (look at closely)\", \"roles\": {\"1\": \"Arg0 (examiner)\", \"2\": \"Arg1 (thing examined)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (examiner)\": \"man in coat and red hat\", \"Arg1 (thing examined)\": \"gun\", \"ArgM (manner)\": \"with knowledge\", \"Scene of the Event\": \"inside gun store\"}}'}]},\n",
       " {'id': 'v_qbdg6o8Z11I_seg_115_125_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_qbdg6o8Z11I_seg_115_125.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"collapse (fall down)\", \"roles\": {\"1\": \"Arg1 (thing collapsing)\", \"2\": \"ArgM (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing collapsing)\": \"air vent\", \"ArgM (location)\": \"middle of restaurant\", \"ArgM (manner)\": \"falling down on a person\"}}'}]},\n",
       " {'id': 'v_qbdg6o8Z11I_seg_115_125_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_qbdg6o8Z11I_seg_115_125.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"flee (run away (from))\", \"roles\": {\"1\": \"Arg0 (fleer, runner)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (fleer, runner)\": \"man in chef outfit\", \"Scene of the Event\": \"restaurant\"}}'}]},\n",
       " {'id': 'v_qbdg6o8Z11I_seg_115_125_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_qbdg6o8Z11I_seg_115_125.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"track (follow)\", \"roles\": {\"1\": \"Arg0 (thing following)\", \"2\": \"Arg1 (thing followed)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (thing following)\": \"men in suits\", \"Arg1 (thing followed)\": \"man in chef outfit\", \"Scene of the Event\": \"restaurant\"}}'}]},\n",
       " {'id': 'v_qbdg6o8Z11I_seg_115_125_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_qbdg6o8Z11I_seg_115_125.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"kick (drive or impel with the foot)\", \"roles\": {\"1\": \"Arg0 (kicker)\", \"2\": \"Arg1 (thing kicked)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (kicker)\": \"man in suit\", \"Arg1 (thing kicked)\": \"man with dark hair\", \"ArgM (direction)\": \"up\", \"ArgM (location)\": \"chest\", \"ArgM (manner)\": \"using both feet\"}}'}]},\n",
       " {'id': 'v_qbdg6o8Z11I_seg_115_125_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_qbdg6o8Z11I_seg_115_125.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"strike (hit)\", \"roles\": {\"1\": \"Arg0 (agent, hitter - animate only!)\", \"2\": \"Arg1 (thing hit)\", \"3\": \"Arg2 (instrument, thing hit by or with)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, hitter - animate only!)\": \"woman\", \"Arg1 (thing hit)\": \"man with dark suit\", \"Arg2 (instrument, thing hit by or with)\": \"fist\", \"Scene of the Event\": \"restaurant\"}}'}]},\n",
       " {'id': 'v_qcFM5Xhg8W8_seg_150_160_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_qcFM5Xhg8W8_seg_150_160.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"loom (appear in a threatening manner)\", \"roles\": {\"1\": \"Arg1 (thing looming, esp \\'disaster\\')\", \"2\": \"ArgM (location)\"}, \"nouns\": {\"Arg1 (thing looming, esp \\'disaster\\')\": \"the monster in the black hat\", \"ArgM (location)\": \"by the man laying on the ground\"}}'}]},\n",
       " {'id': 'v_qcFM5Xhg8W8_seg_150_160_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_qcFM5Xhg8W8_seg_150_160.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cut (slice)\", \"roles\": {\"1\": \"Arg0 (cutter)\", \"2\": \"Arg1 (thing cut)\", \"3\": \"Arg2 (medium, source)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cutter)\": \"the monster in the black hat\", \"Arg1 (thing cut)\": \"by the man laying on the ground\", \"Arg2 (medium, source)\": \"with his hand\", \"ArgM (manner)\": \"violently\", \"Scene of the Event\": \"in an office\"}}'}]},\n",
       " {'id': 'v_qcFM5Xhg8W8_seg_150_160_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_qcFM5Xhg8W8_seg_150_160.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"gloat (to feel or express great self-satisfaction)\", \"roles\": {\"1\": \"Arg0 (person gloating)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (person gloating)\": \"the monster in the black hat\", \"Scene of the Event\": \"in an office\"}}'}]},\n",
       " {'id': 'v_qcFM5Xhg8W8_seg_150_160_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_qcFM5Xhg8W8_seg_150_160.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"peer (to look searchingly)\", \"roles\": {\"1\": \"Arg0 (looker, searcher, agent)\", \"2\": \"Arg1 (entity peered into/at/over...)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker, searcher, agent)\": \"the monster in the black hat\", \"Arg1 (entity peered into/at/over...)\": \"the gold\", \"ArgM (direction)\": \"in the man\\'s stomach\", \"ArgM (manner)\": \"happily\", \"Scene of the Event\": \"in an office\"}}'}]},\n",
       " {'id': 'v_qcFM5Xhg8W8_seg_150_160_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_qcFM5Xhg8W8_seg_150_160.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shock (surprise)\", \"roles\": {\"1\": \"Arg1 (person surprised)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (person surprised)\": \"the man laying on the ground\", \"Scene of the Event\": \"in an office\"}}'}]},\n",
       " {'id': 'v_v7FL42Fon3g_seg_0_10_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_v7FL42Fon3g_seg_0_10.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"alert (alert, warn)\", \"roles\": {\"1\": \"Arg0 (entity giving warning)\", \"2\": \"Arg1 (entity getting warning)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity giving warning)\": \"woman in red dress\", \"Arg1 (entity getting warning)\": \"man in wheelchair\", \"Scene of the Event\": \"window of apartment.\"}}'}]},\n",
       " {'id': 'v_v7FL42Fon3g_seg_0_10_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_v7FL42Fon3g_seg_0_10.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pack (fill, load)\", \"roles\": {\"1\": \"Arg0 (packer, agent)\", \"2\": \"Arg1 (beast of burden)\", \"3\": \"Arg2 (cargo)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (packer, agent)\": \"man in white shirt in another apartment across from them\", \"Arg1 (beast of burden)\": \"suitcase\", \"Arg2 (cargo)\": \"clothes\", \"Scene of the Event\": \"window of apartment.\"}}'}]},\n",
       " {'id': 'v_v7FL42Fon3g_seg_0_10_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_v7FL42Fon3g_seg_0_10.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hand (give)\", \"roles\": {\"1\": \"Arg0 (giver)\", \"2\": \"Arg1 (thing given)\", \"3\": \"Arg2 (entity given to)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (giver)\": \"man in wheelchair\", \"Arg1 (thing given)\": \"photographic camera\", \"Arg2 (entity given to)\": \"woman in white and yellow dress\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"window of apartment.\"}}'}]},\n",
       " {'id': 'v_v7FL42Fon3g_seg_0_10_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_v7FL42Fon3g_seg_0_10.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"reverse (turn around, change direction)\", \"roles\": {\"1\": \"Arg0 (causer of reverse)\", \"2\": \"Arg1 (thing turning around)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of reverse)\": \"man in wheelchair\", \"Arg1 (thing turning around)\": \"wheelchair\", \"Scene of the Event\": \"window of apartment.\"}}'}]},\n",
       " {'id': 'v_v7FL42Fon3g_seg_0_10_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_v7FL42Fon3g_seg_0_10.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pick (pick up: acquire)\", \"roles\": {\"1\": \"Arg0 (agent, entity acquiring something)\", \"2\": \"Arg1 (thing acquired)\", \"3\": \"Arg2 (seller)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (agent, entity acquiring something)\": \"woman in white and yellow dress\", \"Arg1 (thing acquired)\": \"something\", \"Arg2 (seller)\": \"-\", \"ArgM (location)\": \"near stove\", \"ArgM (manner)\": \"quickly\"}}'}]},\n",
       " {'id': 'v_NInjsGq2yCA_seg_85_95_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NInjsGq2yCA_seg_85_95.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"yell (to cry out loudly)\", \"roles\": {\"1\": \"Arg0 (Yeller)\", \"2\": \"Arg2 (Hearer)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Yeller)\": \"possessed woman in a white dress tied to a bed\", \"Arg2 (Hearer)\": \"two men in the room\", \"Scene of the Event\": \"in a dark lit room\"}}'}]},\n",
       " {'id': 'v_NInjsGq2yCA_seg_85_95_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NInjsGq2yCA_seg_85_95.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sit (be in a position)\", \"roles\": {\"1\": \"Arg1 (thing sitting)\", \"2\": \"Arg2 (location or position)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing sitting)\": \"old man in a blue jacket\", \"Arg2 (location or position)\": \"besides the possessed woman in a white dress tied to a bed\", \"ArgM (manner)\": \"calmly\"}}'}]},\n",
       " {'id': 'v_NInjsGq2yCA_seg_85_95_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NInjsGq2yCA_seg_85_95.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"squirm (mode of motion)\", \"roles\": {\"1\": \"Arg0 (squirmer)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (squirmer)\": \"possessed woman in a white dress tied to a bed\", \"Scene of the Event\": \"in a dark lit room\"}}'}]},\n",
       " {'id': 'v_NInjsGq2yCA_seg_85_95_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NInjsGq2yCA_seg_85_95.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"calm (make calm)\", \"roles\": {\"1\": \"Arg0 (agent of calming)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent of calming)\": \"old man in a blue jacket\", \"Scene of the Event\": \"in a dark lit room\"}}'}]},\n",
       " {'id': 'v_NInjsGq2yCA_seg_85_95_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NInjsGq2yCA_seg_85_95.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"squirm (mode of motion)\", \"roles\": {\"1\": \"Arg0 (squirmer)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (squirmer)\": \"possessed woman in a white dress tied to a bed\", \"Scene of the Event\": \"in a dark lit room\"}}'}]},\n",
       " {'id': 'v_mFcz_U62r6s_seg_55_65_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_mFcz_U62r6s_seg_55_65.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"woman in a black dress\", \"Arg1 (thing looked at or for or on)\": \"clothes\", \"ArgM (direction)\": \"into the closet\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"in a home\"}}'}]},\n",
       " {'id': 'v_mFcz_U62r6s_seg_55_65_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_mFcz_U62r6s_seg_55_65.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"woman in a black dress\", \"ArgM (direction)\": \"away\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"in a home\"}}'}]},\n",
       " {'id': 'v_mFcz_U62r6s_seg_55_65_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_mFcz_U62r6s_seg_55_65.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"woman in a black dress\", \"ArgM (direction)\": \"away\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"in a home\"}}'}]},\n",
       " {'id': 'v_mFcz_U62r6s_seg_55_65_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_mFcz_U62r6s_seg_55_65.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"woman in a black dress\", \"Arg1 (thing looked at or for or on)\": \"woman\", \"ArgM (direction)\": \"into the bathroom\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"in a home\"}}'}]},\n",
       " {'id': 'v_mFcz_U62r6s_seg_55_65_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_mFcz_U62r6s_seg_55_65.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"reach (stretch, grasp)\", \"roles\": {\"1\": \"Arg0 (reacher)\", \"2\": \"Arg1 (body part)\", \"3\": \"Arg2 (goal)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (purpose)\", \"6\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (reacher)\": \"woman in a black jacket\", \"Arg1 (body part)\": \"hand\", \"Arg2 (goal)\": \"shower lever\", \"ArgM (direction)\": \"forward\", \"ArgM (purpose)\": \"turn on the shower\", \"Scene of the Event\": \"the bathroom\"}}'}]},\n",
       " {'id': 'v_ifPpI0fXMlw_seg_185_195_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ifPpI0fXMlw_seg_185_195.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"advertise (make a commercial pitch)\", \"roles\": {\"1\": \"Arg1 (thing being pitched, advertised)\", \"2\": \"ArgM (location)\"}, \"nouns\": {\"Arg1 (thing being pitched, advertised)\": \"on the TV\", \"ArgM (location)\": \"somewhere\"}}'}]},\n",
       " {'id': 'v_ifPpI0fXMlw_seg_185_195_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ifPpI0fXMlw_seg_185_195.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"advertise (make a commercial pitch)\", \"roles\": {\"1\": \"Arg1 (thing being pitched, advertised)\", \"2\": \"ArgM (location)\"}, \"nouns\": {\"Arg1 (thing being pitched, advertised)\": \"on the TV\", \"ArgM (location)\": \"somewhere\"}}'}]},\n",
       " {'id': 'v_ifPpI0fXMlw_seg_185_195_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ifPpI0fXMlw_seg_185_195.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"advertise (make a commercial pitch)\", \"roles\": {\"1\": \"Arg1 (thing being pitched, advertised)\", \"2\": \"ArgM (location)\"}, \"nouns\": {\"Arg1 (thing being pitched, advertised)\": \"on the TV\", \"ArgM (location)\": \"somewhere\"}}'}]},\n",
       " {'id': 'v_ifPpI0fXMlw_seg_185_195_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ifPpI0fXMlw_seg_185_195.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"advertise (make a commercial pitch)\", \"roles\": {\"1\": \"Arg1 (thing being pitched, advertised)\", \"2\": \"ArgM (location)\"}, \"nouns\": {\"Arg1 (thing being pitched, advertised)\": \"on the TV\", \"ArgM (location)\": \"somewhere\"}}'}]},\n",
       " {'id': 'v_ifPpI0fXMlw_seg_185_195_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ifPpI0fXMlw_seg_185_195.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"advertise (make a commercial pitch)\", \"roles\": {\"1\": \"Arg1 (thing being pitched, advertised)\", \"2\": \"ArgM (location)\"}, \"nouns\": {\"Arg1 (thing being pitched, advertised)\": \"on the TV\", \"ArgM (location)\": \"somewhere\"}}'}]},\n",
       " {'id': 'v_ueAsO0Gq8vI_seg_55_65_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ueAsO0Gq8vI_seg_55_65.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"move (change location)\", \"roles\": {\"1\": \"Arg1 (moved)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (moved)\": \"camera\", \"Arg2 (destination)\": \"unknown\", \"ArgM (direction)\": \"along the road\", \"ArgM (manner)\": \"swiftly\", \"Scene of the Event\": \"a road through a farm\"}}'}]},\n",
       " {'id': 'v_ueAsO0Gq8vI_seg_55_65_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ueAsO0Gq8vI_seg_55_65.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"approach (move towards)\", \"roles\": {\"1\": \"Arg1 (entity in motion)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity in motion)\": \"a yellow and black small car\", \"Arg2 (destination)\": \"unknown\", \"ArgM (direction)\": \"towards the camera\", \"ArgM (manner)\": \"fast\", \"Scene of the Event\": \"a road through a farm\"}}'}]},\n",
       " {'id': 'v_ueAsO0Gq8vI_seg_55_65_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ueAsO0Gq8vI_seg_55_65.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"drive (drive a vehicle)\", \"roles\": {\"1\": \"Arg0 (driver)\", \"2\": \"Arg1 (vehicle or path)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (driver)\": \"a woman in a green blouse\", \"Arg1 (vehicle or path)\": \"a yellow and black small car\", \"ArgM (direction)\": \"along a small tree lined road\", \"ArgM (manner)\": \"smilingly\", \"Scene of the Event\": \"a road through a farm\"}}'}]},\n",
       " {'id': 'v_ueAsO0Gq8vI_seg_55_65_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ueAsO0Gq8vI_seg_55_65.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"smile (to have or form a smile)\", \"roles\": {\"1\": \"Arg0 (agent smiling)\", \"2\": \"Arg2 (smiled at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent smiling)\": \"a woman in a green blouse\", \"Arg2 (smiled at)\": \"a man in a brown coat\", \"ArgM (manner)\": \"with joy\", \"Scene of the Event\": \"a road through a farm\"}}'}]},\n",
       " {'id': 'v_ueAsO0Gq8vI_seg_55_65_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ueAsO0Gq8vI_seg_55_65.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"nod (to lower and raise the head or to express by nodding)\", \"roles\": {\"1\": \"Arg0 (entity with a bobbing head, agent)\", \"2\": \"ArgM (manner)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity with a bobbing head, agent)\": \"man in a brown coat\", \"ArgM (manner)\": \"with a smile\", \"Scene of the Event\": \"a road through a farm\"}}'}]},\n",
       " {'id': 'v_DJZqFXSHyvc_seg_60_70_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_DJZqFXSHyvc_seg_60_70.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"ready (prepare)\", \"roles\": {\"1\": \"Arg0 (preparer)\", \"2\": \"Arg1 (thing made ready)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (preparer)\": \"policeman\", \"Arg1 (thing made ready)\": \"himself\", \"Scene of the Event\": \"crime scene area\"}}'}]},\n",
       " {'id': 'v_DJZqFXSHyvc_seg_60_70_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_DJZqFXSHyvc_seg_60_70.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"clean (to free from dirt)\", \"roles\": {\"1\": \"Arg0 (cleaner, agent)\", \"2\": \"Arg1 (thing cleaned)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cleaner, agent)\": \"man with gun\", \"Arg1 (thing cleaned)\": \"window of bus\", \"Scene of the Event\": \"on a bus in crime scene area\"}}'}]},\n",
       " {'id': 'v_DJZqFXSHyvc_seg_60_70_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_DJZqFXSHyvc_seg_60_70.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"target (take aim at)\", \"roles\": {\"1\": \"Arg0 (targeter)\", \"2\": \"Arg1 (thing aimed at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (targeter)\": \"bald policeman\", \"Arg1 (thing aimed at)\": \"towards bus\", \"ArgM (manner)\": \"with gun\", \"Scene of the Event\": \"crime scene area\"}}'}]},\n",
       " {'id': 'v_DJZqFXSHyvc_seg_60_70_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_DJZqFXSHyvc_seg_60_70.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man with gun\", \"ArgM (direction)\": \"towards front of bus\", \"ArgM (manner)\": \"slowly\", \"Scene of the Event\": \"on a bus in crime scene area\"}}'}]},\n",
       " {'id': 'v_DJZqFXSHyvc_seg_60_70_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_DJZqFXSHyvc_seg_60_70.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"wait (wait)\", \"roles\": {\"1\": \"Arg1 (wait-er (not waiter, that\\'s the other sense))\", \"2\": \"Arg2 (thing waited for)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (wait-er (not waiter, that\\'s the other sense))\": \"police\", \"Arg2 (thing waited for)\": \"man with gun\", \"ArgM (location)\": \"crime scene area\", \"ArgM (manner)\": \"with SWAT truck and helicopters\"}}'}]},\n",
       " {'id': 'v_MNWmA8mmbH4_seg_40_50_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MNWmA8mmbH4_seg_40_50.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"withdraw (withdraw, remove oneself)\", \"roles\": {\"1\": \"Arg0 (entity removing)\", \"2\": \"Arg1 (thing being withdrawn (often understood as \\'self\\'))\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity removing)\": \"nurse\", \"Arg1 (thing being withdrawn (often understood as \\'self\\'))\": \"blood\", \"Scene of the Event\": \"hospital\"}}'}]},\n",
       " {'id': 'v_MNWmA8mmbH4_seg_40_50_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MNWmA8mmbH4_seg_40_50.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"remove (remove)\", \"roles\": {\"1\": \"Arg0 (entity removing)\", \"2\": \"Arg1 (thing being removed)\", \"3\": \"Arg2 (removed from)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity removing)\": \"nurse\", \"Arg1 (thing being removed)\": \"oxygen mask\", \"Arg2 (removed from)\": \"babies mouth\", \"Scene of the Event\": \"hospital\"}}'}]},\n",
       " {'id': 'v_MNWmA8mmbH4_seg_40_50_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MNWmA8mmbH4_seg_40_50.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"insert (to put or set into, between, or among)\", \"roles\": {\"1\": \"Arg0 (inserter)\", \"2\": \"Arg1 (entity inserted)\", \"3\": \"Arg2 (location)\"}, \"nouns\": {\"Arg0 (inserter)\": \"nurse\", \"Arg1 (entity inserted)\": \"tube\", \"Arg2 (location)\": \"inside babies nose\"}}'}]},\n",
       " {'id': 'v_MNWmA8mmbH4_seg_40_50_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MNWmA8mmbH4_seg_40_50.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"give (transfer)\", \"roles\": {\"1\": \"Arg0 (giver)\", \"2\": \"Arg1 (thing given)\", \"3\": \"Arg2 (entity given to)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (giver)\": \"nurse\", \"Arg1 (thing given)\": \"shot\", \"Arg2 (entity given to)\": \"baby\", \"Scene of the Event\": \"hospital\"}}'}]},\n",
       " {'id': 'v_MNWmA8mmbH4_seg_40_50_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MNWmA8mmbH4_seg_40_50.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"doctor with dark hair\", \"Arg2 (hearer)\": \"doctor with blonde hair\", \"ArgM (manner)\": \"stepping back from baby\", \"Scene of the Event\": \"examination room\"}}'}]},\n",
       " {'id': 'v_52sXSYdNPsg_seg_20_30_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_52sXSYdNPsg_seg_20_30.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"aim (directed motion)\", \"roles\": {\"1\": \"Arg0 (aimer)\", \"2\": \"Arg1 (thing in motion)\", \"3\": \"Arg2 (target)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (aimer)\": \"A young brunette\", \"Arg1 (thing in motion)\": \"a gun\", \"Arg2 (target)\": \"at a man\", \"Scene of the Event\": \"in a house\"}}'}]},\n",
       " {'id': 'v_52sXSYdNPsg_seg_20_30_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_52sXSYdNPsg_seg_20_30.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"smile (to have or form a smile)\", \"roles\": {\"1\": \"Arg0 (agent smiling)\", \"2\": \"Arg2 (smiled at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent smiling)\": \"The brunette\", \"Arg2 (smiled at)\": \"at the man\", \"ArgM (manner)\": \"crazily\", \"Scene of the Event\": \"in the house\"}}'}]},\n",
       " {'id': 'v_52sXSYdNPsg_seg_20_30_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_52sXSYdNPsg_seg_20_30.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"question (ask a question, express doubts)\", \"roles\": {\"1\": \"Arg0 (asker)\", \"2\": \"Arg2 (entity asked, hearer)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (asker)\": \"The man\", \"Arg2 (entity asked, hearer)\": \"the woman\", \"ArgM (location)\": \"in the house\"}}'}]},\n",
       " {'id': 'v_52sXSYdNPsg_seg_20_30_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_52sXSYdNPsg_seg_20_30.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"The brunette and a blonde woman\", \"Arg1 (thing looked at or for or on)\": \"at the man\", \"ArgM (direction)\": \"in front of them\", \"ArgM (manner)\": \"entertained\", \"Scene of the Event\": \"in the house\"}}'}]},\n",
       " {'id': 'v_52sXSYdNPsg_seg_20_30_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_52sXSYdNPsg_seg_20_30.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"rise (go up)\", \"roles\": {\"1\": \"Arg1 (Logical subject, patient, thing rising)\", \"2\": \"Arg3 (start point)\", \"3\": \"Arg4 (end point)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (Logical subject, patient, thing rising)\": \"The man\", \"Arg3 (start point)\": \"from his chair\", \"Arg4 (end point)\": \"to standing\", \"ArgM (manner)\": \"slowly\", \"Scene of the Event\": \"in the house\"}}'}]},\n",
       " {'id': 'v_Epzv2FLSjhk_seg_100_110_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Epzv2FLSjhk_seg_100_110.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man in green shirt\", \"Arg1 (thing looked at or for or on)\": \"weapon\", \"ArgM (direction)\": \"down\", \"ArgM (manner)\": \"serious and angry\", \"Scene of the Event\": \"kitchen\"}}'}]},\n",
       " {'id': 'v_Epzv2FLSjhk_seg_100_110_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Epzv2FLSjhk_seg_100_110.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man in green shirt\", \"ArgM (direction)\": \"down a hallway\", \"ArgM (manner)\": \"carrying his weapon\", \"Scene of the Event\": \"building\"}}'}]},\n",
       " {'id': 'v_Epzv2FLSjhk_seg_100_110_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Epzv2FLSjhk_seg_100_110.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"confront (to engage in confrontation)\", \"roles\": {\"1\": \"Arg0 (confrontational entity, agent)\", \"2\": \"Arg1 (entity confronted)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (confrontational entity, agent)\": \"man in green shirt\", \"Arg1 (entity confronted)\": \"man in dark shirt\", \"Scene of the Event\": \"hallway\"}}'}]},\n",
       " {'id': 'v_Epzv2FLSjhk_seg_100_110_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Epzv2FLSjhk_seg_100_110.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"wrap (enclose)\", \"roles\": {\"1\": \"Arg0 (cause of wrapping)\", \"2\": \"Arg1 (thing wrapped (ie, gift))\", \"3\": \"Arg2 (wrapper (ie, paper))\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cause of wrapping)\": \"man in green shirt\", \"Arg1 (thing wrapped (ie, gift))\": \"girls mouth\", \"Arg2 (wrapper (ie, paper))\": \"cloth\", \"ArgM (manner)\": \"to keep her quiet\", \"Scene of the Event\": \"inside a room\"}}'}]},\n",
       " {'id': 'v_Epzv2FLSjhk_seg_100_110_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Epzv2FLSjhk_seg_100_110.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"drag ((try to) cause motion)\", \"roles\": {\"1\": \"Arg0 (dragger)\", \"2\": \"Arg1 (thing dragged)\", \"3\": \"Arg2 (direction)\", \"4\": \"ArgM (goal)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (dragger)\": \"man in green shirt\", \"Arg1 (thing dragged)\": \"girl\", \"Arg2 (direction)\": \"out of the room\", \"ArgM (goal)\": \"to take her out\", \"Scene of the Event\": \"building\"}}'}]},\n",
       " {'id': 'v_a_iEYXLXbjY_seg_125_135_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_a_iEYXLXbjY_seg_125_135.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"play (play a game/music)\", \"roles\": {\"1\": \"Arg0 (player)\", \"2\": \"Arg1 (game/music)\", \"3\": \"Arg2 (instrument used to play game/music)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (player)\": \"man in yellow jacket\", \"Arg1 (game/music)\": \"music\", \"Arg2 (instrument used to play game/music)\": \"guitar\", \"ArgM (location)\": \"stage\", \"ArgM (manner)\": \"intensely\"}}'}]},\n",
       " {'id': 'v_a_iEYXLXbjY_seg_125_135_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_a_iEYXLXbjY_seg_125_135.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"play (play a game/music)\", \"roles\": {\"1\": \"Arg0 (player)\", \"2\": \"Arg1 (game/music)\", \"3\": \"Arg2 (instrument used to play game/music)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (player)\": \"man in black shirt\", \"Arg1 (game/music)\": \"music\", \"Arg2 (instrument used to play game/music)\": \"guitar\", \"ArgM (location)\": \"stage\", \"ArgM (manner)\": \"intensely\"}}'}]},\n",
       " {'id': 'v_a_iEYXLXbjY_seg_125_135_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_a_iEYXLXbjY_seg_125_135.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sing (sing)\", \"roles\": {\"1\": \"Arg0 (singer)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (singer)\": \"man in suit\", \"Scene of the Event\": \"stage\"}}'}]},\n",
       " {'id': 'v_a_iEYXLXbjY_seg_125_135_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_a_iEYXLXbjY_seg_125_135.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"watch (look at)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"ladies\", \"Arg1 (thing looked at)\": \"man in black shirt\", \"ArgM (manner)\": \"disgustedly\", \"Scene of the Event\": \"in front of stage\"}}'}]},\n",
       " {'id': 'v_a_iEYXLXbjY_seg_125_135_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_a_iEYXLXbjY_seg_125_135.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in suit\", \"Arg2 (hearer)\": \"bandmembers\", \"ArgM (manner)\": \"angrily\", \"Scene of the Event\": \"stage\"}}'}]},\n",
       " {'id': 'v_WgCQS7EllP8_seg_175_185_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WgCQS7EllP8_seg_175_185.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hold (grasp, bear, keep)\", \"roles\": {\"1\": \"Arg0 (holder)\", \"2\": \"Arg1 (thing held)\", \"3\": \"Arg2 (benefactive)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (location)\", \"6\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (holder)\": \"man in white\", \"Arg1 (thing held)\": \"man in black\", \"Arg2 (benefactive)\": \"with his hand\", \"ArgM (direction)\": \"from\", \"ArgM (location)\": \"falling off a cliff\", \"ArgM (manner)\": \"straining\"}}'}]},\n",
       " {'id': 'v_WgCQS7EllP8_seg_175_185_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WgCQS7EllP8_seg_175_185.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"faint (faint, pass out)\", \"roles\": {\"1\": \"Arg0 (fainter)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (fainter)\": \"man in black\", \"Scene of the Event\": \"dangling off a cliff\"}}'}]},\n",
       " {'id': 'v_WgCQS7EllP8_seg_175_185_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WgCQS7EllP8_seg_175_185.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hold (grasp, bear, keep)\", \"roles\": {\"1\": \"Arg0 (holder)\", \"2\": \"Arg1 (thing held)\", \"3\": \"Arg2 (benefactive)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (location)\", \"6\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (holder)\": \"man in white\", \"Arg1 (thing held)\": \"man in black\", \"Arg2 (benefactive)\": \"with his hand\", \"ArgM (direction)\": \"from\", \"ArgM (location)\": \"falling off a cliff\", \"ArgM (manner)\": \"really straining\"}}'}]},\n",
       " {'id': 'v_WgCQS7EllP8_seg_175_185_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WgCQS7EllP8_seg_175_185.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hold (grasp, bear, keep)\", \"roles\": {\"1\": \"Arg0 (holder)\", \"2\": \"Arg1 (thing held)\", \"3\": \"Arg2 (benefactive)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (location)\", \"6\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (holder)\": \"man in white\", \"Arg1 (thing held)\": \"man in black\", \"Arg2 (benefactive)\": \"with his hand\", \"ArgM (direction)\": \"from\", \"ArgM (location)\": \"falling off a cliff\", \"ArgM (manner)\": \"really straining\"}}'}]},\n",
       " {'id': 'v_WgCQS7EllP8_seg_175_185_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WgCQS7EllP8_seg_175_185.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"notice (become aware of)\", \"roles\": {\"1\": \"Arg0 (noticer)\", \"2\": \"Arg1 (noticed)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (noticer)\": \"man in white\", \"Arg1 (noticed)\": \"someone approaching him from the back\", \"ArgM (location)\": \"edge of cliff\"}}'}]},\n",
       " {'id': 'v_EzqRc-RLJfU_seg_75_85_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_EzqRc-RLJfU_seg_75_85.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lay (put, set, cause to exist at some location)\", \"roles\": {\"1\": \"Arg0 (layer)\", \"2\": \"Arg1 (thing laid)\", \"3\": \"Arg2 (location)\"}, \"nouns\": {\"Arg0 (layer)\": \"villagers\", \"Arg1 (thing laid)\": \"themselves\", \"Arg2 (location)\": \"on the ground\"}}'}]},\n",
       " {'id': 'v_EzqRc-RLJfU_seg_75_85_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_EzqRc-RLJfU_seg_75_85.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lay (put, set, cause to exist at some location)\", \"roles\": {\"1\": \"Arg0 (layer)\", \"2\": \"Arg1 (thing laid)\", \"3\": \"Arg2 (location)\"}, \"nouns\": {\"Arg0 (layer)\": \"villagers\", \"Arg1 (thing laid)\": \"themselves\", \"Arg2 (location)\": \"on the ground\"}}'}]},\n",
       " {'id': 'v_EzqRc-RLJfU_seg_75_85_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_EzqRc-RLJfU_seg_75_85.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lay (put, set, cause to exist at some location)\", \"roles\": {\"1\": \"Arg0 (layer)\", \"2\": \"Arg1 (thing laid)\", \"3\": \"Arg2 (location)\"}, \"nouns\": {\"Arg0 (layer)\": \"villagers\", \"Arg1 (thing laid)\": \"themselves\", \"Arg2 (location)\": \"on the ground\"}}'}]},\n",
       " {'id': 'v_EzqRc-RLJfU_seg_75_85_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_EzqRc-RLJfU_seg_75_85.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"watch (look at)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"villager in blue\", \"Arg1 (thing looked at)\": \"villagers laying down\", \"ArgM (manner)\": \"slowly turning around\", \"Scene of the Event\": \"inside a village\"}}'}]},\n",
       " {'id': 'v_EzqRc-RLJfU_seg_75_85_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_EzqRc-RLJfU_seg_75_85.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"turn (rotation)\", \"roles\": {\"1\": \"Arg0 (turner)\", \"2\": \"Arg1 (thing turning)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (purpose)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (turner)\": \"villager in blue\", \"Arg1 (thing turning)\": \"himself\", \"ArgM (direction)\": \"around\", \"ArgM (purpose)\": \"to look behind him\", \"Scene of the Event\": \"village\"}}'}]},\n",
       " {'id': 'v_dp4qnnVSk8Y_seg_20_30_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_dp4qnnVSk8Y_seg_20_30.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pray (talk to God)\", \"roles\": {\"1\": \"Arg0 (pray-er)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (pray-er)\": \"the man holding the cross\", \"Scene of the Event\": \"in a forest\"}}'}]},\n",
       " {'id': 'v_dp4qnnVSk8Y_seg_20_30_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_dp4qnnVSk8Y_seg_20_30.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pray (talk to God)\", \"roles\": {\"1\": \"Arg0 (pray-er)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (pray-er)\": \"the man holding the cross\", \"Scene of the Event\": \"in a forest\"}}'}]},\n",
       " {'id': 'v_dp4qnnVSk8Y_seg_20_30_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_dp4qnnVSk8Y_seg_20_30.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"grab (to capture, obtain)\", \"roles\": {\"1\": \"Arg0 (grabber)\", \"2\": \"Arg1 (entity grabbed)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (grabber)\": \"the man holding the cross\", \"Arg1 (entity grabbed)\": \"the man\\'s arm\", \"ArgM (location)\": \"that was laying on the ground\", \"ArgM (manner)\": \"angrily\"}}'}]},\n",
       " {'id': 'v_dp4qnnVSk8Y_seg_20_30_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_dp4qnnVSk8Y_seg_20_30.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"the man holding the cross\", \"Arg2 (hearer)\": \"to the man\\'s arm\", \"ArgM (manner)\": \"angrily\", \"Scene of the Event\": \"in a forest\"}}'}]},\n",
       " {'id': 'v_dp4qnnVSk8Y_seg_20_30_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_dp4qnnVSk8Y_seg_20_30.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"realize (come to know)\", \"roles\": {\"1\": \"Arg0 (new knower)\", \"2\": \"Arg1 (new knowledge)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (new knower)\": \"the man holding the cross\", \"Arg1 (new knowledge)\": \"that the man on the ground was missing legs\", \"Scene of the Event\": \"in a forest\"}}'}]},\n",
       " {'id': 'v_xsNboBgmN38_seg_20_30_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_xsNboBgmN38_seg_20_30.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sing (sing)\", \"roles\": {\"1\": \"Arg0 (singer)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (singer)\": \"blonde girl\", \"Scene of the Event\": \"garage\"}}'}]},\n",
       " {'id': 'v_xsNboBgmN38_seg_20_30_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_xsNboBgmN38_seg_20_30.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"play (play a game/music)\", \"roles\": {\"1\": \"Arg0 (player)\", \"2\": \"Arg1 (game/music)\", \"3\": \"Arg2 (instrument used to play game/music)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (player)\": \"boy in yellow shirt\", \"Arg1 (game/music)\": \"music\", \"Arg2 (instrument used to play game/music)\": \"guitar\", \"ArgM (location)\": \"garage\", \"ArgM (manner)\": \"moving his hand on the strings\"}}'}]},\n",
       " {'id': 'v_xsNboBgmN38_seg_20_30_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_xsNboBgmN38_seg_20_30.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"act (play a role; behave)\", \"roles\": {\"1\": \"Arg0 (player)\", \"2\": \"Arg1 (role)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (player)\": \"boy in yellow shirt\", \"Arg1 (role)\": \"acting like the guitar is a machine gune\", \"Scene of the Event\": \"garage\"}}'}]},\n",
       " {'id': 'v_xsNboBgmN38_seg_20_30_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_xsNboBgmN38_seg_20_30.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"play (play a game/music)\", \"roles\": {\"1\": \"Arg0 (player)\", \"2\": \"Arg1 (game/music)\", \"3\": \"Arg2 (instrument used to play game/music)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (player)\": \"girl with dark hair\", \"Arg1 (game/music)\": \"music\", \"Arg2 (instrument used to play game/music)\": \"keyboard\", \"ArgM (location)\": \"next to the drums\", \"ArgM (manner)\": \"using both hands\"}}'}]},\n",
       " {'id': 'v_xsNboBgmN38_seg_20_30_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_xsNboBgmN38_seg_20_30.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"tap (hit)\", \"roles\": {\"1\": \"Arg0 (agent, hitter - animate only!)\", \"2\": \"Arg1 (thing hit)\", \"3\": \"Arg2 (instrument, thing hit by or with)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (agent, hitter - animate only!)\": \"boy with long hair\", \"Arg1 (thing hit)\": \"drum\", \"Arg2 (instrument, thing hit by or with)\": \"drumstick\", \"ArgM (location)\": \"standing behind the drum set\"}}'}]},\n",
       " {'id': 'v_xsNboBgmN38_seg_70_80_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_xsNboBgmN38_seg_70_80.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"play (play a game/music)\", \"roles\": {\"1\": \"Arg0 (player)\", \"2\": \"Arg1 (game/music)\", \"3\": \"Arg2 (instrument used to play game/music)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (player)\": \"man in a white T-shirt\", \"Arg1 (game/music)\": \"beat\", \"Arg2 (instrument used to play game/music)\": \"drums\", \"ArgM (location)\": \"behind the singer\", \"ArgM (manner)\": \"energetically\"}}'}]},\n",
       " {'id': 'v_xsNboBgmN38_seg_70_80_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_xsNboBgmN38_seg_70_80.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"play (play a game/music)\", \"roles\": {\"1\": \"Arg0 (player)\", \"2\": \"Arg1 (game/music)\", \"3\": \"Arg2 (instrument used to play game/music)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (player)\": \"man in a green plaid shirt\", \"Arg1 (game/music)\": \"music\", \"Arg2 (instrument used to play game/music)\": \"trumpet\", \"ArgM (location)\": \"to the blonde woman\\'s right\", \"ArgM (manner)\": \"enthusiastically\"}}'}]},\n",
       " {'id': 'v_xsNboBgmN38_seg_70_80_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_xsNboBgmN38_seg_70_80.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sing (sing)\", \"roles\": {\"1\": \"Arg0 (singer)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (singer)\": \"blonde woman\", \"Scene of the Event\": \"band rehearsal\"}}'}]},\n",
       " {'id': 'v_xsNboBgmN38_seg_70_80_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_xsNboBgmN38_seg_70_80.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sing (sing)\", \"roles\": {\"1\": \"Arg0 (singer)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (singer)\": \"blonde woman\", \"Scene of the Event\": \"band rehearsal\"}}'}]},\n",
       " {'id': 'v_xsNboBgmN38_seg_70_80_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_xsNboBgmN38_seg_70_80.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"slide (slide)\", \"roles\": {\"1\": \"Arg0 (agent, causer of sliding)\", \"2\": \"Arg1 (thing sliding)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, causer of sliding)\": \"boy in a striped swater\", \"Arg1 (thing sliding)\": \"bow\", \"ArgM (direction)\": \"across the cello strings\", \"Scene of the Event\": \"band rehearsal\"}}'}]},\n",
       " {'id': 'v_6Bg4HfBsmAU_seg_100_110_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_6Bg4HfBsmAU_seg_100_110.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"flop (to fall, drop)\", \"roles\": {\"1\": \"Arg1 (entity dropped)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg1 (entity dropped)\": \"the man\\'s head\", \"ArgM (direction)\": \"towards\", \"ArgM (location)\": \"his chest\"}}'}]},\n",
       " {'id': 'v_6Bg4HfBsmAU_seg_100_110_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_6Bg4HfBsmAU_seg_100_110.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lean (to incline or cause to incline)\", \"roles\": {\"1\": \"Arg0 (causer of leaning)\", \"2\": \"Arg2 (direction)\", \"3\": \"ArgM (purpose)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of leaning)\": \"the man\\'s head\", \"Arg2 (direction)\": \"down\", \"ArgM (purpose)\": \"-\", \"Scene of the Event\": \"a suspended seat\"}}'}]},\n",
       " {'id': 'v_6Bg4HfBsmAU_seg_100_110_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_6Bg4HfBsmAU_seg_100_110.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"watch (look at)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"a bald man\", \"Arg1 (thing looked at)\": \"a screen\", \"ArgM (manner)\": \"intently\", \"Scene of the Event\": \"a darkened room\"}}'}]},\n",
       " {'id': 'v_6Bg4HfBsmAU_seg_100_110_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_6Bg4HfBsmAU_seg_100_110.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"approach (move towards)\", \"roles\": {\"1\": \"Arg1 (entity in motion)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity in motion)\": \"a dark haired woman\", \"Arg2 (destination)\": \"the man watching the screen\", \"ArgM (direction)\": \"towards\", \"ArgM (manner)\": \"slowly\", \"Scene of the Event\": \"a darkened room\"}}'}]},\n",
       " {'id': 'v_6Bg4HfBsmAU_seg_100_110_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_6Bg4HfBsmAU_seg_100_110.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"a dark haired woman\", \"Arg2 (hearer)\": \"a bald man\", \"ArgM (manner)\": \"curiuosly\", \"Scene of the Event\": \"a darkened room\"}}'}]},\n",
       " {'id': 'v_s-te8zRj4WY_seg_55_65_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_s-te8zRj4WY_seg_55_65.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"young man\", \"Arg1 (thing looked at or for or on)\": \"young woman\", \"ArgM (direction)\": \"in front of him\", \"ArgM (manner)\": \"happily\", \"Scene of the Event\": \"at the door\"}}'}]},\n",
       " {'id': 'v_s-te8zRj4WY_seg_55_65_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_s-te8zRj4WY_seg_55_65.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"young man\", \"Arg2 (hearer)\": \"young woman\", \"ArgM (manner)\": \"happily\", \"Scene of the Event\": \"at the door\"}}'}]},\n",
       " {'id': 'v_s-te8zRj4WY_seg_55_65_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_s-te8zRj4WY_seg_55_65.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"smile (to have or form a smile)\", \"roles\": {\"1\": \"Arg0 (agent smiling)\", \"2\": \"Arg2 (smiled at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent smiling)\": \"young man\", \"Arg2 (smiled at)\": \"young woman\", \"ArgM (manner)\": \"happily\", \"Scene of the Event\": \"at the door\"}}'}]},\n",
       " {'id': 'v_s-te8zRj4WY_seg_55_65_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_s-te8zRj4WY_seg_55_65.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"young man\", \"Arg1 (thing looked at or for or on)\": \"young woman\", \"ArgM (direction)\": \"through the door\", \"ArgM (manner)\": \"slowly\", \"Scene of the Event\": \"at the door\"}}'}]},\n",
       " {'id': 'v_s-te8zRj4WY_seg_55_65_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_s-te8zRj4WY_seg_55_65.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"search (search, seek)\", \"roles\": {\"1\": \"Arg0 (searcher)\", \"2\": \"Arg1 (Area searched)\", \"3\": \"Arg2 (searched for)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (searcher)\": \"young man\", \"Arg1 (Area searched)\": \"his pocket\", \"Arg2 (searched for)\": \"something\", \"ArgM (location)\": \"his pocket\"}}'}]},\n",
       " {'id': 'v_C7ke6vWUu18_seg_85_95_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_C7ke6vWUu18_seg_85_95.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"laugh (laugh)\", \"roles\": {\"1\": \"Arg0 (laugher)\", \"2\": \"Arg2 (source of joy)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (laugher)\": \"A brown haired man\", \"Arg2 (source of joy)\": \"at a conversation\", \"ArgM (manner)\": \"in disbelief\", \"Scene of the Event\": \"in a restauramt\"}}'}]},\n",
       " {'id': 'v_C7ke6vWUu18_seg_85_95_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_C7ke6vWUu18_seg_85_95.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"indicate (show)\", \"roles\": {\"1\": \"Arg0 (indicator)\", \"2\": \"Arg1 (thing indicated)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (indicator)\": \"A blonde man\", \"Arg1 (thing indicated)\": \"something\", \"ArgM (manner)\": \"aggressively\", \"Scene of the Event\": \"in a restauramt\"}}'}]},\n",
       " {'id': 'v_C7ke6vWUu18_seg_85_95_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_C7ke6vWUu18_seg_85_95.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"emphasize (emphasize)\", \"roles\": {\"1\": \"Arg1 (utterance)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (utterance)\": \"A blonde man\", \"Scene of the Event\": \"in a restauramt\"}}'}]},\n",
       " {'id': 'v_C7ke6vWUu18_seg_85_95_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_C7ke6vWUu18_seg_85_95.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"yell (to cry out loudly)\", \"roles\": {\"1\": \"Arg0 (Yeller)\", \"2\": \"Arg2 (Hearer)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Yeller)\": \"A blonde man\", \"Arg2 (Hearer)\": \"the brown haired man\", \"Scene of the Event\": \"in a restauramt\"}}'}]},\n",
       " {'id': 'v_C7ke6vWUu18_seg_85_95_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_C7ke6vWUu18_seg_85_95.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"disbelieve (not believe)\", \"roles\": {\"1\": \"Arg0 (non-believer)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (non-believer)\": \"the brown haired man\", \"Scene of the Event\": \"in a restauramt\"}}'}]},\n",
       " {'id': 'v_MCtE3Y28IR0_seg_30_40_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MCtE3Y28IR0_seg_30_40.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man with thin mustache\", \"Arg2 (hearer)\": \"the others in the room\", \"ArgM (manner)\": \"with passion\", \"Scene of the Event\": \"in a barber shop\"}}'}]},\n",
       " {'id': 'v_MCtE3Y28IR0_seg_30_40_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MCtE3Y28IR0_seg_30_40.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hold (grasp, bear, keep)\", \"roles\": {\"1\": \"Arg0 (holder)\", \"2\": \"Arg1 (thing held)\", \"3\": \"Arg2 (benefactive)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (location)\", \"6\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (holder)\": \"girl in pink coat\", \"Arg1 (thing held)\": \"baseball bat\", \"Arg2 (benefactive)\": \"-\", \"ArgM (direction)\": \"at waist level\", \"ArgM (location)\": \"on a street\", \"ArgM (manner)\": \"to prepare for a smash\"}}'}]},\n",
       " {'id': 'v_MCtE3Y28IR0_seg_30_40_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MCtE3Y28IR0_seg_30_40.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lift (cause increase in elevation)\", \"roles\": {\"1\": \"Arg0 (elevator, Agent)\", \"2\": \"Arg1 (Logical subject, patient, thing rising)\", \"3\": \"Arg3 (Start point)\", \"4\": \"Arg4 (End point)\", \"5\": \"ArgM (direction)\", \"6\": \"ArgM (manner)\", \"7\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (elevator, Agent)\": \"girl in pink coat\", \"Arg1 (Logical subject, patient, thing rising)\": \"baseball bat\", \"Arg3 (Start point)\": \"at her waist\", \"Arg4 (End point)\": \"above her shoulders\", \"ArgM (direction)\": \"upward\", \"ArgM (manner)\": \"in preparation for a swing\", \"Scene of the Event\": \"on a street\"}}'}]},\n",
       " {'id': 'v_MCtE3Y28IR0_seg_30_40_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MCtE3Y28IR0_seg_30_40.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"smash (break violently)\", \"roles\": {\"1\": \"Arg0 (agent, smasher)\", \"2\": \"Arg1 (patient, smashed)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, smasher)\": \"girl in pink coat\", \"Arg1 (patient, smashed)\": \"vehicle windshield\", \"ArgM (direction)\": \"downward\", \"Scene of the Event\": \"on a street\"}}'}]},\n",
       " {'id': 'v_MCtE3Y28IR0_seg_30_40_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MCtE3Y28IR0_seg_30_40.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cheer (applaud, cheer for)\", \"roles\": {\"1\": \"Arg0 (clapper)\", \"2\": \"Arg1 (thing approved of)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (clapper)\": \"a group of men\", \"Arg1 (thing approved of)\": \"the smashing\", \"ArgM (manner)\": \"with glee\", \"Scene of the Event\": \"in a barber shop\"}}'}]},\n",
       " {'id': 'v_LjKZiPNHRUU_seg_35_45_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LjKZiPNHRUU_seg_35_45.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"read (read)\", \"roles\": {\"1\": \"Arg0 (reader)\", \"2\": \"Arg1 (book)\", \"3\": \"Arg3 (text, content)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (reader)\": \"woman\", \"Arg1 (book)\": \"card\", \"Arg3 (text, content)\": \"explaining something\", \"ArgM (location)\": \"in her hand\"}}'}]},\n",
       " {'id': 'v_LjKZiPNHRUU_seg_35_45_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LjKZiPNHRUU_seg_35_45.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"woman\", \"Arg2 (hearer)\": \"man\", \"ArgM (manner)\": \"explaining\", \"Scene of the Event\": \"driveway\"}}'}]},\n",
       " {'id': 'v_LjKZiPNHRUU_seg_35_45_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LjKZiPNHRUU_seg_35_45.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"kneel (on bended knee)\", \"roles\": {\"1\": \"Arg0 (kneeler)\", \"2\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (kneeler)\": \"man\", \"ArgM (location)\": \"in front of boy\"}}'}]},\n",
       " {'id': 'v_LjKZiPNHRUU_seg_35_45_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LjKZiPNHRUU_seg_35_45.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man\", \"Arg2 (hearer)\": \"boy\", \"ArgM (manner)\": \"with a beaver puppet\", \"Scene of the Event\": \"driveway\"}}'}]},\n",
       " {'id': 'v_LjKZiPNHRUU_seg_35_45_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LjKZiPNHRUU_seg_35_45.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"watch (look at)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"woman\", \"Arg1 (thing looked at)\": \"man\", \"ArgM (manner)\": \"judging him\", \"Scene of the Event\": \"driveway\"}}'}]},\n",
       " {'id': 'v_BkW-4CWw3XQ_seg_85_95_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_BkW-4CWw3XQ_seg_85_95.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"3 men in dress clothes\", \"Arg1 (looked at)\": \"out a window\", \"ArgM (direction)\": \"downward\", \"ArgM (manner)\": \"interested\", \"Scene of the Event\": \"office\"}}'}]},\n",
       " {'id': 'v_BkW-4CWw3XQ_seg_85_95_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_BkW-4CWw3XQ_seg_85_95.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"open (open)\", \"roles\": {\"1\": \"Arg0 (opener)\", \"2\": \"Arg1 (thing opening)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (opener)\": \"Man in police uniform\", \"Arg1 (thing opening)\": \"bathroom stall door\", \"ArgM (manner)\": \"hurrying\", \"Scene of the Event\": \"bathroom\"}}'}]},\n",
       " {'id': 'v_BkW-4CWw3XQ_seg_85_95_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_BkW-4CWw3XQ_seg_85_95.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"confuse ((cause to) be confused)\", \"roles\": {\"1\": \"Arg1 (entity experiencing confusion)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity experiencing confusion)\": \"Man in police uniform\", \"Scene of the Event\": \"bathroom\"}}'}]},\n",
       " {'id': 'v_BkW-4CWw3XQ_seg_85_95_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_BkW-4CWw3XQ_seg_85_95.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"Man in police uniform\", \"Arg1 (thing looked at or for or on)\": \"Pants and shoes placed on toilet\", \"ArgM (direction)\": \"downward\", \"ArgM (manner)\": \"angry\", \"Scene of the Event\": \"bathroom\"}}'}]},\n",
       " {'id': 'v_BkW-4CWw3XQ_seg_85_95_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_BkW-4CWw3XQ_seg_85_95.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"switch (change, exchange)\", \"roles\": {\"1\": \"Arg0 (causer of transformation)\", \"2\": \"Arg1 (thing changing)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of transformation)\": \"camera\", \"Arg1 (thing changing)\": \"scene\", \"Scene of the Event\": \"outside alleyway\"}}'}]},\n",
       " {'id': 'v_OlqErSr6Rjw_seg_90_100_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_OlqErSr6Rjw_seg_90_100.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"do (act)\", \"roles\": {\"1\": \"Arg0 (agent, doer)\", \"2\": \"Arg1 (thing done)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, doer)\": \"man with brown cape\", \"Arg1 (thing done)\": \"blows up a device\", \"Scene of the Event\": \"in a white room\"}}'}]},\n",
       " {'id': 'v_OlqErSr6Rjw_seg_90_100_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_OlqErSr6Rjw_seg_90_100.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man with brown cape\", \"ArgM (direction)\": \"walks toward an open door\", \"ArgM (manner)\": \"looking down and quickening his pace\", \"Scene of the Event\": \"in a white room\"}}'}]},\n",
       " {'id': 'v_OlqErSr6Rjw_seg_90_100_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_OlqErSr6Rjw_seg_90_100.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"enter (enter, go in)\", \"roles\": {\"1\": \"Arg0 (entity entering)\", \"2\": \"Arg1 (place or thing entered)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity entering)\": \"two men in red outfits\", \"Arg1 (place or thing entered)\": \"enter the white room\", \"ArgM (manner)\": \"drawing their guns in pursuit of the man with brown cape\", \"Scene of the Event\": \"in a white room\"}}'}]},\n",
       " {'id': 'v_OlqErSr6Rjw_seg_90_100_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_OlqErSr6Rjw_seg_90_100.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"press (apply pressure)\", \"roles\": {\"1\": \"Arg0 (presser)\", \"2\": \"Arg1 (pressed (on))\", \"3\": \"Arg2 (goal, pressed-for)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (manner)\", \"6\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (presser)\": \"man in red outfit\", \"Arg1 (pressed (on))\": \"presses on the door\", \"Arg2 (goal, pressed-for)\": \"to try to open it\", \"ArgM (direction)\": \"to the side of the room\", \"ArgM (manner)\": \"with gun drawn\", \"Scene of the Event\": \"in a white room\"}}'}]},\n",
       " {'id': 'v_OlqErSr6Rjw_seg_90_100_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_OlqErSr6Rjw_seg_90_100.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"man in dark brown jacket\", \"Arg2 (hearer)\": \"talks on intercom\", \"ArgM (location)\": \"in a room with metal walls\", \"ArgM (manner)\": \"with two other men to his side\"}}'}]},\n",
       " {'id': 'v_IvwJ-KwPATw_seg_110_120_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_IvwJ-KwPATw_seg_110_120.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fondle (touch-rub-grab)\", \"roles\": {\"1\": \"Arg0 (fondler, agent)\", \"2\": \"Arg1 (thing fondled, patient)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (fondler, agent)\": \"the boy with the blonde hair\", \"Arg1 (thing fondled, patient)\": \"the woman with brown hair\", \"Scene of the Event\": \"outside\"}}'}]},\n",
       " {'id': 'v_IvwJ-KwPATw_seg_110_120_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_IvwJ-KwPATw_seg_110_120.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"observe (look at, mark)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"the girl with long brown hair\", \"Arg1 (thing looked at)\": \"the girl in the pink shirt\", \"Scene of the Event\": \"on a porch\"}}'}]},\n",
       " {'id': 'v_IvwJ-KwPATw_seg_110_120_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_IvwJ-KwPATw_seg_110_120.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"toss (throw randomly)\", \"roles\": {\"1\": \"Arg0 (tosser(s))\", \"2\": \"Arg1 (thing tossed)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (tosser(s))\": \"the girl in the blue shirt\", \"Arg1 (thing tossed)\": \"something\", \"ArgM (direction)\": \"down the ravine\", \"ArgM (manner)\": \"calmly\", \"Scene of the Event\": \"in a forest\"}}'}]},\n",
       " {'id': 'v_IvwJ-KwPATw_seg_110_120_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_IvwJ-KwPATw_seg_110_120.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"descend (to come down, lower oneself, or arrive)\", \"roles\": {\"1\": \"Arg0 (entity rising)\", \"2\": \"Arg1 (location, descend on or to)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (entity rising)\": \"someone\", \"Arg1 (location, descend on or to)\": \"down the bleachers\", \"ArgM (manner)\": \"quickly\"}}'}]},\n",
       " {'id': 'v_IvwJ-KwPATw_seg_110_120_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_IvwJ-KwPATw_seg_110_120.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cause (impelled action)\", \"roles\": {\"1\": \"Arg0 (forcer, causer)\", \"2\": \"Arg1 (impelled action)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (forcer, causer)\": \"the woman under the bleachers\", \"Arg1 (impelled action)\": \"the person descending to fall\", \"Scene of the Event\": \"down the bleachers\"}}'}]},\n",
       " {'id': 'v_a_aZ01raOoI_seg_70_80_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_a_aZ01raOoI_seg_70_80.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hold (grasp, bear, keep)\", \"roles\": {\"1\": \"Arg0 (holder)\", \"2\": \"Arg1 (thing held)\", \"3\": \"Arg2 (benefactive)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (location)\", \"6\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (holder)\": \"woman in white tank top\", \"Arg1 (thing held)\": \"baby kangaroo a joey\", \"Arg2 (benefactive)\": \"in her arms\", \"ArgM (direction)\": \"in front\", \"ArgM (location)\": \"grassy field\", \"ArgM (manner)\": \"carefully\"}}'}]},\n",
       " {'id': 'v_a_aZ01raOoI_seg_70_80_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_a_aZ01raOoI_seg_70_80.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"assist (help, assist)\", \"roles\": {\"1\": \"Arg0 (assistant)\", \"2\": \"Arg1 (assisted)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (assistant)\": \"man in tan uniform\", \"Arg1 (assisted)\": \"woman in white tank top\", \"Scene of the Event\": \"grassy field\"}}'}]},\n",
       " {'id': 'v_a_aZ01raOoI_seg_70_80_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_a_aZ01raOoI_seg_70_80.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stand (rise)\", \"roles\": {\"1\": \"Arg1 (riser)\", \"2\": \"ArgM (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (riser)\": \"woman in white tank top\", \"ArgM (location)\": \"grassy field\", \"ArgM (manner)\": \"carefully\"}}'}]},\n",
       " {'id': 'v_a_aZ01raOoI_seg_70_80_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_a_aZ01raOoI_seg_70_80.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man in tan uniform\", \"ArgM (direction)\": \"around back of truck\", \"ArgM (manner)\": \"confidently\", \"Scene of the Event\": \"grassy field behind truck\"}}'}]},\n",
       " {'id': 'v_a_aZ01raOoI_seg_70_80_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_a_aZ01raOoI_seg_70_80.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"man in tan uniform\", \"Arg2 (hearer)\": \"camera\", \"ArgM (location)\": \"behind truck\", \"ArgM (manner)\": \"confidently\"}}'}]},\n",
       " {'id': 'v_EI_QlYraNl8_seg_75_85_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_EI_QlYraNl8_seg_75_85.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"collapse (fall down)\", \"roles\": {\"1\": \"Arg1 (thing collapsing)\", \"2\": \"ArgM (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing collapsing)\": \"man in a black and grey striped shirt\", \"ArgM (location)\": \"on a bed\", \"ArgM (manner)\": \"helplessly\"}}'}]},\n",
       " {'id': 'v_EI_QlYraNl8_seg_75_85_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_EI_QlYraNl8_seg_75_85.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man in a black and grey striped shirt\", \"Arg1 (looked at)\": \"the camera\", \"ArgM (direction)\": \"over his shoulder\", \"ArgM (manner)\": \"blankly\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_EI_QlYraNl8_seg_75_85_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_EI_QlYraNl8_seg_75_85.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"move (change location)\", \"roles\": {\"1\": \"Arg1 (moved)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (moved)\": \"the camera\", \"Arg2 (destination)\": \"unknown\", \"ArgM (direction)\": \"away from the man in a black and grey striped shirt\", \"ArgM (manner)\": \"suddenly\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_EI_QlYraNl8_seg_75_85_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_EI_QlYraNl8_seg_75_85.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"focus (focus, concentrate)\", \"roles\": {\"1\": \"Arg0 (agent, focusser)\", \"2\": \"Arg2 (focussed-on)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, focusser)\": \"the camera\", \"Arg2 (focussed-on)\": \"man in a black and grey striped shirt\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_EI_QlYraNl8_seg_75_85_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_EI_QlYraNl8_seg_75_85.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"grab (to capture, obtain)\", \"roles\": {\"1\": \"Arg0 (grabber)\", \"2\": \"Arg1 (entity grabbed)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (grabber)\": \"woman in a purple top\", \"Arg1 (entity grabbed)\": \"man in a black and grey striped shirt\", \"ArgM (location)\": \"by his collar\", \"ArgM (manner)\": \"with an instantaneous lunge\"}}'}]},\n",
       " {'id': 'v_0lNb6NAV6jg_seg_35_45_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0lNb6NAV6jg_seg_35_45.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"flirt (to deal playfully or superficially)\", \"roles\": {\"1\": \"Arg0 (flirt, agent)\", \"2\": \"Arg1 (entity flirted with)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (flirt, agent)\": \"man in suit\", \"Arg1 (entity flirted with)\": \"woman in black dress\", \"Scene of the Event\": \"game room\"}}'}]},\n",
       " {'id': 'v_0lNb6NAV6jg_seg_35_45_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0lNb6NAV6jg_seg_35_45.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"try (Attempt)\", \"roles\": {\"1\": \"Arg0 (Agent/Entity Trying)\", \"2\": \"Arg1 (thing tried)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Agent/Entity Trying)\": \"woman in black dress\", \"Arg1 (thing tried)\": \"to push man away\", \"ArgM (manner)\": \"holding her hands on his upper body\", \"Scene of the Event\": \"game room\"}}'}]},\n",
       " {'id': 'v_0lNb6NAV6jg_seg_35_45_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0lNb6NAV6jg_seg_35_45.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"try (Attempt)\", \"roles\": {\"1\": \"Arg0 (Agent/Entity Trying)\", \"2\": \"Arg1 (thing tried)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Agent/Entity Trying)\": \"man in suit\", \"Arg1 (thing tried)\": \"to kiss girl\", \"ArgM (manner)\": \"forcefull on the lips\", \"Scene of the Event\": \"game room\"}}'}]},\n",
       " {'id': 'v_0lNb6NAV6jg_seg_35_45_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0lNb6NAV6jg_seg_35_45.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"react (give a response, reaction)\", \"roles\": {\"1\": \"Arg0 (reactor)\", \"2\": \"Arg1 (reacted-to)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (reactor)\": \"woman in black dress\", \"Arg1 (reacted-to)\": \"man in suit\", \"ArgM (manner)\": \"slapping him in the face\", \"Scene of the Event\": \"game room\"}}'}]},\n",
       " {'id': 'v_0lNb6NAV6jg_seg_35_45_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0lNb6NAV6jg_seg_35_45.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"woman in black dress\", \"Arg1 (thing looked at or for or on)\": \"man in suit\", \"ArgM (direction)\": \"across the room\", \"ArgM (manner)\": \"with anger\", \"Scene of the Event\": \"next to a pool table\"}}'}]},\n",
       " {'id': 'v_6Tz9krF1K68_seg_100_110_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_6Tz9krF1K68_seg_100_110.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hit (strike)\", \"roles\": {\"1\": \"Arg0 (agent, hitter - animate only!)\", \"2\": \"Arg1 (thing hit)\", \"3\": \"Arg2 (instrument, thing hit by or with)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (agent, hitter - animate only!)\": \"man in tan suit\", \"Arg1 (thing hit)\": \"the machine\", \"Arg2 (instrument, thing hit by or with)\": \"with his hand\", \"ArgM (location)\": \"next to him\", \"ArgM (manner)\": \"to get it to stop moving\"}}'}]},\n",
       " {'id': 'v_6Tz9krF1K68_seg_100_110_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_6Tz9krF1K68_seg_100_110.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"frustrate (cause angst)\", \"roles\": {\"1\": \"Arg1 (entity frustrated)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity frustrated)\": \"man in tan suit\", \"Scene of the Event\": \"in a torture room\"}}'}]},\n",
       " {'id': 'v_6Tz9krF1K68_seg_100_110_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_6Tz9krF1K68_seg_100_110.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"woman with black hair\", \"Arg2 (hearer)\": \"man in tan suit\", \"ArgM (manner)\": \"while strapped to a bed\", \"Scene of the Event\": \"in a torture room\"}}'}]},\n",
       " {'id': 'v_6Tz9krF1K68_seg_100_110_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_6Tz9krF1K68_seg_100_110.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"explain (explain)\", \"roles\": {\"1\": \"Arg0 (explainer)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (explainer)\": \"woman with black hair\", \"Scene of the Event\": \"in a torture room\"}}'}]},\n",
       " {'id': 'v_6Tz9krF1K68_seg_100_110_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_6Tz9krF1K68_seg_100_110.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"respond (give an answer, reply)\", \"roles\": {\"1\": \"Arg0 (replier)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (replier)\": \"man in tan suit\", \"Scene of the Event\": \"in a torture room\"}}'}]},\n",
       " {'id': 'v_OjS7LxDYad8_seg_50_60_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_OjS7LxDYad8_seg_50_60.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cover (obscure)\", \"roles\": {\"1\": \"Arg0 (coverer)\", \"2\": \"Arg1 (thing covered)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (coverer)\": \"man on black cap\", \"Arg1 (thing covered)\": \"a diagram of human anatomy\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"classroom\"}}'}]},\n",
       " {'id': 'v_OjS7LxDYad8_seg_50_60_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_OjS7LxDYad8_seg_50_60.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"run (walk quickly, a course or contest)\", \"roles\": {\"1\": \"Arg0 (runner)\", \"2\": \"Arg1 (course, race, distance)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (goal)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (runner)\": \"man on black cap\", \"Arg1 (course, race, distance)\": \"along the classroom\", \"ArgM (direction)\": \"to his seat\", \"ArgM (goal)\": \"to sit down and avoid being seen\", \"Scene of the Event\": \"classroom\"}}'}]},\n",
       " {'id': 'v_OjS7LxDYad8_seg_50_60_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_OjS7LxDYad8_seg_50_60.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sit (be in a position)\", \"roles\": {\"1\": \"Arg1 (thing sitting)\", \"2\": \"Arg2 (location or position)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing sitting)\": \"man on black cap\", \"Arg2 (location or position)\": \"on a girl\\'s laps\", \"ArgM (manner)\": \"quickly\"}}'}]},\n",
       " {'id': 'v_OjS7LxDYad8_seg_50_60_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_OjS7LxDYad8_seg_50_60.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"point (point at, define, make an example of)\", \"roles\": {\"1\": \"Arg0 (pointer)\", \"2\": \"Arg1 (pointed at)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (pointer)\": \"tutor in class\", \"Arg1 (pointed at)\": \"diagram of a horse\", \"ArgM (direction)\": \"up\", \"Scene of the Event\": \"classroom\"}}'}]},\n",
       " {'id': 'v_OjS7LxDYad8_seg_50_60_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_OjS7LxDYad8_seg_50_60.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"tutor in class\", \"Arg1 (thing looked at or for or on)\": \"diagram of a horse\", \"ArgM (direction)\": \"up\", \"ArgM (manner)\": \"confused\", \"Scene of the Event\": \"classroom\"}}'}]},\n",
       " {'id': 'v_AmYSeovvscE_seg_120_130_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_AmYSeovvscE_seg_120_130.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fade ((cause to) become dim)\", \"roles\": {\"1\": \"Arg1 (thing fading)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (thing fading)\": \"primitive painting\", \"Scene of the Event\": \"wood floor\"}}'}]},\n",
       " {'id': 'v_AmYSeovvscE_seg_120_130_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_AmYSeovvscE_seg_120_130.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"trudge (mode of motion)\", \"roles\": {\"1\": \"Arg0 (entity in motion)\", \"2\": \"Arg1 (path)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity in motion)\": \"man in a black coat\", \"Arg1 (path)\": \"sidewalk\", \"ArgM (direction)\": \"across\", \"Scene of the Event\": \"city street scene\"}}'}]},\n",
       " {'id': 'v_AmYSeovvscE_seg_120_130_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_AmYSeovvscE_seg_120_130.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"tail (follow)\", \"roles\": {\"1\": \"Arg0 (follower, tailer)\", \"2\": \"Arg1 (followed, tailed)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (follower, tailer)\": \"man in a black coat\", \"Arg1 (followed, tailed)\": \"woman in a rust colored coat\", \"ArgM (location)\": \"right behind her\"}}'}]},\n",
       " {'id': 'v_AmYSeovvscE_seg_120_130_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_AmYSeovvscE_seg_120_130.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"cross (move perpendicularly to some barrier)\", \"roles\": {\"1\": \"Arg0 (entity in motion)\", \"2\": \"Arg1 (barrier)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (goal)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity in motion)\": \"man in a black coat\", \"Arg1 (barrier)\": \"stree\", \"ArgM (direction)\": \"into the shady side\", \"ArgM (goal)\": \"-\", \"Scene of the Event\": \"city street scene\"}}'}]},\n",
       " {'id': 'v_AmYSeovvscE_seg_120_130_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_AmYSeovvscE_seg_120_130.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"turn (rotation)\", \"roles\": {\"1\": \"Arg0 (turner)\", \"2\": \"Arg1 (thing turning)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (purpose)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (turner)\": \"man in a black coat\", \"Arg1 (thing turning)\": \"himself\", \"ArgM (direction)\": \"into the building\", \"ArgM (purpose)\": \"-\", \"Scene of the Event\": \"city street scene\"}}'}]},\n",
       " {'id': 'v_NpoB6-TCGWw_seg_0_10_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NpoB6-TCGWw_seg_0_10.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"large green creature\", \"ArgM (direction)\": \"through tunnel\", \"ArgM (manner)\": \"lumbering\", \"Scene of the Event\": \"dark tunnel\"}}'}]},\n",
       " {'id': 'v_NpoB6-TCGWw_seg_0_10_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NpoB6-TCGWw_seg_0_10.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"people in tan uniforms\", \"Arg1 (thing looked at or for or on)\": \"for large green creature\", \"ArgM (direction)\": \"all around\", \"ArgM (manner)\": \"with concern\", \"Scene of the Event\": \"military facility\"}}'}]},\n",
       " {'id': 'v_NpoB6-TCGWw_seg_0_10_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NpoB6-TCGWw_seg_0_10.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"gray haired man in tan uniform\", \"ArgM (direction)\": \"towards computers\", \"ArgM (manner)\": \"with concern\", \"Scene of the Event\": \"military facility\"}}'}]},\n",
       " {'id': 'v_NpoB6-TCGWw_seg_0_10_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NpoB6-TCGWw_seg_0_10.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"rise (go up)\", \"roles\": {\"1\": \"Arg1 (Logical subject, patient, thing rising)\", \"2\": \"Arg3 (start point)\", \"3\": \"Arg4 (end point)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (Logical subject, patient, thing rising)\": \"large metal platform\", \"Arg3 (start point)\": \"on base\", \"Arg4 (end point)\": \"on its side\", \"ArgM (manner)\": \"with sudden force\", \"Scene of the Event\": \"military facility\"}}'}]},\n",
       " {'id': 'v_NpoB6-TCGWw_seg_0_10_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_NpoB6-TCGWw_seg_0_10.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"enter (enter, go in)\", \"roles\": {\"1\": \"Arg0 (entity entering)\", \"2\": \"Arg1 (place or thing entered)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity entering)\": \"large green creature\", \"Arg1 (place or thing entered)\": \"military facility\", \"ArgM (manner)\": \"through hole he made\", \"Scene of the Event\": \"military facility\"}}'}]},\n",
       " {'id': 'v_0GYwcr3RD_k_seg_30_40_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0GYwcr3RD_k_seg_30_40.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"dark-haired man in a gray turtleneck, dark blue shirt, and headset\", \"Arg2 (hearer)\": \"audience\", \"ArgM (manner)\": \"emphasizing some words with gesture\", \"Scene of the Event\": \"church pulpit with cross and candles on a table\"}}'}]},\n",
       " {'id': 'v_0GYwcr3RD_k_seg_30_40_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0GYwcr3RD_k_seg_30_40.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"dark-haired man in a gray turtleneck, dark blue shirt, and headset\", \"Arg2 (hearer)\": \"audience\", \"ArgM (manner)\": \"while pacing\", \"Scene of the Event\": \"church pulpit with cross and candles on a table\"}}'}]},\n",
       " {'id': 'v_0GYwcr3RD_k_seg_30_40_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0GYwcr3RD_k_seg_30_40.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pause (to suspend an action, to hesitate)\", \"roles\": {\"1\": \"Arg0 (thing pausing, agent or action)\", \"2\": \"ArgM (location)\", \"3\": \"ArgM (purpose)\"}, \"nouns\": {\"Arg0 (thing pausing, agent or action)\": \"dark-haired man in a gray turtleneck, dark blue shirt, and headset\", \"ArgM (location)\": \"church pulpit with cross and candles on a table\", \"ArgM (purpose)\": \"to make a point\"}}'}]},\n",
       " {'id': 'v_0GYwcr3RD_k_seg_30_40_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0GYwcr3RD_k_seg_30_40.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"dark-haired man in a gray turtleneck, dark blue shirt, and headset\", \"Arg2 (hearer)\": \"audience\", \"ArgM (manner)\": \"while pacing\", \"Scene of the Event\": \"church pulpit with cross and candles on a table\"}}'}]},\n",
       " {'id': 'v_0GYwcr3RD_k_seg_30_40_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0GYwcr3RD_k_seg_30_40.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"listen (attend to a sound)\", \"roles\": {\"1\": \"Arg0 (listener)\", \"2\": \"Arg1 (sound or speaker)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (listener)\": \"church members\", \"Arg1 (sound or speaker)\": \"dark-haired man in a gray turtleneck, dark blue shirt, and headset\", \"ArgM (manner)\": \"quietly and without expression\", \"Scene of the Event\": \"church interior\"}}'}]},\n",
       " {'id': 'v_CShHiYrQPGM_seg_155_165_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CShHiYrQPGM_seg_155_165.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"enter (enter, go in)\", \"roles\": {\"1\": \"Arg0 (entity entering)\", \"2\": \"Arg1 (place or thing entered)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity entering)\": \"a group of four people\", \"Arg1 (place or thing entered)\": \"enter a building\", \"ArgM (manner)\": \"through an open entrance\", \"Scene of the Event\": \"in a dimly lit building\"}}'}]},\n",
       " {'id': 'v_CShHiYrQPGM_seg_155_165_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CShHiYrQPGM_seg_155_165.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"a group of four people\", \"ArgM (direction)\": \"walk forwards\", \"ArgM (manner)\": \"with purpose\", \"Scene of the Event\": \"in a dimly lit building\"}}'}]},\n",
       " {'id': 'v_CShHiYrQPGM_seg_155_165_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CShHiYrQPGM_seg_155_165.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"a group of four people\", \"ArgM (direction)\": \"walk forwards\", \"ArgM (manner)\": \"with purpose\", \"Scene of the Event\": \"in a dimly lit building\"}}'}]},\n",
       " {'id': 'v_CShHiYrQPGM_seg_155_165_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CShHiYrQPGM_seg_155_165.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"approach (move towards)\", \"roles\": {\"1\": \"Arg1 (entity in motion)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity in motion)\": \"man in brown shirt\", \"Arg2 (destination)\": \"approaches a closed door\", \"ArgM (direction)\": \"to the side on his right\", \"ArgM (manner)\": \"with purpose\", \"Scene of the Event\": \"in a dimly lit building\"}}'}]},\n",
       " {'id': 'v_CShHiYrQPGM_seg_155_165_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CShHiYrQPGM_seg_155_165.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"break (break, cause to not be whole)\", \"roles\": {\"1\": \"Arg0 (breaker)\", \"2\": \"Arg1 (thing broken)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (breaker)\": \"man in brown shirt\", \"Arg1 (thing broken)\": \"breaks through the door\", \"Scene of the Event\": \"in a dimly lit building\"}}'}]},\n",
       " {'id': 'v_CShHiYrQPGM_seg_30_40_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CShHiYrQPGM_seg_30_40.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"two men\", \"ArgM (direction)\": \"walk towards building\", \"ArgM (manner)\": \"hunched over\", \"Scene of the Event\": \"in a resort at night\"}}'}]},\n",
       " {'id': 'v_CShHiYrQPGM_seg_30_40_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CShHiYrQPGM_seg_30_40.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"open (open)\", \"roles\": {\"1\": \"Arg0 (opener)\", \"2\": \"Arg1 (thing opening)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (opener)\": \"two men\", \"Arg1 (thing opening)\": \"open a door\", \"ArgM (manner)\": \"after walking up to it\", \"Scene of the Event\": \"in a resort at night\"}}'}]},\n",
       " {'id': 'v_CShHiYrQPGM_seg_30_40_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CShHiYrQPGM_seg_30_40.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"react (give a response, reaction)\", \"roles\": {\"1\": \"Arg0 (reactor)\", \"2\": \"Arg1 (reacted-to)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (reactor)\": \"two men\", \"Arg1 (reacted-to)\": \"react to a dead body\", \"ArgM (manner)\": \"with shock\", \"Scene of the Event\": \"in a resort at night\"}}'}]},\n",
       " {'id': 'v_CShHiYrQPGM_seg_30_40_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CShHiYrQPGM_seg_30_40.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"do (act)\", \"roles\": {\"1\": \"Arg0 (agent, doer)\", \"2\": \"Arg1 (thing done)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, doer)\": \"two men\", \"Arg1 (thing done)\": \"gasp\", \"Scene of the Event\": \"in a resort at night\"}}'}]},\n",
       " {'id': 'v_CShHiYrQPGM_seg_30_40_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CShHiYrQPGM_seg_30_40.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lie (more explicit horizontal position)\", \"roles\": {\"1\": \"Arg1 (entity lying down)\", \"2\": \"Arg2 (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (entity lying down)\": \"woman with brown hair\", \"Arg2 (location)\": \"lies in a tanning booth\", \"ArgM (manner)\": \"with her eyes and ears covered\"}}'}]},\n",
       " {'id': 'v_4us4K3KLRM0_seg_25_35_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_4us4K3KLRM0_seg_25_35.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"entertain (amuse)\", \"roles\": {\"1\": \"Arg0 (entertainer)\", \"2\": \"Arg1 (entertained)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entertainer)\": \"man in navy suit\", \"Arg1 (entertained)\": \"people walking by\", \"Scene of the Event\": \"city street\"}}'}]},\n",
       " {'id': 'v_4us4K3KLRM0_seg_25_35_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_4us4K3KLRM0_seg_25_35.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"give (transfer)\", \"roles\": {\"1\": \"Arg0 (giver)\", \"2\": \"Arg1 (thing given)\", \"3\": \"Arg2 (entity given to)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (giver)\": \"woman\", \"Arg1 (thing given)\": \"money\", \"Arg2 (entity given to)\": \"man in navy suit\", \"Scene of the Event\": \"on the sidewalk\"}}'}]},\n",
       " {'id': 'v_4us4K3KLRM0_seg_25_35_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_4us4K3KLRM0_seg_25_35.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"see (view)\", \"roles\": {\"1\": \"Arg0 (viewer)\", \"2\": \"Arg1 (thing viewed)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (viewer)\": \"camera man\", \"Arg1 (thing viewed)\": \"business sign\", \"ArgM (direction)\": \"up\", \"ArgM (location)\": \"on roof of a building\"}}'}]},\n",
       " {'id': 'v_4us4K3KLRM0_seg_25_35_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_4us4K3KLRM0_seg_25_35.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sit (be in a position)\", \"roles\": {\"1\": \"Arg1 (thing sitting)\", \"2\": \"Arg2 (location or position)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing sitting)\": \"man in red jacket\", \"Arg2 (location or position)\": \"behind a desk\", \"ArgM (manner)\": \"quietly\"}}'}]},\n",
       " {'id': 'v_4us4K3KLRM0_seg_25_35_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_4us4K3KLRM0_seg_25_35.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sit (be in a position)\", \"roles\": {\"1\": \"Arg1 (thing sitting)\", \"2\": \"Arg2 (location or position)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing sitting)\": \"man in red jacket\", \"Arg2 (location or position)\": \"behind a desk\", \"ArgM (manner)\": \"playing with toys\"}}'}]},\n",
       " {'id': 'v_HIBYaeYQF0k_seg_100_110_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_HIBYaeYQF0k_seg_100_110.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man wearing sunglasses\", \"Arg2 (hearer)\": \"girl in orange shirt\", \"ArgM (manner)\": \"casually while driving\", \"Scene of the Event\": \"inside a car\"}}'}]},\n",
       " {'id': 'v_HIBYaeYQF0k_seg_100_110_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_HIBYaeYQF0k_seg_100_110.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man wearing sunglasses\", \"Arg2 (hearer)\": \"boy with dark hair\", \"ArgM (manner)\": \"serious\", \"Scene of the Event\": \"inside a car\"}}'}]},\n",
       " {'id': 'v_HIBYaeYQF0k_seg_100_110_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_HIBYaeYQF0k_seg_100_110.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"chew (masticate)\", \"roles\": {\"1\": \"Arg0 (chewer)\", \"2\": \"Arg1 (food)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (chewer)\": \"man wearing sunglasses\", \"Arg1 (food)\": \"gum\", \"Scene of the Event\": \"inside a car\"}}'}]},\n",
       " {'id': 'v_HIBYaeYQF0k_seg_100_110_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_HIBYaeYQF0k_seg_100_110.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"respond (give an answer, reply)\", \"roles\": {\"1\": \"Arg0 (replier)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (replier)\": \"girl in orange shirt\", \"Scene of the Event\": \"backseat\"}}'}]},\n",
       " {'id': 'v_HIBYaeYQF0k_seg_100_110_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_HIBYaeYQF0k_seg_100_110.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"smile (to have or form a smile)\", \"roles\": {\"1\": \"Arg0 (agent smiling)\", \"2\": \"Arg2 (smiled at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent smiling)\": \"boy with dark hair\", \"Arg2 (smiled at)\": \"man wearing sunglasses\", \"ArgM (manner)\": \"in a chipper way\", \"Scene of the Event\": \"inside a car\"}}'}]},\n",
       " {'id': 'v_gPamy0ygNs8_seg_105_115_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gPamy0ygNs8_seg_105_115.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lift (cause increase in elevation)\", \"roles\": {\"1\": \"Arg0 (elevator, Agent)\", \"2\": \"Arg1 (Logical subject, patient, thing rising)\", \"3\": \"Arg3 (Start point)\", \"4\": \"Arg4 (End point)\", \"5\": \"ArgM (direction)\", \"6\": \"ArgM (manner)\", \"7\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (elevator, Agent)\": \"brown-haired man in a black t-shirt and blue shirt\", \"Arg1 (Logical subject, patient, thing rising)\": \"striped yellow and clear drinking glass\", \"Arg3 (Start point)\": \"from the table\", \"Arg4 (End point)\": \"towards his mouth\", \"ArgM (direction)\": \"dining room with white hanging lampshade light\", \"ArgM (manner)\": \"while talking\", \"Scene of the Event\": \"dining room with white hanging lampshade light\"}}'}]},\n",
       " {'id': 'v_gPamy0ygNs8_seg_105_115_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gPamy0ygNs8_seg_105_115.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sip (to drink in small quantities )\", \"roles\": {\"1\": \"Arg0 (drinker, agent)\", \"2\": \"Arg1 (drink)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (drinker, agent)\": \"brown-haired man in a black t-shirt and blue shirt\", \"Arg1 (drink)\": \"orange liquid from the striped yellow and clear drinking glass\", \"Scene of the Event\": \"dining room with white hanging lampshade light\"}}'}]},\n",
       " {'id': 'v_gPamy0ygNs8_seg_105_115_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gPamy0ygNs8_seg_105_115.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"react (give a response, reaction)\", \"roles\": {\"1\": \"Arg0 (reactor)\", \"2\": \"Arg1 (reacted-to)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (reactor)\": \"brown-haired man in a black pulloever\", \"Arg1 (reacted-to)\": \"brown-haired man in a black t-shirt and blue shirt\", \"ArgM (manner)\": \"with an amazed look, and one hand positioned to gesture near his mouth\", \"Scene of the Event\": \"dining room with white hanging lampshade light\"}}'}]},\n",
       " {'id': 'v_gPamy0ygNs8_seg_105_115_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gPamy0ygNs8_seg_105_115.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"silence (to make silent)\", \"roles\": {\"1\": \"Arg0 (cause of silence)\", \"2\": \"Arg1 (entity silenced)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cause of silence)\": \"brown-haired man in a black pulloever\", \"Arg1 (entity silenced)\": \"brown-haired man in a black pulloever\", \"Scene of the Event\": \"dining room with white hanging lampshade light\"}}'}]},\n",
       " {'id': 'v_gPamy0ygNs8_seg_105_115_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gPamy0ygNs8_seg_105_115.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"finish (cause to stop)\", \"roles\": {\"1\": \"Arg0 (Intentional agent)\", \"2\": \"Arg1 (Thing finishing)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Intentional agent)\": \"brown-haired man in a black t-shirt and blue shirt\", \"Arg1 (Thing finishing)\": \"orange liquid from the striped yellow and clear drinking glass\", \"Scene of the Event\": \"dining room with white hanging lampshade light\"}}'}]},\n",
       " {'id': 'v_avQ9Wvp5wZQ_seg_0_10_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_avQ9Wvp5wZQ_seg_0_10.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"Man in black hoodie and sunglasses\", \"ArgM (direction)\": \"forward\", \"ArgM (manner)\": \"inconspicuous\", \"Scene of the Event\": \"city street\"}}'}]},\n",
       " {'id': 'v_avQ9Wvp5wZQ_seg_0_10_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_avQ9Wvp5wZQ_seg_0_10.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"peer (to look searchingly)\", \"roles\": {\"1\": \"Arg0 (looker, searcher, agent)\", \"2\": \"Arg1 (entity peered into/at/over...)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker, searcher, agent)\": \"Man in black hoodie and sunglasses\", \"Arg1 (entity peered into/at/over...)\": \"city street\", \"ArgM (direction)\": \"forward and side to side\", \"ArgM (manner)\": \"inconspicuous\", \"Scene of the Event\": \"city street\"}}'}]},\n",
       " {'id': 'v_avQ9Wvp5wZQ_seg_0_10_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_avQ9Wvp5wZQ_seg_0_10.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"enter (enter, go in)\", \"roles\": {\"1\": \"Arg0 (entity entering)\", \"2\": \"Arg1 (place or thing entered)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity entering)\": \"Man in black hoodie and sunglasses\", \"Arg1 (place or thing entered)\": \"Bar\", \"ArgM (manner)\": \"inconspicuous\", \"Scene of the Event\": \"Bar\"}}'}]},\n",
       " {'id': 'v_avQ9Wvp5wZQ_seg_0_10_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_avQ9Wvp5wZQ_seg_0_10.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"Man in black hoodie and sunglasses\", \"Arg1 (thing looked at or for or on)\": \"off scene\", \"ArgM (direction)\": \"around\", \"ArgM (manner)\": \"searching\", \"Scene of the Event\": \"Bar\"}}'}]},\n",
       " {'id': 'v_avQ9Wvp5wZQ_seg_0_10_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_avQ9Wvp5wZQ_seg_0_10.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"unnerve (cause to be nervous)\", \"roles\": {\"1\": \"Arg0 (cause)\", \"2\": \"Arg1 (patient, entity become nervous)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cause)\": \"People in the bar area\", \"Arg1 (patient, entity become nervous)\": \"Man in black hoodie and sunglasses\", \"Scene of the Event\": \"Bar\"}}'}]},\n",
       " {'id': 'v_gMIvHGdpQpE_seg_5_15_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gMIvHGdpQpE_seg_5_15.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"the man with dark hair\", \"Arg2 (hearer)\": \"the woman with dark hair\", \"ArgM (location)\": \"in a bedroom\", \"ArgM (manner)\": \"as he holds his hands up in front of him\"}}'}]},\n",
       " {'id': 'v_gMIvHGdpQpE_seg_5_15_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gMIvHGdpQpE_seg_5_15.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"the woman with dark hair\", \"Arg2 (hearer)\": \"the man with dark hair\", \"ArgM (location)\": \"in a bedroom\", \"ArgM (manner)\": \"as she looks up at him\"}}'}]},\n",
       " {'id': 'v_gMIvHGdpQpE_seg_5_15_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gMIvHGdpQpE_seg_5_15.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lower (go down, esp of financial usage)\", \"roles\": {\"1\": \"Arg0 (entity moving something downward)\", \"2\": \"Arg1 (Logical subject, patient, thing going down)\", \"3\": \"Arg4 (end point, end state of arg1)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity moving something downward)\": \"the man with dark hair\", \"Arg1 (Logical subject, patient, thing going down)\": \"his hands\", \"Arg4 (end point, end state of arg1)\": \"in front of his body\", \"ArgM (manner)\": \"down by the side of his body\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_gMIvHGdpQpE_seg_5_15_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gMIvHGdpQpE_seg_5_15.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"the man with dark hair\", \"Arg2 (hearer)\": \"the woman with dark hair\", \"ArgM (location)\": \"in a bedroom\", \"ArgM (manner)\": \"as he looks away\"}}'}]},\n",
       " {'id': 'v_gMIvHGdpQpE_seg_5_15_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_gMIvHGdpQpE_seg_5_15.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sit (be in a position)\", \"roles\": {\"1\": \"Arg1 (thing sitting)\", \"2\": \"Arg2 (location or position)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing sitting)\": \"the man with dark hair\", \"Arg2 (location or position)\": \"on the couch\", \"ArgM (manner)\": \"slowly\"}}'}]},\n",
       " {'id': 'v_rt8L4_lD-_g_seg_20_30_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_rt8L4_lD-_g_seg_20_30.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"the boy in the yellow shirt\", \"Arg1 (looked at)\": \"the man on the floor\", \"ArgM (direction)\": \"down\", \"ArgM (manner)\": \"shocked\", \"Scene of the Event\": \"inside a public bathroom\"}}'}]},\n",
       " {'id': 'v_rt8L4_lD-_g_seg_20_30_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_rt8L4_lD-_g_seg_20_30.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"the boy in the yellow shirt\", \"Arg1 (looked at)\": \"the man on the floor\", \"ArgM (direction)\": \"down\", \"ArgM (manner)\": \"shocked\", \"Scene of the Event\": \"inside a public bathroom\"}}'}]},\n",
       " {'id': 'v_rt8L4_lD-_g_seg_20_30_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_rt8L4_lD-_g_seg_20_30.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"leave (move away from)\", \"roles\": {\"1\": \"Arg0 (entity leaving)\", \"2\": \"Arg1 (place, person, or thing left)\", \"3\": \"Arg2 (attribute of arg1)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (entity leaving)\": \"the boy in the yellow shirt\", \"Arg1 (place, person, or thing left)\": \"the man on the floor\", \"Arg2 (attribute of arg1)\": \"laying\", \"ArgM (location)\": \"inside a public bathroom\"}}'}]},\n",
       " {'id': 'v_rt8L4_lD-_g_seg_20_30_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_rt8L4_lD-_g_seg_20_30.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"leave (move away from)\", \"roles\": {\"1\": \"Arg0 (entity leaving)\", \"2\": \"Arg1 (place, person, or thing left)\", \"3\": \"Arg2 (attribute of arg1)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (entity leaving)\": \"the boy in the yellow shirt\", \"Arg1 (place, person, or thing left)\": \"the man on the floor\", \"Arg2 (attribute of arg1)\": \"laying\", \"ArgM (location)\": \"inside a public bathroom\"}}'}]},\n",
       " {'id': 'v_rt8L4_lD-_g_seg_20_30_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_rt8L4_lD-_g_seg_20_30.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hurt (be experiencing pain)\", \"roles\": {\"1\": \"Arg1 (patient, entity experiencing pain)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (patient, entity experiencing pain)\": \"the man with black hair\", \"Scene of the Event\": \"inside a public bathroom\"}}'}]},\n",
       " {'id': 'v_WnAVeKAUxPY_seg_160_170_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WnAVeKAUxPY_seg_160_170.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"the girl with the headband\", \"Arg1 (thing looked at or for or on)\": \"the girl with the short dark hair\", \"ArgM (direction)\": \"straight\", \"ArgM (manner)\": \"with concern\", \"Scene of the Event\": \"inside a bedroom\"}}'}]},\n",
       " {'id': 'v_WnAVeKAUxPY_seg_160_170_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WnAVeKAUxPY_seg_160_170.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"the girl with blonde hair and the girl with short dark hair\", \"Arg1 (thing looked at or for or on)\": \"bones from a roasted chicken\", \"ArgM (direction)\": \"under the bed\", \"ArgM (manner)\": \"with confusion\", \"Scene of the Event\": \"inside a bedroom\"}}'}]},\n",
       " {'id': 'v_WnAVeKAUxPY_seg_160_170_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WnAVeKAUxPY_seg_160_170.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"smell (notice an odor)\", \"roles\": {\"1\": \"Arg0 (entity with a nose)\", \"2\": \"Arg1 (stinky thing)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity with a nose)\": \"the girl with blonde hair and the girl with short dark hair\", \"Arg1 (stinky thing)\": \"bones from a roasted chicken\", \"Scene of the Event\": \"inside a bedroom\"}}'}]},\n",
       " {'id': 'v_WnAVeKAUxPY_seg_160_170_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WnAVeKAUxPY_seg_160_170.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"the girl with the headband\", \"Arg1 (thing looked at or for or on)\": \"the girl with blonde hair and the girl with short dark hair\", \"ArgM (direction)\": \"down\", \"ArgM (manner)\": \"with concern\", \"Scene of the Event\": \"inside a bedroom\"}}'}]},\n",
       " {'id': 'v_WnAVeKAUxPY_seg_160_170_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WnAVeKAUxPY_seg_160_170.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"the girl with the headband\", \"Arg2 (hearer)\": \"the girl with blonde hair and the girl with short dark hair\", \"ArgM (location)\": \"inside a bedroom\", \"ArgM (manner)\": \"with concern\"}}'}]},\n",
       " {'id': 'v_wt0klpk3tBA_seg_40_50_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_wt0klpk3tBA_seg_40_50.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"spit (eject saliva)\", \"roles\": {\"1\": \"Arg0 (spitter)\", \"2\": \"Arg1 (explicit mention of saliva)\", \"3\": \"Arg2 (spat-on)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (spitter)\": \"A younger man\", \"Arg1 (explicit mention of saliva)\": \"tabacco\", \"Arg2 (spat-on)\": \"the ground\", \"Scene of the Event\": \"in a doorway\"}}'}]},\n",
       " {'id': 'v_wt0klpk3tBA_seg_40_50_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_wt0klpk3tBA_seg_40_50.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"lean (to incline or cause to incline)\", \"roles\": {\"1\": \"Arg0 (causer of leaning)\", \"2\": \"Arg2 (direction)\", \"3\": \"ArgM (purpose)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of leaning)\": \"An older coach\", \"Arg2 (direction)\": \"to his side\", \"ArgM (purpose)\": \"to reach with something\", \"Scene of the Event\": \"while seated\"}}'}]},\n",
       " {'id': 'v_wt0klpk3tBA_seg_40_50_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_wt0klpk3tBA_seg_40_50.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"squeeze (extract or insert by means of pressure)\", \"roles\": {\"1\": \"Arg0 (squeezer)\", \"2\": \"Arg1 (extracted material)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (squeezer)\": \"The coach\", \"Arg1 (extracted material)\": \"liquid\", \"Scene of the Event\": \"while seated\"}}'}]},\n",
       " {'id': 'v_wt0klpk3tBA_seg_40_50_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_wt0klpk3tBA_seg_40_50.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stand ((cause to) be in a vertical position)\", \"roles\": {\"1\": \"Arg1 (thing standing)\", \"2\": \"Arg2 (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing standing)\": \"The coach\", \"Arg2 (location)\": \"from the seat\", \"ArgM (manner)\": \"slowly\"}}'}]},\n",
       " {'id': 'v_wt0klpk3tBA_seg_40_50_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_wt0klpk3tBA_seg_40_50.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"The coach\", \"ArgM (direction)\": \"forward\", \"ArgM (manner)\": \"slowly\", \"Scene of the Event\": \"in a boxseat\"}}'}]},\n",
       " {'id': 'v_RgaUubM7yyY_seg_95_105_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_RgaUubM7yyY_seg_95_105.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man in brown shirt\", \"Arg1 (thing looked at or for or on)\": \"looks at woman with brown hair\", \"ArgM (direction)\": \"in front of him\", \"ArgM (manner)\": \"while gesturing with his hand\", \"Scene of the Event\": \"in a room with couches\"}}'}]},\n",
       " {'id': 'v_RgaUubM7yyY_seg_95_105_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_RgaUubM7yyY_seg_95_105.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"woman with brown hair\", \"Arg2 (hearer)\": \"speaks to man in brown shirt\", \"ArgM (location)\": \"across the room\", \"ArgM (manner)\": \"while looking downward\"}}'}]},\n",
       " {'id': 'v_RgaUubM7yyY_seg_95_105_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_RgaUubM7yyY_seg_95_105.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shout (yell, or announce loudly)\", \"roles\": {\"1\": \"Arg0 (shouter)\", \"2\": \"Arg2 (listener)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shouter)\": \"man in brown shirt\", \"Arg2 (listener)\": \"shouts at woman with brown hair\", \"Scene of the Event\": \"in a room with couches\"}}'}]},\n",
       " {'id': 'v_RgaUubM7yyY_seg_95_105_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_RgaUubM7yyY_seg_95_105.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"do (act)\", \"roles\": {\"1\": \"Arg0 (agent, doer)\", \"2\": \"Arg1 (thing done)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, doer)\": \"man in brown shirt\", \"Arg1 (thing done)\": \"leans forward in frustration\", \"Scene of the Event\": \"in a room with couches\"}}'}]},\n",
       " {'id': 'v_RgaUubM7yyY_seg_95_105_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_RgaUubM7yyY_seg_95_105.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"approach (move towards)\", \"roles\": {\"1\": \"Arg1 (entity in motion)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity in motion)\": \"woman with brown hair\", \"Arg2 (destination)\": \"approaches man in brown shirt\", \"ArgM (direction)\": \"in front of her\", \"ArgM (manner)\": \"cautiously\", \"Scene of the Event\": \"in a room with couches\"}}'}]},\n",
       " {'id': 'v_QslzL-DhXDY_seg_30_40_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QslzL-DhXDY_seg_30_40.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"gesture (body language)\", \"roles\": {\"1\": \"Arg0 (gesturer)\", \"2\": \"Arg1 (gestured at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (gesturer)\": \"Man in black suit\", \"Arg1 (gestured at)\": \"off scene\", \"Scene of the Event\": \"airport\"}}'}]},\n",
       " {'id': 'v_QslzL-DhXDY_seg_30_40_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QslzL-DhXDY_seg_30_40.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shamble (walk in an awkward manner)\", \"roles\": {\"1\": \"Arg0 (agent, shambling entity)\", \"2\": \"Arg1 (path)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, shambling entity)\": \"Man in black suit\", \"Arg1 (path)\": \"in same area\", \"ArgM (direction)\": \"backwards\", \"Scene of the Event\": \"airport\"}}'}]},\n",
       " {'id': 'v_QslzL-DhXDY_seg_30_40_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QslzL-DhXDY_seg_30_40.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sit (be in a position)\", \"roles\": {\"1\": \"Arg1 (thing sitting)\", \"2\": \"Arg2 (location or position)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing sitting)\": \"Woman in white coat\", \"Arg2 (location or position)\": \"sitting in tall chair at island counter in kitchen\", \"ArgM (manner)\": \"waiting\"}}'}]},\n",
       " {'id': 'v_QslzL-DhXDY_seg_30_40_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QslzL-DhXDY_seg_30_40.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"phone (to telephone)\", \"roles\": {\"1\": \"Arg0 (agent making a call)\", \"2\": \"Arg1 (receiver)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent making a call)\": \"Man in black suit\", \"Arg1 (receiver)\": \"off scene\", \"Scene of the Event\": \"airport\"}}'}]},\n",
       " {'id': 'v_QslzL-DhXDY_seg_30_40_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_QslzL-DhXDY_seg_30_40.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"unnerve (cause to be nervous)\", \"roles\": {\"1\": \"Arg0 (cause)\", \"2\": \"Arg1 (patient, entity become nervous)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cause)\": \"waiting\", \"Arg1 (patient, entity become nervous)\": \"Man in black suit\", \"Scene of the Event\": \"airport\"}}'}]},\n",
       " {'id': 'v_5BL8zybMd-M_seg_10_20_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_5BL8zybMd-M_seg_10_20.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"kneel (on bended knee)\", \"roles\": {\"1\": \"Arg0 (kneeler)\", \"2\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (kneeler)\": \"man with dark hair\", \"ArgM (location)\": \"in a building\"}}'}]},\n",
       " {'id': 'v_5BL8zybMd-M_seg_10_20_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_5BL8zybMd-M_seg_10_20.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man in black\", \"ArgM (direction)\": \"through a room\", \"ArgM (manner)\": \"quickly while speaking\", \"Scene of the Event\": \"in a building\"}}'}]},\n",
       " {'id': 'v_5BL8zybMd-M_seg_10_20_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_5BL8zybMd-M_seg_10_20.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"respond (give an answer, reply)\", \"roles\": {\"1\": \"Arg0 (replier)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (replier)\": \"man with dark hair\", \"Scene of the Event\": \"lobby\"}}'}]},\n",
       " {'id': 'v_5BL8zybMd-M_seg_10_20_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_5BL8zybMd-M_seg_10_20.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man in black\", \"ArgM (direction)\": \"inside a safe\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"bank\"}}'}]},\n",
       " {'id': 'v_5BL8zybMd-M_seg_10_20_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_5BL8zybMd-M_seg_10_20.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"wait (wait)\", \"roles\": {\"1\": \"Arg1 (wait-er (not waiter, that\\'s the other sense))\", \"2\": \"Arg2 (thing waited for)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (wait-er (not waiter, that\\'s the other sense))\": \"man with dark hair\", \"Arg2 (thing waited for)\": \"man in black\", \"ArgM (location)\": \"lobby\", \"ArgM (manner)\": \"nervously\"}}'}]},\n",
       " {'id': 'v_CDywMUdVPqk_seg_15_25_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CDywMUdVPqk_seg_15_25.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hoist (lift, raise)\", \"roles\": {\"1\": \"Arg0 (lifter, raiser)\", \"2\": \"Arg1 (thing going up)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (lifter, raiser)\": \"naked bold headed man\", \"Arg1 (thing going up)\": \"his arms\", \"ArgM (direction)\": \"towards a CD player\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_CDywMUdVPqk_seg_15_25_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CDywMUdVPqk_seg_15_25.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"naked bold headed man\", \"Arg1 (looked at)\": \"a CD player\", \"ArgM (direction)\": \"up\", \"ArgM (manner)\": \"wordlessly\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_CDywMUdVPqk_seg_15_25_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CDywMUdVPqk_seg_15_25.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"punch (to hit or press (a key or a button))\", \"roles\": {\"1\": \"Arg0 (agent)\", \"2\": \"Arg1 (entity punched)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (agent)\": \"naked bold headed man\", \"Arg1 (entity punched)\": \"a CD player\\'s button\", \"ArgM (direction)\": \"on\", \"ArgM (location)\": \"above him\"}}'}]},\n",
       " {'id': 'v_CDywMUdVPqk_seg_15_25_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CDywMUdVPqk_seg_15_25.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"set (put, place)\", \"roles\": {\"1\": \"Arg0 (agent, setter)\", \"2\": \"Arg1 (thing set)\", \"3\": \"Arg2 (location or position)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (agent, setter)\": \"naked bold headed man\", \"Arg1 (thing set)\": \"a CD\", \"Arg2 (location or position)\": \"into a CD player\", \"ArgM (manner)\": \"gently\"}}'}]},\n",
       " {'id': 'v_CDywMUdVPqk_seg_15_25_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CDywMUdVPqk_seg_15_25.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"gesture (body language)\", \"roles\": {\"1\": \"Arg0 (gesturer)\", \"2\": \"Arg1 (gestured at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (gesturer)\": \"naked bold headed man\", \"Arg1 (gestured at)\": \"a CD player\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_CDywMUdVPqk_seg_115_125_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CDywMUdVPqk_seg_115_125.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"slide (slide)\", \"roles\": {\"1\": \"Arg0 (agent, causer of sliding)\", \"2\": \"Arg1 (thing sliding)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, causer of sliding)\": \"bald man\", \"Arg1 (thing sliding)\": \"slides himself\", \"ArgM (direction)\": \"backwards\", \"Scene of the Event\": \"on the floor of a bedroom\"}}'}]},\n",
       " {'id': 'v_CDywMUdVPqk_seg_115_125_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CDywMUdVPqk_seg_115_125.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"do (act)\", \"roles\": {\"1\": \"Arg0 (agent, doer)\", \"2\": \"Arg1 (thing done)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, doer)\": \"bald man\", \"Arg1 (thing done)\": \"loosens his muscles and leans forward\", \"Scene of the Event\": \"on the floor of a bedroom\"}}'}]},\n",
       " {'id': 'v_CDywMUdVPqk_seg_115_125_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CDywMUdVPqk_seg_115_125.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"woman with brown hair\", \"Arg2 (hearer)\": \"talks to bald man\", \"ArgM (location)\": \"in front of her\", \"ArgM (manner)\": \"while shrugging and gesturing in exasperation\"}}'}]},\n",
       " {'id': 'v_CDywMUdVPqk_seg_115_125_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CDywMUdVPqk_seg_115_125.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"woman with brown hair\", \"Arg2 (hearer)\": \"talks to bald man\", \"ArgM (location)\": \"in front of her\", \"ArgM (manner)\": \"while shrugging and gesturing in exasperation\"}}'}]},\n",
       " {'id': 'v_CDywMUdVPqk_seg_115_125_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_CDywMUdVPqk_seg_115_125.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"bald man\", \"ArgM (direction)\": \"walks toward woman with brown hair\", \"ArgM (manner)\": \"confidently while gesturing with his index finger\", \"Scene of the Event\": \"in a bedroom\"}}'}]},\n",
       " {'id': 'v_1JLugcZa7kw_seg_50_60_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_1JLugcZa7kw_seg_50_60.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"unlock (detach, open)\", \"roles\": {\"1\": \"Arg0 (entity with a key, agent)\", \"2\": \"Arg1 (things that were attached)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity with a key, agent)\": \"the woman with brown hair\", \"Arg1 (things that were attached)\": \"the man belt\", \"Scene of the Event\": \"in a hallway\"}}'}]},\n",
       " {'id': 'v_1JLugcZa7kw_seg_50_60_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_1JLugcZa7kw_seg_50_60.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"undress (to remove clothes)\", \"roles\": {\"1\": \"Arg0 (person removing clothes)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (person removing clothes)\": \"the woman with brown hair\", \"Scene of the Event\": \"the man in the hallway\"}}'}]},\n",
       " {'id': 'v_1JLugcZa7kw_seg_50_60_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_1JLugcZa7kw_seg_50_60.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"undress (to remove clothes)\", \"roles\": {\"1\": \"Arg0 (person removing clothes)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (person removing clothes)\": \"the woman with brown hair\", \"Scene of the Event\": \"the man in the hallway\"}}'}]},\n",
       " {'id': 'v_1JLugcZa7kw_seg_50_60_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_1JLugcZa7kw_seg_50_60.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"peek (look at, sneakily)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"the man with the blonde hair\", \"ArgM (direction)\": \"through the window\", \"Scene of the Event\": \"at the woman and the man in the hallway\"}}'}]},\n",
       " {'id': 'v_1JLugcZa7kw_seg_50_60_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_1JLugcZa7kw_seg_50_60.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"peek (look at, sneakily)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"the man with the blonde hair\", \"ArgM (direction)\": \"through the window\", \"Scene of the Event\": \"at the woman and the man in the hallway\"}}'}]},\n",
       " {'id': 'v_Fz9Y72jbsxU_seg_80_90_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Fz9Y72jbsxU_seg_80_90.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sneak (move stealthily)\", \"roles\": {\"1\": \"Arg0 (entity sneaking)\", \"2\": \"Arg1 (destination)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity sneaking)\": \"three men\", \"Arg1 (destination)\": \"into a room\", \"Scene of the Event\": \"in a hallway\"}}'}]},\n",
       " {'id': 'v_Fz9Y72jbsxU_seg_80_90_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Fz9Y72jbsxU_seg_80_90.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"turn (rotation)\", \"roles\": {\"1\": \"Arg0 (turner)\", \"2\": \"Arg1 (thing turning)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (purpose)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (turner)\": \"clean shaven man\", \"Arg1 (thing turning)\": \"his body\", \"ArgM (direction)\": \"side\", \"ArgM (purpose)\": \"positioning himself to get a good peek through a door\", \"Scene of the Event\": \"in a hallway\"}}'}]},\n",
       " {'id': 'v_Fz9Y72jbsxU_seg_80_90_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Fz9Y72jbsxU_seg_80_90.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"glance (look at briefly)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked-at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"clean shaven man and a man in a blue baseball cap\", \"Arg1 (looked-at)\": \"man in a blue half jacket\", \"ArgM (direction)\": \"other their shoulders\", \"ArgM (manner)\": \"briefly\", \"Scene of the Event\": \"in a hallway\"}}'}]},\n",
       " {'id': 'v_Fz9Y72jbsxU_seg_80_90_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Fz9Y72jbsxU_seg_80_90.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"open (open)\", \"roles\": {\"1\": \"Arg0 (opener)\", \"2\": \"Arg1 (thing opening)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (opener)\": \"clean shaven man and a man in a blue baseball cap\", \"Arg1 (thing opening)\": \"a door\", \"ArgM (manner)\": \"slowly\", \"Scene of the Event\": \"in a hallway\"}}'}]},\n",
       " {'id': 'v_Fz9Y72jbsxU_seg_80_90_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Fz9Y72jbsxU_seg_80_90.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"peek (look at, sneakily)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man in a blue baseball cap\", \"ArgM (direction)\": \"through the gap on the door\", \"Scene of the Event\": \"in a hallway\"}}'}]},\n",
       " {'id': 'v_YALDmRKFYSk_seg_115_125_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_YALDmRKFYSk_seg_115_125.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"listen (attend to a sound)\", \"roles\": {\"1\": \"Arg0 (listener)\", \"2\": \"Arg1 (sound or speaker)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (listener)\": \"man with scarf\", \"Arg1 (sound or speaker)\": \"man in brown jacket\", \"ArgM (manner)\": \"shocked\", \"Scene of the Event\": \"bathhouse\"}}'}]},\n",
       " {'id': 'v_YALDmRKFYSk_seg_115_125_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_YALDmRKFYSk_seg_115_125.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"leave (move away from)\", \"roles\": {\"1\": \"Arg0 (entity leaving)\", \"2\": \"Arg1 (place, person, or thing left)\", \"3\": \"Arg2 (attribute of arg1)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (entity leaving)\": \"man in brown jacket\", \"Arg1 (place, person, or thing left)\": \"man with scarf\", \"Arg2 (attribute of arg1)\": \"from the\", \"ArgM (location)\": \"bathhouse\"}}'}]},\n",
       " {'id': 'v_YALDmRKFYSk_seg_115_125_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_YALDmRKFYSk_seg_115_125.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"watch (look at)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"man with scarf\", \"Arg1 (thing looked at)\": \"man in brown jacket\", \"ArgM (manner)\": \"sadly\", \"Scene of the Event\": \"bathhouse\"}}'}]},\n",
       " {'id': 'v_YALDmRKFYSk_seg_115_125_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_YALDmRKFYSk_seg_115_125.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"feel (emote)\", \"roles\": {\"1\": \"Arg0 (feeler, person experiencing emotion)\", \"2\": \"Arg1 (emotion or sensation)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (feeler, person experiencing emotion)\": \"man with scarf\", \"Arg1 (emotion or sensation)\": \"sadness\", \"Scene of the Event\": \"bathhouse\"}}'}]},\n",
       " {'id': 'v_YALDmRKFYSk_seg_115_125_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_YALDmRKFYSk_seg_115_125.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"feel (emote)\", \"roles\": {\"1\": \"Arg0 (feeler, person experiencing emotion)\", \"2\": \"Arg1 (emotion or sensation)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (feeler, person experiencing emotion)\": \"man with scarf\", \"Arg1 (emotion or sensation)\": \"sadness\", \"Scene of the Event\": \"bathhouse\"}}'}]},\n",
       " {'id': 'v_HcuptmqW_kA_seg_5_15_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_HcuptmqW_kA_seg_5_15.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stop (stop)\", \"roles\": {\"1\": \"Arg0 (Agent)\", \"2\": \"Arg1 (Theme (action or object being stopped))\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (Agent)\": \"man in green jacket\", \"Arg1 (Theme (action or object being stopped))\": \"bald man\", \"ArgM (location)\": \"behind a tree\"}}'}]},\n",
       " {'id': 'v_HcuptmqW_kA_seg_5_15_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_HcuptmqW_kA_seg_5_15.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fire (fire a gun)\", \"roles\": {\"1\": \"Arg0 (shooter)\", \"2\": \"Arg1 (gun)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shooter)\": \"man in green jacket\", \"Arg1 (gun)\": \"gun\", \"ArgM (direction)\": \"at woman with gun\", \"Scene of the Event\": \"behind a tree\"}}'}]},\n",
       " {'id': 'v_HcuptmqW_kA_seg_5_15_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_HcuptmqW_kA_seg_5_15.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"motion (to direct with a gesture)\", \"roles\": {\"1\": \"Arg0 (gesturer)\", \"2\": \"Arg1 (gestured at)\", \"3\": \"Arg2 (for what)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (gesturer)\": \"man in suit\", \"Arg1 (gestured at)\": \"man with dark hair\", \"Arg2 (for what)\": \"to listen\", \"Scene of the Event\": \"inside building\"}}'}]},\n",
       " {'id': 'v_HcuptmqW_kA_seg_5_15_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_HcuptmqW_kA_seg_5_15.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sit (be in a position)\", \"roles\": {\"1\": \"Arg1 (thing sitting)\", \"2\": \"Arg2 (location or position)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing sitting)\": \"older man\", \"Arg2 (location or position)\": \"on a cot\", \"ArgM (manner)\": \"looking at other man\"}}'}]},\n",
       " {'id': 'v_HcuptmqW_kA_seg_5_15_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_HcuptmqW_kA_seg_5_15.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"respond (give an answer, reply)\", \"roles\": {\"1\": \"Arg0 (replier)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (replier)\": \"man in suit\", \"Scene of the Event\": \"inside building\"}}'}]},\n",
       " {'id': 'v_b1KjK4fd3ZU_seg_85_95_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_b1KjK4fd3ZU_seg_85_95.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"reach (stretch, grasp)\", \"roles\": {\"1\": \"Arg0 (reacher)\", \"2\": \"Arg1 (body part)\", \"3\": \"Arg2 (goal)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (purpose)\", \"6\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (reacher)\": \"the woman in the white robe\", \"Arg1 (body part)\": \"a hand\", \"Arg2 (goal)\": \"the phone\", \"ArgM (direction)\": \"towards\", \"ArgM (purpose)\": \"to call someone\", \"Scene of the Event\": \"inside a bedroom\"}}'}]},\n",
       " {'id': 'v_b1KjK4fd3ZU_seg_85_95_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_b1KjK4fd3ZU_seg_85_95.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"dial (to call on a telephone)\", \"roles\": {\"1\": \"Arg0 (entity dialing, agent)\", \"2\": \"Arg1 (dialed number)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity dialing, agent)\": \"the woman in the white robe\", \"Arg1 (dialed number)\": \"unknown\", \"Scene of the Event\": \"inside a bedroom\"}}'}]},\n",
       " {'id': 'v_b1KjK4fd3ZU_seg_85_95_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_b1KjK4fd3ZU_seg_85_95.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"listen (attend to a sound)\", \"roles\": {\"1\": \"Arg0 (listener)\", \"2\": \"Arg1 (sound or speaker)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (listener)\": \"the woman in the white robe\", \"Arg1 (sound or speaker)\": \"for the person on the other end of the phone\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"inside a bedroom\"}}'}]},\n",
       " {'id': 'v_b1KjK4fd3ZU_seg_85_95_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_b1KjK4fd3ZU_seg_85_95.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"the woman in the white robe\", \"Arg2 (hearer)\": \"the person on the other end of the phone\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"inside a bedroom\"}}'}]},\n",
       " {'id': 'v_b1KjK4fd3ZU_seg_85_95_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_b1KjK4fd3ZU_seg_85_95.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"the woman in the white robe\", \"Arg2 (hearer)\": \"the person on the other end of the phone\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"inside a bedroom\"}}'}]},\n",
       " {'id': 'v_b1KjK4fd3ZU_seg_120_130_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_b1KjK4fd3ZU_seg_120_130.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"yell (to cry out loudly)\", \"roles\": {\"1\": \"Arg0 (Yeller)\", \"2\": \"Arg2 (Hearer)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Yeller)\": \"the woman with dark hair\", \"Arg2 (Hearer)\": \"the man wearing a suit\", \"Scene of the Event\": \"inside a bedroom\"}}'}]},\n",
       " {'id': 'v_b1KjK4fd3ZU_seg_120_130_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_b1KjK4fd3ZU_seg_120_130.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hold (grasp, bear, keep)\", \"roles\": {\"1\": \"Arg0 (holder)\", \"2\": \"Arg1 (thing held)\", \"3\": \"Arg2 (benefactive)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (location)\", \"6\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (holder)\": \"the man wearing a suit\", \"Arg1 (thing held)\": \"the woman with dark hair\", \"Arg2 (benefactive)\": \"on the bed\", \"ArgM (direction)\": \"down\", \"ArgM (location)\": \"inside a bedroom\", \"ArgM (manner)\": \"as he pins her down by the arms\"}}'}]},\n",
       " {'id': 'v_b1KjK4fd3ZU_seg_120_130_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_b1KjK4fd3ZU_seg_120_130.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hold (grasp, bear, keep)\", \"roles\": {\"1\": \"Arg0 (holder)\", \"2\": \"Arg1 (thing held)\", \"3\": \"Arg2 (benefactive)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (location)\", \"6\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (holder)\": \"the man wearing a suit\", \"Arg1 (thing held)\": \"the woman with dark hair\", \"Arg2 (benefactive)\": \"on the bed\", \"ArgM (direction)\": \"down\", \"ArgM (location)\": \"inside a bedroom\", \"ArgM (manner)\": \"as he pins her down by the arms\"}}'}]},\n",
       " {'id': 'v_b1KjK4fd3ZU_seg_120_130_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_b1KjK4fd3ZU_seg_120_130.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"the woman with dark hair\", \"Arg2 (hearer)\": \"the man wearing a suit\", \"ArgM (location)\": \"inside a bedroom\", \"ArgM (manner)\": \"as she struggles\"}}'}]},\n",
       " {'id': 'v_b1KjK4fd3ZU_seg_120_130_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_b1KjK4fd3ZU_seg_120_130.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"release (let go)\", \"roles\": {\"1\": \"Arg0 (releaser)\", \"2\": \"Arg1 (thing released)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (releaser)\": \"the man wearing a suit\", \"Arg1 (thing released)\": \"the woman with dark hair\", \"Scene of the Event\": \"inside a bedroom\"}}'}]},\n",
       " {'id': 'v_ebNbXsFdz9w_seg_155_165_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ebNbXsFdz9w_seg_155_165.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"react (give a response, reaction)\", \"roles\": {\"1\": \"Arg0 (reactor)\", \"2\": \"Arg1 (reacted-to)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (reactor)\": \"older red haired woman and older gray haired woman\", \"Arg1 (reacted-to)\": \"man stepping on baby\", \"ArgM (manner)\": \"while leaning back\", \"Scene of the Event\": \"in a playground\"}}'}]},\n",
       " {'id': 'v_ebNbXsFdz9w_seg_155_165_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ebNbXsFdz9w_seg_155_165.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"set (put, place)\", \"roles\": {\"1\": \"Arg0 (agent, setter)\", \"2\": \"Arg1 (thing set)\", \"3\": \"Arg2 (location or position)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (agent, setter)\": \"man in gray pants\", \"Arg1 (thing set)\": \"his foot\", \"Arg2 (location or position)\": \"baby doll in red and white striped clothes\", \"ArgM (manner)\": \"to pin it down to the floor\"}}'}]},\n",
       " {'id': 'v_ebNbXsFdz9w_seg_155_165_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ebNbXsFdz9w_seg_155_165.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"collapse (fall down)\", \"roles\": {\"1\": \"Arg1 (thing collapsing)\", \"2\": \"ArgM (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing collapsing)\": \"man stepping on baby\", \"ArgM (location)\": \"backward on a swing\", \"ArgM (manner)\": \"suddenly\"}}'}]},\n",
       " {'id': 'v_ebNbXsFdz9w_seg_155_165_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ebNbXsFdz9w_seg_155_165.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"approach (move towards)\", \"roles\": {\"1\": \"Arg1 (entity in motion)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity in motion)\": \"baby doll in red and white striped clothes\", \"Arg2 (destination)\": \"man in gray pants\", \"ArgM (direction)\": \"by the swing\", \"ArgM (manner)\": \"ominously\", \"Scene of the Event\": \"in a playground\"}}'}]},\n",
       " {'id': 'v_ebNbXsFdz9w_seg_155_165_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_ebNbXsFdz9w_seg_155_165.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"throw (throw)\", \"roles\": {\"1\": \"Arg0 (thrower)\", \"2\": \"Arg1 (thing thrown)\", \"3\": \"Arg2 (thrown at, to, over, etc)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (thrower)\": \"man in gray pants\", \"Arg1 (thing thrown)\": \"swing seat\", \"Arg2 (thrown at, to, over, etc)\": \"baby doll in red and white striped clothes\", \"ArgM (manner)\": \"aggressively\", \"Scene of the Event\": \"in a playground\"}}'}]},\n",
       " {'id': 'v__H0EYJHeddU_seg_185_195_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__H0EYJHeddU_seg_185_195.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"nod (to lower and raise the head or to express by nodding)\", \"roles\": {\"1\": \"Arg0 (entity with a bobbing head, agent)\", \"2\": \"ArgM (manner)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity with a bobbing head, agent)\": \"man wearing a black shirt\", \"ArgM (manner)\": \"while staring at a man in front of him\", \"Scene of the Event\": \"in front of a wall with photos\"}}'}]},\n",
       " {'id': 'v__H0EYJHeddU_seg_185_195_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__H0EYJHeddU_seg_185_195.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"a man wearing a shirt with a collar\", \"Arg2 (hearer)\": \"man wearing a black shirt\", \"ArgM (location)\": \"in front of him\", \"ArgM (manner)\": \"face to face\"}}'}]},\n",
       " {'id': 'v__H0EYJHeddU_seg_185_195_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__H0EYJHeddU_seg_185_195.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"reach (stretch, grasp)\", \"roles\": {\"1\": \"Arg0 (reacher)\", \"2\": \"Arg1 (body part)\", \"3\": \"Arg2 (goal)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (purpose)\", \"6\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (reacher)\": \"a man wearing a shirt with a collar\", \"Arg1 (body part)\": \"his left arm\", \"Arg2 (goal)\": \"to grab something\", \"ArgM (direction)\": \"to the left\", \"ArgM (purpose)\": \"to pick up something\", \"Scene of the Event\": \"near a window\"}}'}]},\n",
       " {'id': 'v__H0EYJHeddU_seg_185_195_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__H0EYJHeddU_seg_185_195.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"bargain (to negotiate the terms of agreement)\", \"roles\": {\"1\": \"Arg0 (negotiator, agent)\", \"2\": \"Arg1 (thing bargained for)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (negotiator, agent)\": \"a man wearing a shirt with a collar\", \"Arg1 (thing bargained for)\": \"-\", \"Scene of the Event\": \"near a window\"}}'}]},\n",
       " {'id': 'v__H0EYJHeddU_seg_185_195_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__H0EYJHeddU_seg_185_195.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"give (transfer)\", \"roles\": {\"1\": \"Arg0 (giver)\", \"2\": \"Arg1 (thing given)\", \"3\": \"Arg2 (entity given to)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (giver)\": \"a man wearing a shirt with a collar\", \"Arg1 (thing given)\": \"a gun\", \"Arg2 (entity given to)\": \"man wearing a black shirt\", \"Scene of the Event\": \"near a window\"}}'}]},\n",
       " {'id': 'v_reQPn8oDC2c_seg_10_20_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_reQPn8oDC2c_seg_10_20.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stand ((cause to) be in a vertical position)\", \"roles\": {\"1\": \"Arg1 (thing standing)\", \"2\": \"Arg2 (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing standing)\": \"creature\", \"Arg2 (location)\": \"doorway\", \"ArgM (manner)\": \"frighteningly\"}}'}]},\n",
       " {'id': 'v_reQPn8oDC2c_seg_10_20_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_reQPn8oDC2c_seg_10_20.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"see (view)\", \"roles\": {\"1\": \"Arg0 (viewer)\", \"2\": \"Arg1 (thing viewed)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (viewer)\": \"man\", \"Arg1 (thing viewed)\": \"creature\", \"ArgM (direction)\": \"across room\", \"ArgM (location)\": \"cabin\"}}'}]},\n",
       " {'id': 'v_reQPn8oDC2c_seg_10_20_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_reQPn8oDC2c_seg_10_20.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"back (move backwards)\", \"roles\": {\"1\": \"Arg0 (causer of backwards motion)\", \"2\": \"Arg1 (entity in motion)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of backwards motion)\": \"fright\", \"Arg1 (entity in motion)\": \"man\", \"ArgM (direction)\": \"away from creature\", \"Scene of the Event\": \"cabin\"}}'}]},\n",
       " {'id': 'v_reQPn8oDC2c_seg_10_20_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_reQPn8oDC2c_seg_10_20.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"bump (collide)\", \"roles\": {\"1\": \"Arg1 (one thing in collision)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (one thing in collision)\": \"man\", \"Scene of the Event\": \"cabin\"}}'}]},\n",
       " {'id': 'v_reQPn8oDC2c_seg_10_20_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_reQPn8oDC2c_seg_10_20.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fall (move downward)\", \"roles\": {\"1\": \"Arg1 (Logical subject, patient, thing falling)\", \"2\": \"Arg3 (start point)\", \"3\": \"Arg4 (end point, end state of arg1)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (manner)\", \"6\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (Logical subject, patient, thing falling)\": \"man\", \"Arg3 (start point)\": \"standing\", \"Arg4 (end point, end state of arg1)\": \"on the floor\", \"ArgM (direction)\": \"down\", \"ArgM (manner)\": \"after knocking a knight in shining armor on himself\", \"Scene of the Event\": \"cabin\"}}'}]},\n",
       " {'id': 'v_OHNZUmdqdv8_seg_70_80_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_OHNZUmdqdv8_seg_70_80.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"man with mustache\", \"Arg2 (hearer)\": \"man in blue shirt\", \"ArgM (location)\": \"office\", \"ArgM (manner)\": \"fidgety and nervous\"}}'}]},\n",
       " {'id': 'v_OHNZUmdqdv8_seg_70_80_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_OHNZUmdqdv8_seg_70_80.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"frustrate (cause angst)\", \"roles\": {\"1\": \"Arg1 (entity frustrated)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity frustrated)\": \"man with mustache\", \"Scene of the Event\": \"office\"}}'}]},\n",
       " {'id': 'v_OHNZUmdqdv8_seg_70_80_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_OHNZUmdqdv8_seg_70_80.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"leave (move away from)\", \"roles\": {\"1\": \"Arg0 (entity leaving)\", \"2\": \"Arg1 (place, person, or thing left)\", \"3\": \"Arg2 (attribute of arg1)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (entity leaving)\": \"man with mustache\", \"Arg1 (place, person, or thing left)\": \"office\", \"Arg2 (attribute of arg1)\": \"by foot\", \"ArgM (location)\": \"middle of the room\"}}'}]},\n",
       " {'id': 'v_OHNZUmdqdv8_seg_70_80_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_OHNZUmdqdv8_seg_70_80.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"woman in black dress\", \"Arg2 (hearer)\": \"man in blue shirt\", \"ArgM (manner)\": \"standing in a doorway\", \"Scene of the Event\": \"office\"}}'}]},\n",
       " {'id': 'v_OHNZUmdqdv8_seg_70_80_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_OHNZUmdqdv8_seg_70_80.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"react (give a response, reaction)\", \"roles\": {\"1\": \"Arg0 (reactor)\", \"2\": \"Arg1 (reacted-to)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (reactor)\": \"man in blue shirt\", \"Arg1 (reacted-to)\": \"woman in black dress\", \"ArgM (manner)\": \"getting up and starting to move\", \"Scene of the Event\": \"office\"}}'}]},\n",
       " {'id': 'v_wYMfDxQdnUc_seg_5_15_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_wYMfDxQdnUc_seg_5_15.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"roll (move in circular fashion)\", \"roles\": {\"1\": \"Arg0 (roller)\", \"2\": \"Arg1 (thing rolled or rolling)\", \"3\": \"ArgM (direction)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (roller)\": \"man with long hair\", \"Arg1 (thing rolled or rolling)\": \"chair\", \"ArgM (direction)\": \"backwards\", \"Scene of the Event\": \"bedroom\"}}'}]},\n",
       " {'id': 'v_wYMfDxQdnUc_seg_5_15_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_wYMfDxQdnUc_seg_5_15.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pour (move liquids)\", \"roles\": {\"1\": \"Arg0 (agent, pourer)\", \"2\": \"Arg1 (liquid)\", \"3\": \"Arg2 (source)\", \"4\": \"Arg3 (destination)\", \"5\": \"ArgM (direction)\", \"6\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (agent, pourer)\": \"blonde woman\", \"Arg1 (liquid)\": \"alcohol\", \"Arg2 (source)\": \"bottle\", \"Arg3 (destination)\": \"cup\", \"ArgM (direction)\": \"-\", \"Scene of the Event\": \"bedroom\"}}'}]},\n",
       " {'id': 'v_wYMfDxQdnUc_seg_5_15_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_wYMfDxQdnUc_seg_5_15.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"chug (drink rapidly)\", \"roles\": {\"1\": \"Arg0 (drinker)\", \"2\": \"Arg1 (beverage)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (drinker)\": \"woman in green\", \"Arg1 (beverage)\": \"alcohol\", \"Scene of the Event\": \"bedroom\"}}'}]},\n",
       " {'id': 'v_wYMfDxQdnUc_seg_5_15_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_wYMfDxQdnUc_seg_5_15.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"drink (ingest liquids)\", \"roles\": {\"1\": \"Arg0 (drinker)\", \"2\": \"Arg1 (liquid)\", \"3\": \"Arg2 (source of liquid)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (drinker)\": \"woman in green\", \"Arg1 (liquid)\": \"soda\", \"Arg2 (source of liquid)\": \"can\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"bedroom\"}}'}]},\n",
       " {'id': 'v_wYMfDxQdnUc_seg_5_15_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_wYMfDxQdnUc_seg_5_15.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"drink (ingest liquids)\", \"roles\": {\"1\": \"Arg0 (drinker)\", \"2\": \"Arg1 (liquid)\", \"3\": \"Arg2 (source of liquid)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (drinker)\": \"man with long hair\", \"Arg1 (liquid)\": \"soda\", \"Arg2 (source of liquid)\": \"can\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"bedroom\"}}'}]},\n",
       " {'id': 'v__g-f7cZGqJ0_seg_0_10_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__g-f7cZGqJ0_seg_0_10.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shout (yell, or announce loudly)\", \"roles\": {\"1\": \"Arg0 (shouter)\", \"2\": \"Arg2 (listener)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shouter)\": \"the man in the black suit\", \"Arg2 (listener)\": \"the man at the door\", \"Scene of the Event\": \"on the front porch\"}}'}]},\n",
       " {'id': 'v__g-f7cZGqJ0_seg_0_10_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__g-f7cZGqJ0_seg_0_10.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"enter (enter, go in)\", \"roles\": {\"1\": \"Arg0 (entity entering)\", \"2\": \"Arg1 (place or thing entered)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (entity entering)\": \"the man in the blue jacket\", \"Arg1 (place or thing entered)\": \"the door\", \"ArgM (manner)\": \"quickly\", \"Scene of the Event\": \"inside a house\"}}'}]},\n",
       " {'id': 'v__g-f7cZGqJ0_seg_0_10_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__g-f7cZGqJ0_seg_0_10.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shout (yell, or announce loudly)\", \"roles\": {\"1\": \"Arg0 (shouter)\", \"2\": \"Arg2 (listener)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shouter)\": \"the man in the black suit\", \"Arg2 (listener)\": \"the man in the blue jacket\", \"Scene of the Event\": \"inside a house\"}}'}]},\n",
       " {'id': 'v__g-f7cZGqJ0_seg_0_10_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__g-f7cZGqJ0_seg_0_10.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"respond (give an answer, reply)\", \"roles\": {\"1\": \"Arg0 (replier)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (replier)\": \"the man in the blue jacket\", \"Scene of the Event\": \"inside a house\"}}'}]},\n",
       " {'id': 'v__g-f7cZGqJ0_seg_0_10_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__g-f7cZGqJ0_seg_0_10.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shout (yell, or announce loudly)\", \"roles\": {\"1\": \"Arg0 (shouter)\", \"2\": \"Arg2 (listener)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (shouter)\": \"the man in the blue jacket\", \"Arg2 (listener)\": \"the man in the black suit\", \"Scene of the Event\": \"inside a house\"}}'}]},\n",
       " {'id': 'v_zXF0zcwPGuI_seg_100_110_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_zXF0zcwPGuI_seg_100_110.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"kiss (smooch)\", \"roles\": {\"1\": \"Arg0 (kisser)\", \"2\": \"Arg1 (kissed)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (kisser)\": \"woman in a blue apron\", \"Arg1 (kissed)\": \"man in a tan suit\", \"ArgM (location)\": \"in the kitchen\", \"ArgM (manner)\": \"on the cheek\"}}'}]},\n",
       " {'id': 'v_zXF0zcwPGuI_seg_100_110_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_zXF0zcwPGuI_seg_100_110.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"man in a tan suit\", \"Arg2 (hearer)\": \"woman in a blue apron\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"in the kitchen\"}}'}]},\n",
       " {'id': 'v_zXF0zcwPGuI_seg_100_110_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_zXF0zcwPGuI_seg_100_110.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"approach (move towards)\", \"roles\": {\"1\": \"Arg1 (entity in motion)\", \"2\": \"Arg2 (destination)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (entity in motion)\": \"man in a tan suit\", \"Arg2 (destination)\": \"table\", \"ArgM (direction)\": \"forward\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"in the kitchen\"}}'}]},\n",
       " {'id': 'v_zXF0zcwPGuI_seg_100_110_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_zXF0zcwPGuI_seg_100_110.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pull ((try to) cause motion)\", \"roles\": {\"1\": \"Arg0 (puller)\", \"2\": \"Arg1 (thing pulled)\", \"3\": \"Arg2 (DIR or attribute of arg1)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (puller)\": \"man in a tan suit\", \"Arg1 (thing pulled)\": \"chair\", \"Arg2 (DIR or attribute of arg1)\": \"out from the table\", \"ArgM (location)\": \"in the kitchen\"}}'}]},\n",
       " {'id': 'v_zXF0zcwPGuI_seg_100_110_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_zXF0zcwPGuI_seg_100_110.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sit (be in a position)\", \"roles\": {\"1\": \"Arg1 (thing sitting)\", \"2\": \"Arg2 (location or position)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing sitting)\": \"man in a tan suit\", \"Arg2 (location or position)\": \"woman in a blue apron\", \"ArgM (manner)\": \"casually\"}}'}]},\n",
       " {'id': 'v_tIj1luuOfO4_seg_50_60_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_tIj1luuOfO4_seg_50_60.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"run (walk quickly, a course or contest)\", \"roles\": {\"1\": \"Arg0 (runner)\", \"2\": \"Arg1 (course, race, distance)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (goal)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (runner)\": \"man with short hair\", \"Arg1 (course, race, distance)\": \"runs alongside truck\", \"ArgM (direction)\": \"down a long road\", \"ArgM (goal)\": \"trying to get the truck to stop\", \"Scene of the Event\": \"on a road in a desert\"}}'}]},\n",
       " {'id': 'v_tIj1luuOfO4_seg_50_60_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_tIj1luuOfO4_seg_50_60.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"yell (to cry out loudly)\", \"roles\": {\"1\": \"Arg0 (Yeller)\", \"2\": \"Arg2 (Hearer)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (Yeller)\": \"man with scraggly hair\", \"Arg2 (Hearer)\": \"yells at man with short hair\", \"Scene of the Event\": \"in the truck\"}}'}]},\n",
       " {'id': 'v_tIj1luuOfO4_seg_50_60_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_tIj1luuOfO4_seg_50_60.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"jump (physically or metaphorically leap)\", \"roles\": {\"1\": \"Arg0 (jumper)\", \"2\": \"ArgM (direction)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (jumper)\": \"man with short hair\", \"ArgM (direction)\": \"jumps up onto the truck\", \"Scene of the Event\": \"on a road in a desert\"}}'}]},\n",
       " {'id': 'v_tIj1luuOfO4_seg_50_60_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_tIj1luuOfO4_seg_50_60.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"man with short hair\", \"Arg2 (hearer)\": \"speaks to man with scraggly hair\", \"ArgM (location)\": \"from the side of the truck\", \"ArgM (manner)\": \"frantically\"}}'}]},\n",
       " {'id': 'v_tIj1luuOfO4_seg_50_60_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_tIj1luuOfO4_seg_50_60.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"man with scraggly hair\", \"Arg2 (hearer)\": \"speaks to man with short hair\", \"ArgM (location)\": \"through the side window\", \"ArgM (manner)\": \"with a look of surprise\"}}'}]},\n",
       " {'id': 'v__TRUBZVUg8k_seg_20_30_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__TRUBZVUg8k_seg_20_30.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stop (stop)\", \"roles\": {\"1\": \"Arg0 (Agent)\", \"2\": \"Arg1 (Theme (action or object being stopped))\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (Agent)\": \"man\", \"Arg1 (Theme (action or object being stopped))\": \"green car\", \"ArgM (location)\": \"middle of street\"}}'}]},\n",
       " {'id': 'v__TRUBZVUg8k_seg_20_30_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__TRUBZVUg8k_seg_20_30.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"drive (drive a vehicle)\", \"roles\": {\"1\": \"Arg0 (driver)\", \"2\": \"Arg1 (vehicle or path)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (driver)\": \"man\", \"Arg1 (vehicle or path)\": \"mack truck\", \"ArgM (direction)\": \"down the street\", \"ArgM (manner)\": \"towards green car\", \"Scene of the Event\": \"in the city\"}}'}]},\n",
       " {'id': 'v__TRUBZVUg8k_seg_20_30_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__TRUBZVUg8k_seg_20_30.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"panic (be all afluster)\", \"roles\": {\"1\": \"Arg1 (panicker)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (panicker)\": \"men in car\", \"Scene of the Event\": \"middle of street\"}}'}]},\n",
       " {'id': 'v__TRUBZVUg8k_seg_20_30_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__TRUBZVUg8k_seg_20_30.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"men in car\", \"Arg1 (thing looked at or for or on)\": \"mack truck\", \"ArgM (direction)\": \"to their left\", \"ArgM (manner)\": \"breathing hard with their hands up\", \"Scene of the Event\": \"inside green car\"}}'}]},\n",
       " {'id': 'v__TRUBZVUg8k_seg_20_30_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v__TRUBZVUg8k_seg_20_30.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shock (surprise)\", \"roles\": {\"1\": \"Arg1 (person surprised)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (person surprised)\": \"man with dark hair\", \"Scene of the Event\": \"inside green car\"}}'}]},\n",
       " {'id': 'v_Qh5tZM4ybhI_seg_5_15_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Qh5tZM4ybhI_seg_5_15.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stand ((cause to) be in a vertical position)\", \"roles\": {\"1\": \"Arg1 (thing standing)\", \"2\": \"Arg2 (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing standing)\": \"man with beard\", \"Arg2 (location)\": \"middle of a room\", \"ArgM (manner)\": \"looking upset\"}}'}]},\n",
       " {'id': 'v_Qh5tZM4ybhI_seg_5_15_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Qh5tZM4ybhI_seg_5_15.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"drink (ingest liquids)\", \"roles\": {\"1\": \"Arg0 (drinker)\", \"2\": \"Arg1 (liquid)\", \"3\": \"Arg2 (source of liquid)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (drinker)\": \"man in suit\", \"Arg1 (liquid)\": \"beer\", \"Arg2 (source of liquid)\": \"bottle\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"hotel\"}}'}]},\n",
       " {'id': 'v_Qh5tZM4ybhI_seg_5_15_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Qh5tZM4ybhI_seg_5_15.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"set (put, place)\", \"roles\": {\"1\": \"Arg0 (agent, setter)\", \"2\": \"Arg1 (thing set)\", \"3\": \"Arg2 (location or position)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (agent, setter)\": \"blonde man\", \"Arg1 (thing set)\": \"his arm\", \"Arg2 (location or position)\": \"around man in suit\", \"ArgM (manner)\": \"in a friendly way\"}}'}]},\n",
       " {'id': 'v_Qh5tZM4ybhI_seg_5_15_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Qh5tZM4ybhI_seg_5_15.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"react (give a response, reaction)\", \"roles\": {\"1\": \"Arg0 (reactor)\", \"2\": \"Arg1 (reacted-to)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (reactor)\": \"man in suit\", \"Arg1 (reacted-to)\": \"blonde man\", \"ArgM (manner)\": \"smiling\", \"Scene of the Event\": \"hotel room\"}}'}]},\n",
       " {'id': 'v_Qh5tZM4ybhI_seg_5_15_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Qh5tZM4ybhI_seg_5_15.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"feed (cause to eat)\", \"roles\": {\"1\": \"Arg0 (causal agent)\", \"2\": \"Arg2 (eater)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causal agent)\": \"blonde man\", \"Arg2 (eater)\": \"man in suit\", \"Scene of the Event\": \"hotel room\"}}'}]},\n",
       " {'id': 'v_TktPJgdwMtQ_seg_115_125_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_TktPJgdwMtQ_seg_115_125.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man with blonde hair\", \"Arg1 (thing looked at or for or on)\": \"man in jean jacket\", \"ArgM (direction)\": \"face to face\", \"ArgM (manner)\": \"with an angry look\", \"Scene of the Event\": \"inside an office\"}}'}]},\n",
       " {'id': 'v_TktPJgdwMtQ_seg_115_125_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_TktPJgdwMtQ_seg_115_125.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"frighten (frighten)\", \"roles\": {\"1\": \"Arg1 (frightened entity)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (frightened entity)\": \"man in jean jacket\", \"Scene of the Event\": \"inside an office\"}}'}]},\n",
       " {'id': 'v_TktPJgdwMtQ_seg_115_125_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_TktPJgdwMtQ_seg_115_125.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man with blonde hair\", \"ArgM (direction)\": \"toward desk\", \"ArgM (manner)\": \"staring down the other man\", \"Scene of the Event\": \"inside an office\"}}'}]},\n",
       " {'id': 'v_TktPJgdwMtQ_seg_115_125_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_TktPJgdwMtQ_seg_115_125.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"relax ((cause to) become less tight)\", \"roles\": {\"1\": \"Arg1 (thing relaxing)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (thing relaxing)\": \"man in jean jacket\", \"Scene of the Event\": \"inside an office\"}}'}]},\n",
       " {'id': 'v_TktPJgdwMtQ_seg_115_125_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_TktPJgdwMtQ_seg_115_125.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"grab (to capture, obtain)\", \"roles\": {\"1\": \"Arg0 (grabber)\", \"2\": \"Arg1 (entity grabbed)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (grabber)\": \"man with blonde hair\", \"Arg1 (entity grabbed)\": \"gun\", \"ArgM (location)\": \"out of desk drawer\", \"ArgM (manner)\": \"lifting it up staring at man\"}}'}]},\n",
       " {'id': 'v_St16P31BURU_seg_5_15_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_St16P31BURU_seg_5_15.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"display (to present, exhibit)\", \"roles\": {\"1\": \"Arg0 (displayer, agent)\", \"2\": \"Arg1 (entity displayed)\", \"3\": \"Arg2 (location)\"}, \"nouns\": {\"Arg0 (displayer, agent)\": \"still shot in black and white\", \"Arg1 (entity displayed)\": \"filmmaker credits\", \"Arg2 (location)\": \"by a Job Printing business\"}}'}]},\n",
       " {'id': 'v_St16P31BURU_seg_5_15_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_St16P31BURU_seg_5_15.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"salute (to greet or honor )\", \"roles\": {\"1\": \"Arg0 (saluter)\", \"2\": \"Arg1 (entity saluted)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (saluter)\": \"men riding down the street on horses\", \"Arg1 (entity saluted)\": \"two men in brown uniforms and hats standing at attention across the way\", \"Scene of the Event\": \"frontier town main street\"}}'}]},\n",
       " {'id': 'v_St16P31BURU_seg_5_15_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_St16P31BURU_seg_5_15.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"observe (look at, mark)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"two men in brown uniforms and hats standing at attention across the way\", \"Arg1 (thing looked at)\": \"men riding down the street on horses\", \"Scene of the Event\": \"frontier town main street\"}}'}]},\n",
       " {'id': 'v_St16P31BURU_seg_5_15_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_St16P31BURU_seg_5_15.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"ride (as a horse)\", \"roles\": {\"1\": \"Arg0 (rider)\", \"2\": \"Arg1 (steed)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (rider)\": \"3 men\", \"Arg1 (steed)\": \"3 horses\", \"ArgM (direction)\": \"down the street\", \"ArgM (manner)\": \"leisurely\", \"Scene of the Event\": \"frontier town main street\"}}'}]},\n",
       " {'id': 'v_St16P31BURU_seg_5_15_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_St16P31BURU_seg_5_15.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"display (to present, exhibit)\", \"roles\": {\"1\": \"Arg0 (displayer, agent)\", \"2\": \"Arg1 (entity displayed)\", \"3\": \"Arg2 (location)\"}, \"nouns\": {\"Arg0 (displayer, agent)\": \"still shot in black and white\", \"Arg1 (entity displayed)\": \"filmmaker credits\", \"Arg2 (location)\": \"frontier town main street\"}}'}]},\n",
       " {'id': 'v_Aok-54MlYFk_seg_0_10_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Aok-54MlYFk_seg_0_10.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"the man holding the can\", \"ArgM (direction)\": \"forward\", \"ArgM (manner)\": \"strolling\", \"Scene of the Event\": \"in the house\"}}'}]},\n",
       " {'id': 'v_Aok-54MlYFk_seg_0_10_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Aok-54MlYFk_seg_0_10.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"the man holding the can\", \"ArgM (direction)\": \"forward\", \"ArgM (manner)\": \"strolling\", \"Scene of the Event\": \"in the house\"}}'}]},\n",
       " {'id': 'v_Aok-54MlYFk_seg_0_10_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Aok-54MlYFk_seg_0_10.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"drink (ingest liquids)\", \"roles\": {\"1\": \"Arg0 (drinker)\", \"2\": \"Arg1 (liquid)\", \"3\": \"Arg2 (source of liquid)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (drinker)\": \"the man holding the can\", \"Arg1 (liquid)\": \"drink\", \"Arg2 (source of liquid)\": \"the can\", \"ArgM (manner)\": \"easily\", \"Scene of the Event\": \"in the house\"}}'}]},\n",
       " {'id': 'v_Aok-54MlYFk_seg_0_10_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Aok-54MlYFk_seg_0_10.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"the man holding the can\", \"ArgM (direction)\": \"forward\", \"ArgM (manner)\": \"strolling\", \"Scene of the Event\": \"in the house\"}}'}]},\n",
       " {'id': 'v_Aok-54MlYFk_seg_0_10_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_Aok-54MlYFk_seg_0_10.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"the man holding the can\", \"Arg2 (hearer)\": \"the man wearing the blue shirt\", \"ArgM (location)\": \"in the house\", \"ArgM (manner)\": \"softly\"}}'}]},\n",
       " {'id': 'v_LwbFwVf8yoE_seg_30_40_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LwbFwVf8yoE_seg_30_40.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"grab (to capture, obtain)\", \"roles\": {\"1\": \"Arg0 (grabber)\", \"2\": \"Arg1 (entity grabbed)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (grabber)\": \"man in cowboy hat\", \"Arg1 (entity grabbed)\": \"rifle\", \"ArgM (location)\": \"saddle bag\", \"ArgM (manner)\": \"sitting on a horse unsettled\"}}'}]},\n",
       " {'id': 'v_LwbFwVf8yoE_seg_30_40_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LwbFwVf8yoE_seg_30_40.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"unsettle (cause anxiety)\", \"roles\": {\"1\": \"Arg1 (anxious entity)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (anxious entity)\": \"horses\", \"Scene of the Event\": \"desert\"}}'}]},\n",
       " {'id': 'v_LwbFwVf8yoE_seg_30_40_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LwbFwVf8yoE_seg_30_40.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"unnerve (cause to be nervous)\", \"roles\": {\"1\": \"Arg0 (cause)\", \"2\": \"Arg1 (patient, entity become nervous)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (cause)\": \"unknown\", \"Arg1 (patient, entity become nervous)\": \"horses\", \"Scene of the Event\": \"desert\"}}'}]},\n",
       " {'id': 'v_LwbFwVf8yoE_seg_30_40_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LwbFwVf8yoE_seg_30_40.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"rise (go up)\", \"roles\": {\"1\": \"Arg1 (Logical subject, patient, thing rising)\", \"2\": \"Arg3 (start point)\", \"3\": \"Arg4 (end point)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (Logical subject, patient, thing rising)\": \"dirt\", \"Arg3 (start point)\": \"ground\", \"Arg4 (end point)\": \"in the air\", \"ArgM (manner)\": \"across the ground\", \"Scene of the Event\": \"desert\"}}'}]},\n",
       " {'id': 'v_LwbFwVf8yoE_seg_30_40_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LwbFwVf8yoE_seg_30_40.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"fall (move downward)\", \"roles\": {\"1\": \"Arg1 (Logical subject, patient, thing falling)\", \"2\": \"Arg3 (start point)\", \"3\": \"Arg4 (end point, end state of arg1)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (manner)\", \"6\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (Logical subject, patient, thing falling)\": \"horse\", \"Arg3 (start point)\": \"standing\", \"Arg4 (end point, end state of arg1)\": \"on its side\", \"ArgM (direction)\": \"down\", \"ArgM (manner)\": \"losing balance with the ground caving in\", \"Scene of the Event\": \"desert floor\"}}'}]},\n",
       " {'id': 'v_LwbFwVf8yoE_seg_110_120_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LwbFwVf8yoE_seg_110_120.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"collapse (fall down)\", \"roles\": {\"1\": \"Arg1 (thing collapsing)\", \"2\": \"ArgM (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing collapsing)\": \"the fence post\", \"ArgM (location)\": \"on the ground\", \"ArgM (manner)\": \"quickly\"}}'}]},\n",
       " {'id': 'v_LwbFwVf8yoE_seg_110_120_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LwbFwVf8yoE_seg_110_120.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"retreat (run away!)\", \"roles\": {\"1\": \"Arg0 (retreater)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (retreater)\": \"the two men\", \"Scene of the Event\": \"in the desert\"}}'}]},\n",
       " {'id': 'v_LwbFwVf8yoE_seg_110_120_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LwbFwVf8yoE_seg_110_120.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"retreat (run away!)\", \"roles\": {\"1\": \"Arg0 (retreater)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (retreater)\": \"the two men\", \"Scene of the Event\": \"in the desert\"}}'}]},\n",
       " {'id': 'v_LwbFwVf8yoE_seg_110_120_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LwbFwVf8yoE_seg_110_120.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"retreat (run away!)\", \"roles\": {\"1\": \"Arg0 (retreater)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (retreater)\": \"the two men\", \"Scene of the Event\": \"in the desert\"}}'}]},\n",
       " {'id': 'v_LwbFwVf8yoE_seg_110_120_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_LwbFwVf8yoE_seg_110_120.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"retreat (run away!)\", \"roles\": {\"1\": \"Arg0 (retreater)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (retreater)\": \"the two men\", \"Scene of the Event\": \"in the desert\"}}'}]},\n",
       " {'id': 'v_54LTsr8IAU4_seg_75_85_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_54LTsr8IAU4_seg_75_85.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man in blue jacket\", \"ArgM (direction)\": \"away from crowd\", \"ArgM (manner)\": \"swiftly\", \"Scene of the Event\": \"pasture\"}}'}]},\n",
       " {'id': 'v_54LTsr8IAU4_seg_75_85_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_54LTsr8IAU4_seg_75_85.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man in blue jacket\", \"ArgM (direction)\": \"away from crowd\", \"ArgM (manner)\": \"swiftly\", \"Scene of the Event\": \"pasture\"}}'}]},\n",
       " {'id': 'v_54LTsr8IAU4_seg_75_85_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_54LTsr8IAU4_seg_75_85.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man in blue jacket\", \"ArgM (direction)\": \"away from crowd\", \"ArgM (manner)\": \"swiftly\", \"Scene of the Event\": \"pasture\"}}'}]},\n",
       " {'id': 'v_54LTsr8IAU4_seg_75_85_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_54LTsr8IAU4_seg_75_85.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man in blue jacket\", \"ArgM (direction)\": \"away from crowd\", \"ArgM (manner)\": \"swiftly\", \"Scene of the Event\": \"pasture\"}}'}]},\n",
       " {'id': 'v_54LTsr8IAU4_seg_75_85_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_54LTsr8IAU4_seg_75_85.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"man in blue jacket\", \"ArgM (direction)\": \"away from crowd\", \"ArgM (manner)\": \"swiftly\", \"Scene of the Event\": \"pasture\"}}'}]},\n",
       " {'id': 'v_MXcA1Ow7Lzw_seg_35_45_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MXcA1Ow7Lzw_seg_35_45.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"woman in striped shirt\", \"Arg1 (thing looked at or for or on)\": \"something off screen\", \"ArgM (direction)\": \"through a pair of glasses\", \"ArgM (manner)\": \"while standing\", \"Scene of the Event\": \"in a room\"}}'}]},\n",
       " {'id': 'v_MXcA1Ow7Lzw_seg_35_45_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MXcA1Ow7Lzw_seg_35_45.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"rock (tremble)\", \"roles\": {\"1\": \"Arg0 (causer of trembling motion)\", \"2\": \"Arg1 (thing trembling)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of trembling motion)\": \"something off screen\", \"Arg1 (thing trembling)\": \"a rocking chair\", \"Scene of the Event\": \"in a room\"}}'}]},\n",
       " {'id': 'v_MXcA1Ow7Lzw_seg_35_45_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MXcA1Ow7Lzw_seg_35_45.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"rock (tremble)\", \"roles\": {\"1\": \"Arg0 (causer of trembling motion)\", \"2\": \"Arg1 (thing trembling)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of trembling motion)\": \"something off screen\", \"Arg1 (thing trembling)\": \"a rocking chair\", \"Scene of the Event\": \"in a room\"}}'}]},\n",
       " {'id': 'v_MXcA1Ow7Lzw_seg_35_45_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MXcA1Ow7Lzw_seg_35_45.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"push ((try to) cause motion)\", \"roles\": {\"1\": \"Arg0 (pusher)\", \"2\": \"Arg1 (thing pushed)\", \"3\": \"Arg2 (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (pusher)\": \"woman in striped shirt\", \"Arg1 (thing pushed)\": \"a pair of glasses\", \"Arg2 (direction)\": \"up away from her eyes\", \"ArgM (manner)\": \"with both hands\", \"Scene of the Event\": \"in a room\"}}'}]},\n",
       " {'id': 'v_MXcA1Ow7Lzw_seg_35_45_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_MXcA1Ow7Lzw_seg_35_45.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"terrify (scare very badly)\", \"roles\": {\"1\": \"Arg1 (terrified entity)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (terrified entity)\": \"woman in striped shirt\", \"Scene of the Event\": \"in a room\"}}'}]},\n",
       " {'id': 'v_DX1p8C_FuxU_seg_95_105_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_DX1p8C_FuxU_seg_95_105.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"sniff (use the nose, smell)\", \"roles\": {\"1\": \"Arg0 (sniffer)\", \"2\": \"Arg1 (thing sniffed)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (sniffer)\": \"young man with dark hair and dark pullover shirt\", \"Arg1 (thing sniffed)\": \"tip of a gun barrel\", \"Scene of the Event\": \"dingy basement\"}}'}]},\n",
       " {'id': 'v_DX1p8C_FuxU_seg_95_105_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_DX1p8C_FuxU_seg_95_105.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hide (conceal)\", \"roles\": {\"1\": \"Arg0 (hider)\", \"2\": \"Arg1 (thing hidden)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (hider)\": \"young man with dark hair and dark pullover shirt\", \"Arg1 (thing hidden)\": \"gun\", \"ArgM (location)\": \"dingy basement\"}}'}]},\n",
       " {'id': 'v_DX1p8C_FuxU_seg_95_105_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_DX1p8C_FuxU_seg_95_105.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"set (put, place)\", \"roles\": {\"1\": \"Arg0 (agent, setter)\", \"2\": \"Arg1 (thing set)\", \"3\": \"Arg2 (location or position)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (agent, setter)\": \"middle-aged woman with brown hair behind the seated young man\", \"Arg1 (thing set)\": \"unlabeled aluminum can\", \"Arg2 (location or position)\": \"on an open shelf\", \"ArgM (manner)\": \"calmly\"}}'}]},\n",
       " {'id': 'v_DX1p8C_FuxU_seg_95_105_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_DX1p8C_FuxU_seg_95_105.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"reach (stretch, grasp)\", \"roles\": {\"1\": \"Arg0 (reacher)\", \"2\": \"Arg1 (body part)\", \"3\": \"Arg2 (goal)\", \"4\": \"ArgM (direction)\", \"5\": \"ArgM (purpose)\", \"6\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (reacher)\": \"middle-aged woman with brown hair behind the seated young man\", \"Arg1 (body part)\": \"hands\", \"Arg2 (goal)\": \"in order to\", \"ArgM (direction)\": \"down\", \"ArgM (purpose)\": \"to pick something up\", \"Scene of the Event\": \"dingy basement\"}}'}]},\n",
       " {'id': 'v_DX1p8C_FuxU_seg_95_105_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_DX1p8C_FuxU_seg_95_105.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"notice (become aware of)\", \"roles\": {\"1\": \"Arg0 (noticer)\", \"2\": \"Arg1 (noticed)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (noticer)\": \"middle-aged woman with brown hair behind the seated young man\", \"Arg1 (noticed)\": \"bulletin board\", \"ArgM (location)\": \"dingy basement\"}}'}]},\n",
       " {'id': 'v_DX1p8C_FuxU_seg_110_120_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_DX1p8C_FuxU_seg_110_120.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"a boy in a dark t shirt\", \"Arg1 (looked at)\": \"oblivion\", \"ArgM (direction)\": \"ahead\", \"ArgM (manner)\": \"blankly\", \"Scene of the Event\": \"in a room\"}}'}]},\n",
       " {'id': 'v_DX1p8C_FuxU_seg_110_120_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_DX1p8C_FuxU_seg_110_120.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"read (read)\", \"roles\": {\"1\": \"Arg0 (reader)\", \"2\": \"Arg1 (book)\", \"3\": \"Arg3 (text, content)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (reader)\": \"woman in a black coat\", \"Arg1 (book)\": \"posters on a notice board\", \"Arg3 (text, content)\": \"unseen\", \"ArgM (location)\": \"on the wall\"}}'}]},\n",
       " {'id': 'v_DX1p8C_FuxU_seg_110_120_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_DX1p8C_FuxU_seg_110_120.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"turn (rotation)\", \"roles\": {\"1\": \"Arg0 (turner)\", \"2\": \"Arg1 (thing turning)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (purpose)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (turner)\": \"woman in a black coat\", \"Arg1 (thing turning)\": \"herself\", \"ArgM (direction)\": \"side\", \"ArgM (purpose)\": \"to face the boy in a dark t shirt\", \"Scene of the Event\": \"in a room\"}}'}]},\n",
       " {'id': 'v_DX1p8C_FuxU_seg_110_120_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_DX1p8C_FuxU_seg_110_120.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"rise (go up)\", \"roles\": {\"1\": \"Arg1 (Logical subject, patient, thing rising)\", \"2\": \"Arg3 (start point)\", \"3\": \"Arg4 (end point)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg1 (Logical subject, patient, thing rising)\": \"woman in a black coat\", \"Arg3 (start point)\": \"from bending\", \"Arg4 (end point)\": \"to standing\", \"ArgM (manner)\": \"slowly\", \"Scene of the Event\": \"in a room\"}}'}]},\n",
       " {'id': 'v_DX1p8C_FuxU_seg_110_120_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_DX1p8C_FuxU_seg_110_120.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"glance (look at briefly)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked-at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"woman in a black coat\", \"Arg1 (looked-at)\": \"a boy in a dark t shirt\", \"ArgM (direction)\": \"over her shoulders\", \"ArgM (manner)\": \"as if shocked by something\", \"Scene of the Event\": \"in a room\"}}'}]},\n",
       " {'id': 'v_25UjaIMN-rY_seg_90_100_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_25UjaIMN-rY_seg_90_100.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"command (impelled action)\", \"roles\": {\"1\": \"Arg0 (commander)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (commander)\": \"the man with the beard\", \"Scene of the Event\": \"by a campfire\"}}'}]},\n",
       " {'id': 'v_25UjaIMN-rY_seg_90_100_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_25UjaIMN-rY_seg_90_100.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"ask (ask a question)\", \"roles\": {\"1\": \"Arg0 (asker)\", \"2\": \"Arg1 (question)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (asker)\": \"the man with the beard\", \"Arg1 (question)\": \"If he brought the boy there\", \"Scene of the Event\": \"by a campfire\"}}'}]},\n",
       " {'id': 'v_25UjaIMN-rY_seg_90_100_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_25UjaIMN-rY_seg_90_100.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"talk (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (talker)\": \"the man with the beard\", \"Arg2 (hearer)\": \"the boy with the pistol\", \"ArgM (location)\": \"by a campfire\", \"ArgM (manner)\": \"angrily\"}}'}]},\n",
       " {'id': 'v_25UjaIMN-rY_seg_90_100_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_25UjaIMN-rY_seg_90_100.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"speak (speak)\", \"roles\": {\"1\": \"Arg0 (talker)\", \"2\": \"Arg2 (hearer)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (talker)\": \"the man with the beard\", \"Arg2 (hearer)\": \"the boy with the pistol\", \"ArgM (manner)\": \"angrily\", \"Scene of the Event\": \"by a campfire\"}}'}]},\n",
       " {'id': 'v_25UjaIMN-rY_seg_90_100_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_25UjaIMN-rY_seg_90_100.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"respond (give an answer, reply)\", \"roles\": {\"1\": \"Arg0 (replier)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (replier)\": \"the boy with the pistol\", \"Scene of the Event\": \"by a campfire\"}}'}]},\n",
       " {'id': 'v_aEpa21af2j4_seg_15_25_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_aEpa21af2j4_seg_15_25.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"ride (as a horse)\", \"roles\": {\"1\": \"Arg0 (rider)\", \"2\": \"Arg1 (steed)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (rider)\": \"man with hat\", \"Arg1 (steed)\": \"black horse\", \"ArgM (direction)\": \"forward\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"forest\"}}'}]},\n",
       " {'id': 'v_aEpa21af2j4_seg_15_25_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_aEpa21af2j4_seg_15_25.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"ride (as a horse)\", \"roles\": {\"1\": \"Arg0 (rider)\", \"2\": \"Arg1 (steed)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (rider)\": \"man with hat\", \"Arg1 (steed)\": \"black horse\", \"ArgM (direction)\": \"forward\", \"ArgM (manner)\": \"casually\", \"Scene of the Event\": \"forest\"}}'}]},\n",
       " {'id': 'v_aEpa21af2j4_seg_15_25_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_aEpa21af2j4_seg_15_25.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man  with hat\", \"Arg1 (looked at)\": \"trees\", \"ArgM (direction)\": \"sideways\", \"ArgM (manner)\": \"curiously\", \"Scene of the Event\": \"forest\"}}'}]},\n",
       " {'id': 'v_aEpa21af2j4_seg_15_25_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_aEpa21af2j4_seg_15_25.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man with hat\", \"Arg1 (looked at)\": \"trees\", \"ArgM (direction)\": \"sideways\", \"ArgM (manner)\": \"curiously\", \"Scene of the Event\": \"forest\"}}'}]},\n",
       " {'id': 'v_aEpa21af2j4_seg_15_25_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_aEpa21af2j4_seg_15_25.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stare (look intently)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (looked at)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"man with hat\", \"Arg1 (looked at)\": \"trees\", \"ArgM (direction)\": \"sideways\", \"ArgM (manner)\": \"curiously\", \"Scene of the Event\": \"forest\"}}'}]},\n",
       " {'id': 'v_0kM0c3Q-hHQ_seg_40_50_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0kM0c3Q-hHQ_seg_40_50.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"question (ask a question, express doubts)\", \"roles\": {\"1\": \"Arg0 (asker)\", \"2\": \"Arg2 (entity asked, hearer)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (asker)\": \"girl with long hair\", \"Arg2 (entity asked, hearer)\": \"man with dark hair\", \"ArgM (location)\": \"living room\"}}'}]},\n",
       " {'id': 'v_0kM0c3Q-hHQ_seg_40_50_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0kM0c3Q-hHQ_seg_40_50.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"answer (give an answer, reply)\", \"roles\": {\"1\": \"Arg0 (replier)\", \"2\": \"Arg1 (in response to)\", \"3\": \"ArgM (location)\", \"4\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (replier)\": \"man with dark hair\", \"Arg1 (in response to)\": \"girl with long hair\", \"ArgM (location)\": \"living room\", \"ArgM (manner)\": \"sitting in a chair\"}}'}]},\n",
       " {'id': 'v_0kM0c3Q-hHQ_seg_40_50_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0kM0c3Q-hHQ_seg_40_50.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"stand ((cause to) be in a vertical position)\", \"roles\": {\"1\": \"Arg1 (thing standing)\", \"2\": \"Arg2 (location)\", \"3\": \"ArgM (manner)\"}, \"nouns\": {\"Arg1 (thing standing)\": \"girl with long hair\", \"Arg2 (location)\": \"next to a table\", \"ArgM (manner)\": \"swaying a little holding a beer\"}}'}]},\n",
       " {'id': 'v_0kM0c3Q-hHQ_seg_40_50_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0kM0c3Q-hHQ_seg_40_50.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"turn (rotation)\", \"roles\": {\"1\": \"Arg0 (turner)\", \"2\": \"Arg1 (thing turning)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (purpose)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (turner)\": \"girl with long hair\", \"Arg1 (thing turning)\": \"herself\", \"ArgM (direction)\": \"around\", \"ArgM (purpose)\": \"to face other direction\", \"Scene of the Event\": \"living room\"}}'}]},\n",
       " {'id': 'v_0kM0c3Q-hHQ_seg_40_50_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0kM0c3Q-hHQ_seg_40_50.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"shake (tremble)\", \"roles\": {\"1\": \"Arg0 (causer of trembling motion)\", \"2\": \"Arg1 (thing trembling)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (causer of trembling motion)\": \"man with dark hair\", \"Arg1 (thing trembling)\": \"head\", \"ArgM (manner)\": \"side to side in disagreement\", \"Scene of the Event\": \"living room\"}}'}]},\n",
       " {'id': 'v_0kM0c3Q-hHQ_seg_30_40_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0kM0c3Q-hHQ_seg_30_40.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"listen (attend to a sound)\", \"roles\": {\"1\": \"Arg0 (listener)\", \"2\": \"Arg1 (sound or speaker)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (listener)\": \"man in grey shirt\", \"Arg1 (sound or speaker)\": \"woman\", \"ArgM (manner)\": \"looking confused\", \"Scene of the Event\": \"living room\"}}'}]},\n",
       " {'id': 'v_0kM0c3Q-hHQ_seg_30_40_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0kM0c3Q-hHQ_seg_30_40.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"react (give a response, reaction)\", \"roles\": {\"1\": \"Arg0 (reactor)\", \"2\": \"Arg1 (reacted-to)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (reactor)\": \"man in grey shirt\", \"Arg1 (reacted-to)\": \"woman\", \"ArgM (manner)\": \"nodding his head slightly\", \"Scene of the Event\": \"living room\"}}'}]},\n",
       " {'id': 'v_0kM0c3Q-hHQ_seg_30_40_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0kM0c3Q-hHQ_seg_30_40.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"respond (give an answer, reply)\", \"roles\": {\"1\": \"Arg0 (replier)\", \"2\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (replier)\": \"man in grey shirt\", \"Scene of the Event\": \"living room\"}}'}]},\n",
       " {'id': 'v_0kM0c3Q-hHQ_seg_30_40_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0kM0c3Q-hHQ_seg_30_40.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"walk (walk)\", \"roles\": {\"1\": \"Arg0 (walker)\", \"2\": \"ArgM (direction)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (walker)\": \"woman\", \"ArgM (direction)\": \"across the room\", \"ArgM (manner)\": \"looking upset and away from man\", \"Scene of the Event\": \"living room\"}}'}]},\n",
       " {'id': 'v_0kM0c3Q-hHQ_seg_30_40_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_0kM0c3Q-hHQ_seg_30_40.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"look (vision)\", \"roles\": {\"1\": \"Arg0 (looker)\", \"2\": \"Arg1 (thing looked at or for or on)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (looker)\": \"woman\", \"Arg1 (thing looked at or for or on)\": \"the area in front of her\", \"ArgM (direction)\": \"forward\", \"ArgM (manner)\": \"speechless\", \"Scene of the Event\": \"living room\"}}'}]},\n",
       " {'id': 'v_WJlOBTLg4xw_seg_85_95_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WJlOBTLg4xw_seg_85_95.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"hand (give)\", \"roles\": {\"1\": \"Arg0 (giver)\", \"2\": \"Arg1 (thing given)\", \"3\": \"Arg2 (entity given to)\", \"4\": \"ArgM (manner)\", \"5\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (giver)\": \"man in white jacket\", \"Arg1 (thing given)\": \"a shirt\", \"Arg2 (entity given to)\": \"man in white shirt\", \"ArgM (manner)\": \"with one hand\", \"Scene of the Event\": \"in a house\"}}'}]},\n",
       " {'id': 'v_WJlOBTLg4xw_seg_85_95_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WJlOBTLg4xw_seg_85_95.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"rummage (dig for something)\", \"roles\": {\"1\": \"Arg0 (digger, delver)\", \"2\": \"Arg1 (dug/delved into/through)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (digger, delver)\": \"man in white jacket\", \"Arg1 (dug/delved into/through)\": \"a closet\", \"Scene of the Event\": \"in a house\"}}'}]},\n",
       " {'id': 'v_WJlOBTLg4xw_seg_85_95_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WJlOBTLg4xw_seg_85_95.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"rummage (dig for something)\", \"roles\": {\"1\": \"Arg0 (digger, delver)\", \"2\": \"Arg1 (dug/delved into/through)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (digger, delver)\": \"man in white jacket\", \"Arg1 (dug/delved into/through)\": \"a closet\", \"Scene of the Event\": \"in a house\"}}'}]},\n",
       " {'id': 'v_WJlOBTLg4xw_seg_85_95_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WJlOBTLg4xw_seg_85_95.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"pick (pick up: acquire)\", \"roles\": {\"1\": \"Arg0 (agent, entity acquiring something)\", \"2\": \"Arg1 (thing acquired)\", \"3\": \"Arg2 (seller)\", \"4\": \"ArgM (location)\", \"5\": \"ArgM (manner)\"}, \"nouns\": {\"Arg0 (agent, entity acquiring something)\": \"man in white jacket\", \"Arg1 (thing acquired)\": \"black socks\", \"Arg2 (seller)\": \"from a closet\", \"ArgM (location)\": \"in a house\", \"ArgM (manner)\": \"with both hands\"}}'}]},\n",
       " {'id': 'v_WJlOBTLg4xw_seg_85_95_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WJlOBTLg4xw_seg_85_95.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"examine (look at closely)\", \"roles\": {\"1\": \"Arg0 (examiner)\", \"2\": \"Arg1 (thing examined)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (examiner)\": \"man in white jacket\", \"Arg1 (thing examined)\": \"black socks\", \"ArgM (manner)\": \"carefully\", \"Scene of the Event\": \"in a house\"}}'}]},\n",
       " {'id': 'v_WJlOBTLg4xw_seg_60_70_Ev1',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WJlOBTLg4xw_seg_60_70.mp4',\n",
       "  'event': 'Ev1',\n",
       "  'start_secs': 0,\n",
       "  'end_secs': 2,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"check (examine)\", \"roles\": {\"1\": \"Arg0 (checker)\", \"2\": \"Arg1 (thing checked)\", \"3\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (checker)\": \"A curly hair man with a grey tie\", \"Arg1 (thing checked)\": \"the cabinet\", \"ArgM (location)\": \"In a kitchen\"}}'}]},\n",
       " {'id': 'v_WJlOBTLg4xw_seg_60_70_Ev2',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WJlOBTLg4xw_seg_60_70.mp4',\n",
       "  'event': 'Ev2',\n",
       "  'start_secs': 2,\n",
       "  'end_secs': 4,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"observe (look at, mark)\", \"roles\": {\"1\": \"Arg0 (observer)\", \"2\": \"Arg1 (thing looked at)\", \"3\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (observer)\": \"A man in white long sleeves shirt\", \"Arg1 (thing looked at)\": \"The bathroom\", \"Scene of the Event\": \"In a house\"}}'}]},\n",
       " {'id': 'v_WJlOBTLg4xw_seg_60_70_Ev3',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WJlOBTLg4xw_seg_60_70.mp4',\n",
       "  'event': 'Ev3',\n",
       "  'start_secs': 4,\n",
       "  'end_secs': 6,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"leave (move away from)\", \"roles\": {\"1\": \"Arg0 (entity leaving)\", \"2\": \"Arg1 (place, person, or thing left)\", \"3\": \"Arg2 (attribute of arg1)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (entity leaving)\": \"A man in white long sleeves shirt\", \"Arg1 (place, person, or thing left)\": \"The bathroom\", \"Arg2 (attribute of arg1)\": \"away from the bathroom, to the hallway\", \"ArgM (location)\": \"In a house\"}}'}]},\n",
       " {'id': 'v_WJlOBTLg4xw_seg_60_70_Ev4',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WJlOBTLg4xw_seg_60_70.mp4',\n",
       "  'event': 'Ev4',\n",
       "  'start_secs': 6,\n",
       "  'end_secs': 8,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"see (view)\", \"roles\": {\"1\": \"Arg0 (viewer)\", \"2\": \"Arg1 (thing viewed)\", \"3\": \"ArgM (direction)\", \"4\": \"ArgM (location)\"}, \"nouns\": {\"Arg0 (viewer)\": \"A curly hair man with a grey tie\", \"Arg1 (thing viewed)\": \"His note\", \"ArgM (direction)\": \"to his hand\", \"ArgM (location)\": \"down on his hand, in a kitchen\"}}'}]},\n",
       " {'id': 'v_WJlOBTLg4xw_seg_60_70_Ev5',\n",
       "  'video': '/home/dhruv/Projects/VidSitu/vidsitu_data/vsitu_video_trimmed_dir/v_WJlOBTLg4xw_seg_60_70.mp4',\n",
       "  'event': 'Ev5',\n",
       "  'start_secs': 8,\n",
       "  'end_secs': 10,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<video>\\n Task VidSitu: Generate the verb and corresponding roles, then generate the noun based on the verb and roles'},\n",
       "   {'from': 'gpt',\n",
       "    'value': '{\"verb\": \"open (open)\", \"roles\": {\"1\": \"Arg0 (opener)\", \"2\": \"Arg1 (thing opening)\", \"3\": \"ArgM (manner)\", \"4\": \"Scene of the Event\"}, \"nouns\": {\"Arg0 (opener)\": \"A curly hair man with a grey tie\", \"Arg1 (thing opening)\": \"The fridge\", \"ArgM (manner)\": \"Hoping to find something\", \"Scene of the Event\": \"In a kitchen\"}}'}]},\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuning_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert dataset\n",
    "fine_tuning_data = convert_to_fine_tuning_format(train_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "print(json.dumps(fine_tuning_data, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121330"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fine_tuning_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"vidsitu_train_SFT.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(fine_tuning_dataset, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_file = \"imsitu_train_SFT.json\"\n",
    "\n",
    "fine_tuning_data = json.load(open(output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_images = {}\n",
    "\n",
    "# Iterate through the dataset and randomly select one element per unique image\n",
    "for item in fine_tuning_data:\n",
    "    image_id = item['id']\n",
    "    if image_id not in unique_images:\n",
    "        unique_images[image_id] = []\n",
    "    unique_images[image_id].append(item)\n",
    "\n",
    "# Select one random element for each unique image\n",
    "final_data = []\n",
    "for image_id, items in unique_images.items():\n",
    "    selected_item = random.choice(items)\n",
    "    final_data.append(selected_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"imsitu_train_unique_SFT.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(final_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75702"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227106"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "75702*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print or save the modified dataset\n",
    "print(json.dumps(final_data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vila",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
